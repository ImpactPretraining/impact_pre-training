,id,title,author,year,publisher,issn,url,doi,abstract,keyword,pages,num_pages,publication_venue
0,@article: PALLY2022105285,Application of image processing and convolutional neural networks for flood image classification and semantic segmentation,R.J. Pally and S. Samadi,2022,,1364-8152,https://www.sciencedirect.com/science/article/pii/S1364815221003273,https://doi.org/10.1016/j.envsoft.2021.105285,"Deep learning algorithms are exceptionally valuable tools for collecting and analyzing the catastrophic readiness and countless actionable flood data. Convolutional neural networks (CNNs) are one form of deep learning algorithms widely used in computer vision which can be used to study flood images and assign learnable weights to various objects in the image. Here, we leveraged and discussed how connected vision systems can be used to embed cameras, image processing, CNNs, and data connectivity capabilities for flood label detection. We built a training database service of >9000 images (image annotation service) including the image geolocation information by streaming relevant images from social media platforms, Department of Transportation (DOT) 511 traffic cameras, the US Geological Survey (USGS) live river cameras, and images downloaded from search engines. We then developed a new python package called “FloodImageClassifier” to classify and detect objects within the collected flood images. “FloodImageClassifier” includes various CNNs architectures such as YOLOv3 (You look only once version 3), Fast R–CNN (Region-based CNN), Mask R–CNN, SSD MobileNet (Single Shot MultiBox Detector MobileNet), and EfficientDet (Efficient Object Detection) to perform both object detection and segmentation simultaneously. Canny Edge Detection and aspect ratio concepts are also included in the package for flood water level estimation and classification. The pipeline is smartly designed to train a large number of images and calculate flood water levels and inundation areas which can be used to identify flood depth, severity, and risk. “FloodImageClassifier” can be embedded with the USGS live river cameras and 511 traffic cameras to monitor river and road flooding conditions and provide early intelligence to emergency response authorities in real-time","Image processing, Convolutional neural networks, Flood label detection, Floodwater level and extend estimation, “FloodImageClassifier” package",105285,,Environmental Modelling & Software
1,@article: GAUCH2021104926,The proper care and feeding of CAMELS: How limited training data affects streamflow prediction,Martin Gauch and Juliane Mai and Jimmy Lin,2021,,1364-8152,https://www.sciencedirect.com/science/article/pii/S136481522030983X,https://doi.org/10.1016/j.envsoft.2020.104926,"Accurate streamflow prediction largely relies on historical meteorological records and streamflow measurements. For many regions, however, such data are only scarcely available. Facing this problem, many studies simply trained their machine learning models on the region's available data, leaving possible repercussions of this strategy unclear. In this study, we evaluate the sensitivity of tree- and LSTM-based models to limited training data, both in terms of geographic diversity and different time spans. We feed the models meteorological observations disseminated with the CAMELS dataset, and individually restrict the training period length, number of training basins, and input sequence length. We quantify how additional training data improve predictions and how many previous days of forcings we should feed the models to obtain best predictions for each training set size. Further, our findings show that tree- and LSTM-based models provide similarly accurate predictions on small datasets, while LSTMs are superior given more training data","LSTM, XGBoost, CAMELS, Streamflow prediction, Machine learning",104926,,Environmental Modelling & Software
2,@article: ZHANG2020104600,Constructing a PM2.5 concentration prediction model by combining auto-encoder with Bi-LSTM neural networks,Bo Zhang and Hanwen Zhang and Gengming Zhao and Jie Lian,2020,,1364-8152,https://www.sciencedirect.com/science/article/pii/S1364815219300192,https://doi.org/10.1016/j.envsoft.2019.104600,"Air pollution problems have a severe effect on the natural environment and public health. The application of machine learning to air pollutant data can result in a better understanding of environmental quality. Of these methods, the deep learning method has proven to be a very efficient and accurate method to forecast complex air quality data. This paper proposes a deep learning model based on an auto-encoder and bidirectional long short-term memory (Bi-LSTM) to forecast PM2.5 concentrations to reveal the correlation between PM2.5 and multiple climate variables. The model comprises several aspects, including data preprocessing, auto-encoder layer, and Bi-LSTM layer. The performance of the proposed model was verified based on a real-world air pollution dataset, and the results indicated this model can improve the prediction accuracy in an experimental scenario","Deep learning, Auto-encoder, Bi-LSTM, Data preprocessing, PM concentration prediction, Air pollution",104600,,Environmental Modelling & Software
3,@article: PAIS2021105122,Deep fire topology: Understanding the role of landscape spatial patterns in wildfire occurrence using artificial intelligence,Cristobal Pais and Alejandro Miranda and Jaime Carrasco and Zuo-Jun Max Shen,2021,,1364-8152,https://www.sciencedirect.com/science/article/pii/S1364815221001651,https://doi.org/10.1016/j.envsoft.2021.105122,"Increasing wildfire activity globally has become an urgent issue with enormous ecological and social impacts. In this work, we focus on analyzing and quantifying the influence of landscape topology, understood as the spatial structure and interaction of multiple land-covers in an area, on fire ignition. We propose a deep learning framework, Deep Fire Topology, to estimate and predict wildfire ignition risk. We focus on understanding the impact of these topological attributes and the rationale behind the results to provide interpretable knowledge for territorial planning considering wildfire ignition uncertainty. We demonstrate the high performance and interpretability of the framework in a case study, accurately detecting risky areas by exploiting spatial patterns. This work reveals the strong potential of landscape topology in wildfire occurrence prediction and its implications to develop robust landscape management plans. We discuss potential extensions and applications of the proposed method, available as an open-source software","Deep learning, Machine learning, Landscape topology, Wildfire ignition risk, Wildfire management, Territorial planning",105122,,Environmental Modelling & Software
4,@article: YE2019407,Projecting Australia's forest cover dynamics and exploring influential factors using deep learning,Long Ye and Lei Gao and Raymundo Marcos-Martinez and Dirk Mallants and Brett A. Bryan,2019,,1364-8152,https://www.sciencedirect.com/science/article/pii/S1364815218304237,https://doi.org/10.1016/j.envsoft.2019.07.013,"This study presents the first application of deep learning techniques in capturing long-term, time-continuous forest cover dynamics at a continental scale. We developed a spatially-explicit ensemble model for projecting Australia's forest cover change using Long Short-Term Memory (LSTM) deep learning neural networks applied to a multi-dimensional, high-resolution spatiotemporal dataset and run on a high-performance computing cluster. We further quantified the influence of explanatory variables on the spatiotemporal dynamics of continental forest cover. Deep learning greatly outperformed a state-of-the-art spatial-econometric model at continental, state, and grid-cell scales. For example, at the continental scale, compared to the spatial-econometric model, the deep learning model improved projection performance by 44% (root-mean-square error) and 12% (pseudo R-squared). The results illustrate the robustness and effectiveness of the LSTM model. This work provides a reliable tool for projecting forest cover and agricultural production under given future scenarios, supporting decision-making in sustainable land development, management, and conservation","Long short-term memory, Deep learning, Forest cover change, Spatiotemporal data, Projections, Deforestation",407-417,,Environmental Modelling & Software
5,@article: RAZAVI2021105159,"Deep learning, explained: Fundamentals, explainability, and bridgeability to process-based modelling",Saman Razavi,2021,,1364-8152,https://www.sciencedirect.com/science/article/pii/S1364815221002024,https://doi.org/10.1016/j.envsoft.2021.105159,"Recent breakthroughs in artificial intelligence (AI), and particularly in deep learning (DL), have created tremendous excitement and opportunities in the earth and environmental sciences communities. To leverage these new ‘data-driven’ technologies, however, one needs to understand the fundamental concepts that give rise to DL and how they differ from ‘process-based’, mechanistic modelling. This paper revisits those fundamentals and addresses 10 questions that might be posed by earth and environmental scientists, and with the aid of a real-world modelling experiment, it explains some critical, but often ignored, issues DL may face in practice. The overarching objective is to contribute to a future of AI-assisted earth and environmental sciences where AI models can (1) embrace the typically ignored knowledge base available, (2) function credibly in ‘true’ out-of-sample prediction, and (3) handle non-stationarity in earth and environmental systems. Comparing and contrasting earth and environmental problems with prominent AI applications, such as playing chess and trading in stock markets, provides critical insights for better directing future research in this field","Artificial intelligence, Machine learning, Deep learning, Artificial neural networks, Process-based modelling, Earth systems, Hydrology",105159,,Environmental Modelling & Software
6,@article: XU2017127,Automatic land cover classification of geo-tagged field photos by deep learning,Guang Xu and Xuan Zhu and Dongjie Fu and Jinwei Dong and Xiangming Xiao,2017,,1364-8152,https://www.sciencedirect.com/science/article/pii/S1364815216303152,https://doi.org/10.1016/j.envsoft.2017.02.004,"With more and more crowdsourcing geo-tagged field photos available online, they are becoming a potentially valuable source of information for environmental studies. However, the labelling and recognition of these photos are time-consuming. To utilise such information, a land cover type recognition model for field photos was proposed based on the deep learning technique. This model combines a pre-trained convolutional neural network (CNN) as the image feature extractor and the multinomial logistic regression model as the feature classifier. The pre-trained CNN model Inception-v3 was used in this study. The labelled field photos from the Global Geo-Referenced Field Photo Library (http://eomf.ou.edu/photos) were chosen for model training and validation. The results indicated that our recognition model achieved an acceptable accuracy (48.40% for top-1 prediction and 76.24% for top-3 prediction) of land cover classification. With accurate self-assessment of confidence, the model can be applied to classify numerous online geo-tagged field photos for environmental information extraction","Deep learning, Convolutional neural network, Transfer learning, Multinomial logistic regression, Land cover, Crowdsourced photos",127-134,,Environmental Modelling & Software
7,@article: XU2021106452,Feature selection and embedding based cross project framework for identifying crashing fault residence,Zhou Xu and Tao Zhang and Jacky Keung and Meng Yan and Xiapu Luo and Xiaohong Zhang and Ling Xu and Yutian Tang,2021,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584920302019,https://doi.org/10.1016/j.infsof.2020.106452,"Context: The automatically produced crash reports are able to analyze the root of fault causing the crash (crashing fault for short) which is a critical activity for software quality assurance. Objective: Correctly predicting the existence of crashing fault residence in stack traces of crash report can speed up program debugging process and optimize debugging efforts. Existing work focused on the collected label information from bug-fixing logs, and the extracted features of crash instances from stack traces and source code for Identification of Crashing Fault Residence (ICFR) of newly-submitted crashes. This work develops a novel cross project ICFR framework to address the data scarcity problem by using labeled crash data of other project for the ICFR task of the project at hand. This framework removes irrelevant features, reduces distribution differences, and eases the class imbalance issue of cross project data since these factors may negatively impact the ICFR performance. Method: The proposed framework, called FSE, combines Feature Selection and feature Embedding techniques. The FSE framework first uses an information gain ratio based feature ranking method to select a relevant feature subset for cross project data, and then employs a state-of-the-art Weighted Balanced Distribution Adaptation (WBDA) method to map features of cross project data into a common space. WBDA considers both marginal and conditional distributions as well as their weights to reduce data distribution discrepancies. Besides, WBDA balances the class proportion of each project data to alleviate the class imbalance issue. Results: We conduct experiments on 7 projects to evaluate the performance of our FSE framework. The results show that FSE outperforms 25 methods under comparison. Conclusion: This work proposes a cross project learning framework for ICFR, which uses feature selection and embedding to remove irrelevant features and reduce distribution differences, respectively. The results illustrate the performance superiority of our FSE framework","Crashing fault, Stack trace, Feature selection, Feature embedding, Cross project framework",106452,,Information and Software Technology
8,@article: ZHAO2021106619,Icon2Code: Recommending code implementations for Android GUI components,Yanjie Zhao and Li Li and Xiaoyu Sun and Pei Liu and John Grundy,2021,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584921000926,https://doi.org/10.1016/j.infsof.2021.106619,Contex,"Android, App development, Collaborative filtering, Icon implementation, API recommendation",106619,,Information and Software Technology
9,@article: HUANG2020106373,Towards automatically generating block comments for code snippets,Yuan Huang and Shaohao Huang and Huanchao Chen and Xiangping Chen and Zibin Zheng and Xiapu Luo and Nan Jia and Xinyu Hu and Xiaocong Zhou,2020,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584920301427,https://doi.org/10.1016/j.infsof.2020.106373,"Code commenting is a common programming practice of practical importance to help developers review and comprehend source code. There are two main types of code comments for a method: header comments that summarize the method functionality located before a method, and block comments that describe the functionality of the code snippets within a method. Inspired by the effectiveness of deep learning techniques in the NLP field, many studies focus on using the machine translation model to automatically generate comment for the source code. Because the data set of block comments is difficult to collect, current studies focus more on the automatic generation of header comments than that of block comments. However, block comments are important for program comprehension due to their explanation role for the code snippets in a method. To fill the gap, we have proposed an approach that combines heuristic rules and learning-based method to collect a large number of comment-code pairs from 1,032 open source projects in our previous study. In this paper, we propose a reinforcement learning-based method, RL-BlockCom, to automatically generate block comments for code snippets based on the collected comment-code pairs. Specifically, we utilize the abstract syntax tree (i.e., AST) of a code snippet to generate a token sequence with a statement-based traversal way. Then we propose a composite learning model, which combines the actor-critic algorithm of reinforcement learning with the encoder-decoder algorithm, to generate block comments. On the data set of the comment-code pairs, the BLEU-4 score of our method is 24.28, which outperforms the baselines and state-of-the-art in comment generation","Automatic comment generation, Source code summarization, Code comment scope, Reinforcement learning",106373,,Information and Software Technology
10,@article: CHEN2021106441,Revisiting heterogeneous defect prediction methods: How far are we?,Xiang Chen and Yanzhou Mu and Ke Liu and Zhanqi Cui and Chao Ni,2021,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584920301944,https://doi.org/10.1016/j.infsof.2020.106441,"Context: Cross-project defect prediction applies to the scenarios that the target projects are new projects. Most of the previous studies tried to utilize the training data from other projects (i.e., the source projects). However, metrics used by practitioners to measure the extracted program modules from different projects may not be the same, and performing heterogeneous defect prediction (HDP) is challenging. Objective: Researchers have proposed many novel HDP methods with promising performance until now. Recently, unsupervised defect prediction (UDP) methods have received more attention and show competitive performance. However, to our best knowledge, whether HDP methods can perform significantly better than UDP methods has not yet been thoroughly investigated. Method: In this article, we perform a comparative study to have a holistic look at this issue. Specifically, we compare five HDP methods with four UDP methods on 34 projects in five groups under the same experimental setup from three different perspectives: non-effort-aware performance indicators (NPIs), effort-aware performance indicators (EPIs) and diversity analysis on identifying defective modules. Result: We have the following findings: (1) HDP methods do not perform significantly better than some of UDP methods in terms of two NPIs and four EPIs. (2) According to two satisfactory criteria recommended by previous studies, the satisfactory ratio of existing HDP methods is pessimistic. (3) The diversity of prediction for defective modules across HDP vs. UDP methods is more than that within HDP methods or UDP methods. Conclusion: The above findings implicate there is still a long way for the HDP issue to go. Given this, we present some observations about the road ahead for HDP","Software defect prediction, Heterogeneous defect prediction, Unsupervised defect prediction, Non-effort-aware performance indicators, Effort-aware performance indicators, Diversity analysis, Empirical studies",106441,,Information and Software Technology
11,@article: FANG2021106542,Self-Attention Networks for Code Search,Sen Fang and You-Shuai Tan and Tao Zhang and Yepang Liu,2021,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584921000288,https://doi.org/10.1016/j.infsof.2021.106542,Contex,"Code search, Self-attention mechanism, Joint embedding",106542,,Information and Software Technology
12,@article: JAVED2021106558,iMER: Iterative process of entity relationship and business process model extraction from the requirements,Muhammad Javed and Yuqing Lin,2021,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584921000422,https://doi.org/10.1016/j.infsof.2021.106558,Conte,"Entity relationship model, Business process model, General requirements, User stories, Use case specification, Natural language processing",106558,,Information and Software Technology
13,@article: ZHANG2021106701,DeepBackground: Metamorphic testing for Deep-Learning-driven image recognition systems accompanied by Background-Relevance,Zhiyi Zhang and Pu Wang and Hongjing Guo and Ziyuan Wang and Yuqian Zhou and Zhiqiu Huang,2021,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584921001555,https://doi.org/10.1016/j.infsof.2021.106701,Contex,"Metamorphic testing, Deep learning, Image recognition system, Test data generation, Robust systems",106701,,Information and Software Technology
14,@article: MA2012248,Transfer learning for cross-company software defect prediction,Ying Ma and Guangchun Luo and Xue Zeng and Aiguo Chen,2012,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584911001996,https://doi.org/10.1016/j.infsof.2011.09.007,Conte,"Machine learning, Software defect prediction, Transfer learning, Naive Bayes, Different distribution",248-256,,Information and Software Technology
15,@article: SAHIN2022106822,Predicting vulnerability inducing function versions using node embeddings and graph neural networks,Sefa Eren Şahin and Ecem Mine Özyedierler and Ayse Tosun,2022,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584922000015,https://doi.org/10.1016/j.infsof.2022.106822,Contex,"Software vulnerabilities, Graph neural networks, Graph embeddings, Abstract syntax trees",106822,,Information and Software Technology
16,@article: ZOU2021106588,Joint feature representation learning and progressive distribution matching for cross-project defect prediction,Quanyi Zou and Lu Lu and Zhanyu Yang and Xiaowei Gu and Shaojian Qiu,2021,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584921000689,https://doi.org/10.1016/j.infsof.2021.106588,Contex,"Domain adaption, Cross project defect prediction, Feature representation, Progressive distribution matching",106588,,Information and Software Technology
17,@article: QU2021106605,Leveraging developer information for efficient effort-aware bug prediction,Yu Qu and Jianlei Chi and Heng Yin,2021,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584921000823,https://doi.org/10.1016/j.infsof.2021.106605,Contex,"Software bug prediction, Defect prediction, Effort-aware bug prediction, Developer information, Unsupervised model, Empirical study",106605,,Information and Software Technology
18,@article: ISLAM2022106756,Early prediction for merged vs abandoned code changes in modern code reviews,Khairul Islam and Toufique Ahmed and Rifat Shahriyar and Anindya Iqbal and Gias Uddin,2022,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584921002032,https://doi.org/10.1016/j.infsof.2021.106756,Contex,"Code review, Patch, Early prediction, Merged, Abandoned",106756,,Information and Software Technology
19,@article: HUQ2022106765,Review4Repair: Code review aided automatic program repairing,Faria Huq and Masum Hasan and Md Mahim Anjum Haque and Sazan Mahbub and Anindya Iqbal and Toufique Ahmed,2022,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584921002111,https://doi.org/10.1016/j.infsof.2021.106765,Contex,"Automatic program repair, Deep learning, Code review",106765,,Information and Software Technology
20,@article: MENZIES201935,“Bad smells” in software analytics papers,Tim Menzies and Martin Shepperd,2019,,0950-5849,https://www.sciencedirect.com/science/article/pii/S095058491930076X,https://doi.org/10.1016/j.infsof.2019.04.005,Conte,,35-47,,Information and Software Technology
21,@article: GHADHAB2021106566,Augmenting commit classification by using fine-grained source code changes and a pre-trained deep neural language model,Lobna Ghadhab and Ilyes Jenhani and Mohamed Wiem Mkaouer and Montassar {Ben Messaoud},2021,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584921000495,https://doi.org/10.1016/j.infsof.2021.106566,Contex,"Software maintenance, Commit classification, Code changes, Deep neural networks, Pre-trained neural language model",106566,,Information and Software Technology
22,@article: LI2022106770,Automated data function extraction from textual requirements by leveraging semi-supervised CRF and language model,Mingyang Li and Lin Shi and Yawen Wang and Junjie Wang and Qing Wang and Jun Hu and Xinhua Peng and Weimin Liao and Guizhen Pi,2022,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584921002135,https://doi.org/10.1016/j.infsof.2021.106770,Contex,"Function point analysis, Size estimation, Conditional random field, Bootstrapping, Language model",106770,,Information and Software Technology
23,@article: LIU2020106348,A statistical pattern based feature extraction method on system call traces for anomaly detection,Zhen Liu and Nathalie Japkowicz and Ruoyu Wang and Yongming Cai and Deyu Tang and Xianfa Cai,2020,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584920301154,https://doi.org/10.1016/j.infsof.2020.106348,Conte,"Feature extraction, Statistical pattern, System calls, Platform-independent, One-class learning, Anomaly detection",106348,,Information and Software Technology
24,@article: ZHANG201558,Using Bayesian regression and EM algorithm with missing handling for software effort prediction,Wen Zhang and Ye Yang and Qing Wang,2015,,0950-5849,https://www.sciencedirect.com/science/article/pii/S095058491400216X,https://doi.org/10.1016/j.infsof.2014.10.005,Conte,"Bayesian regression, EM algorithm, Missing imputation, Software effort prediction",58-70,,Information and Software Technology
25,@article: LWAKATARE2020106368,Large-scale machine learning systems in real-world industrial settings: A review of challenges and solutions,Lucy Ellen Lwakatare and Aiswarya Raj and Ivica Crnkovic and Jan Bosch and Helena Holmström Olsson,2020,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584920301373,https://doi.org/10.1016/j.infsof.2020.106368,"Background: Developing and maintaining large scale machine learning (ML) based software systems in an industrial setting is challenging. There are no well-established development guidelines, but the literature contains reports on how companies develop and maintain deployed ML-based software systems. Objective: This study aims to survey the literature related to development and maintenance of large scale ML-based systems in industrial settings in order to provide a synthesis of the challenges that practitioners face. In addition, we identify solutions used to address some of these challenges. Method: A systematic literature review was conducted and we identified 72 papers related to development and maintenance of large scale ML-based software systems in industrial settings. The selected articles were qualitatively analyzed by extracting challenges and solutions. The challenges and solutions were thematically synthesized into four quality attributes: adaptability, scalability, safety and privacy. The analysis was done in relation to ML workflow, i.e. data acquisition, training, evaluation, and deployment. Results: We identified a total of 23 challenges and 8 solutions related to development and maintenance of large scale ML-based software systems in industrial settings including six different domains. Challenges were most often reported in relation to adaptability and scalability. Safety and privacy challenges had the least reported solutions. Conclusion: The development and maintenance on large-scale ML-based systems in industrial settings introduce new challenges specific for ML, and for the known challenges characteristic for these types of systems, require new methods in overcoming the challenges. The identified challenges highlight important concerns in ML system development practice and the lack of solutions point to directions for future research","Machine learning systems, Software engineering, Industrial settings, Challenges, Solutions, SLR",106368,,Information and Software Technology
26,@article: PERTICAS2020106350,Neural networks learn to detect and emulate sorting algorithms from images of their execution traces,Cătălin F. Perticas and Bipin Indurkhya,2020,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584920301178,https://doi.org/10.1016/j.infsof.2020.106350,Conte,"Computer program traces, Program behavior, Program induction, Algorithms, Neural networks, Program visualization, Data representation",106350,,Information and Software Technology
27,@article: KRISHNA201753,Less is more: Minimizing code reorganization using XTREE,Rahul Krishna and Tim Menzies and Lucas Layman,2017,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584916301641,https://doi.org/10.1016/j.infsof.2017.03.012,"Context: Developers use bad code smells to guide code reorganization. Yet developers, textbooks, tools, and researchers disagree on which bad smells are important. How can we offer reliable advice to developers about which bad smells to fix? Objective: To evaluate the likelihood that a code reorganization to address bad code smells will yield improvement in the defect-proneness of the code. Method: We introduce XTREE, a framework that analyzes a historical log of defects seen previously in the code and generates a set of useful code changes. Any bad smell that requires changes outside of that set can be deprioritized (since there is no historical evidence that the bad smell causes any problems). Evaluation: We evaluate XTREE’s recommendations for bad smell improvement against recommendations from previous work (Shatnawi, Alves, and Borges) using multiple data sets of code metrics and defect counts. Results: Code modules that are changed in response to XTREE’s recommendations contain significantly fewer defects than recommendations from previous studies. Further, XTREE endorses changes to very few code metrics, so XTREE requires programmers to do less work. Further, XTREE’s recommendations are more responsive to the particulars of different data sets. Finally XTREE’s recommendations may be generalized to identify the most crucial factors affecting multiple datasets (see the last figure in paper). Conclusion: Before undertaking a code reorganization based on a bad smell report, use a framework like XTREE to check and ignore any such operations that are useless; i.e. ones which lack evidence in the historical record that it is useful to make that change. Note that this use case applies to both manual code reorganizations proposed by developers as well as those conducted by automatic methods","Bad smells, Performance prediction, Decision trees",53-66,,Information and Software Technology
28,@article: OCHODEK2020106310,Deep learning model for end-to-end approximation of COSMIC functional size based on use-case names,Mirosław Ochodek and Sylwia Kopczyńska and Miroslaw Staron,2020,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584920300628,https://doi.org/10.1016/j.infsof.2020.106310,Conte,"Functional size approximation, Approximate software sizing methods, COSMIC, Deep learning, Word embeddings, Use cases",106310,,Information and Software Technology
29,@article: XI2016219,Suppressing detection of inconsistency hazards with pattern learning,Wang Xi and Chang Xu and Wenhua Yang and Xiaoxing Ma and Ping Yu and Jian Lu,2016,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584915001378,https://doi.org/10.1016/j.infsof.2015.08.003,"Context: Inconsistency detection and resolution is critical for context-aware applications to ensure their normal execution. Contexts, which refer to pieces of environmental information used by applications, are checked against consistency constraints for potential errors. However, not all detected inconsistencies are caused by real context problems. Instead, they might be triggered by improper checking timing. Such inconsistencies are ephemeral and usually harmless. Their detection and resolution is unnecessary, and may even be detrimental. We name them inconsistency hazards. Objective: Inconsistency hazards should be prevented from being detected or resolved, but it is not straightforward since their occurrences resemble real inconsistencies. In this article, we present SHAP, a pattern-learning based approach to suppressing the detection of such hazards automatically. Method: Our key insight is that detection of inconsistency hazards is subject to certain patterns of context changes. Although such patterns can be difficult to specify manually, they may be learned effectively with data mining techniques. With these patterns, we can reasonably schedule inconsistency detections. Results: The experimental results show that SHAP can effectively suppress the detection of most inconsistency hazards (over 90%) with negligible overhead. Conclusions: Comparing with other approaches, our approach can effectively suppress the detection of inconsistency hazards, and at the same time allow real inconsistencies to be detected and resolved timely","Context inconsistency, Inconsistency hazard, Pattern learning",219-229,,Information and Software Technology
30,@article: CHEN201567,Negative samples reduction in cross-company software defects prediction,Lin Chen and Bin Fang and Zhaowei Shang and Yuanyan Tang,2015,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584915000348,https://doi.org/10.1016/j.infsof.2015.01.014,Conte,"Cross-company defects prediction, Software fault prediction, Transfer learning",67-77,,Information and Software Technology
31,@article: CASILLO2022106853,Detecting privacy requirements from User Stories with NLP transfer learning models,Francesco Casillo and Vincenzo Deufemia and Carmine Gravino,2022,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584922000246,https://doi.org/10.1016/j.infsof.2022.106853,Contex,"User Stories, Natural Language Processing, Deep learning, Transfer Learning",106853,,Information and Software Technology
32,@article: YAO2021106664,The impact of using biased performance metrics on software defect prediction research,Jingxiu Yao and Martin Shepperd,2021,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584921001270,https://doi.org/10.1016/j.infsof.2021.106664,Contex,"Software engineering, Machine learning, Software defect prediction, Computational experiment, Classification metrics",106664,,Information and Software Technology
33,@article: KRUPITZER2022106826,Proactive hybrid learning and optimisation in self-adaptive systems: The swarm-fleet infrastructure scenario,Christian Krupitzer and Christian Gruhl and Bernhard Sick and Sven Tomforde,2022,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584922000052,https://doi.org/10.1016/j.infsof.2022.106826,Contex,"Self-awareness, Self-reflection, Hybrid optimisation, Autonomous learning, Proactive behaviour, Swarm fleet infrastructure, Autonomous taxi, Organic computing",106826,,Information and Software Technology
34,@article: WU2021106530,Improving high-impact bug report prediction with combination of interactive machine learning and active learning,Xiaoxue Wu and Wei Zheng and Xiang Chen and Yu Zhao and Tingting Yu and Dejun Mu,2021,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584921000185,https://doi.org/10.1016/j.infsof.2021.106530,Contex,"High-impact bug report, Interactive machine learning, Active learning, Uncertainty-sampling, Security bug report prediction",106530,,Information and Software Technology
35,@article: CHO2022106743,Classifying issue reports according to feature descriptions in a user manual based on a deep learning model,Heetae Cho and Seonah Lee and Sungwon Kang,2022,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584921001890,https://doi.org/10.1016/j.infsof.2021.106743,Conte,"Deep learning, Classification, Issue reports, User manual, Software features, Data-based software engineering, Convolution neural network, Recurrent neural network, Machine learning",106743,,Information and Software Technology
36,@article: KAPPEL2021106472,Leveraging Small Sample Learning for Business Process Management,Martin Käppel and Stefan Schönig and Stefan Jablonski,2021,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584920302172,https://doi.org/10.1016/j.infsof.2020.106472,"Context: Tool support for business process management (BPM) is improving more and more. Often, machine learning techniques are used to recognize certain execution patterns, to optimize workflows and to observe or predict processes. Frequently, many organisations cannot meet the fundamental prerequisites of machine learning methods since less data is recorded and therefore available for analysis. Most machine learning techniques rely on big and sufficient data source sets that can be analyzed. Small Sample Learning (SSL) tackles the issue of implementing machine learning methods in environments where only quantitatively insufficient datasets are available. These methods are strongly tailored to computer vision or natural language processing problems, which is why they are still neglected in the BPM area. Objective: This paper motivates the use of SSL methods in the BPM area and fosters a research stream that is concerned with the transferability to and the application of these methods in the BPM area. Method: We propose a concept for leveraging SSL methods in BPM and illustrate the idea exemplarly in the field of process mining. Results: Reasons for the need of SSL methods in the BPM area and a conceptual approach for transferring existing SSL methods to the BPM area. The feasibility of our apprach is shown by a brief overview of a primary study leveraging SSL methods for process prediction. Conclusions: Many areas of process mining or BPM in general depend on a sufficient amount of (training) data. Often small and medium sized companies lack ”big data”, which is why advantages of machine learning and data analysis in the context of BPM cannot be applied. Existing methods that deal with insufficient data are very domain-specific and must be transferred to the process mining area respectively the BPM area","Small Sample Learning, BPM, Process Prediction, Machine Learning, Process Mining",106472,,Information and Software Technology
37,@article: WANG2022106845,Personalizing label prediction for GitHub issues,Jun Wang and Xiaofang Zhang and Lin Chen and Xiaoyuan Xie,2022,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584922000192,https://doi.org/10.1016/j.infsof.2022.106845,Contex,"Deep learning, Issue labeling, Data analysis, Language model",106845,,Information and Software Technology
38,@article: WARTSCHINSKI2022106809,VUDENC: Vulnerability Detection with Deep Learning on a Natural Codebase for Python,Laura Wartschinski and Yannic Noller and Thomas Vogel and Timo Kehrer and Lars Grunske,2022,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584921002421,https://doi.org/10.1016/j.infsof.2021.106809,Contex,"Static analysis, Vulnerability detection, Deep learning, Long-short-term memory network, Natural codebase, Software repository mining",106809,,Information and Software Technology
39,@article: LIU2019125,A two-phase transfer learning model for cross-project defect prediction,Chao Liu and Dan Yang and Xin Xia and Meng Yan and Xiaohong Zhang,2019,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584918302416,https://doi.org/10.1016/j.infsof.2018.11.005,"Context: Previous studies have shown that a transfer learning model, TCA+ proposed by Nam et al., can significantly improve the performance of cross-project defect prediction (CPDP). TCA+ achieves the improvement by reducing data distribution difference between source (training data) and target (testing data) projects. However, TCA+ is unstable, i.e., its performance varies largely when using different source projects to build prediction models. In practice, it is hard to choose a suitable source project to build the prediction model. Objective: To address the limitation of TCA+, we propose a two-phase transfer learning model (TPTL) for CPDP. Method: In the first phase, we propose a source project estimator (SPE) to automatically choose two source projects with the highest distribution similarity to a target project from candidates. Next, two source projects that are estimated to achieve the highest values of F1-score and cost-effectiveness are selected. In the second phase, we leverage TCA+ to build two prediction models based on the two selected projects and combine their prediction results to further improve the prediction performance. Results: We evaluate TPTL on 42 defect datasets from PROMISE repository, and compare it with two versions of TCA+ (TCA+_Rnd, randomly selecting one source project; TCA+_All, using all alternative source projects), a related source project selection model TDS proposed by Herbold, a state-of-the-art CPDP model leveraging a log transformation (LT) method, and a transfer learning model Dycom with better form of TCA. Experiment results show that, on average across 42 datasets, TPTL respectively improves these baseline models by 19%, 5%, 36%, 27%, and 11% in terms of F1-score; by 64%, 92%, 71%, 11%, and 66% in terms of cost-effectiveness. Conclusion: The proposed TPTL model can solve the instability problem of TCA+, showing substantial improvements over the state-of-the-art and related CPDP models","Cross-Project prediction, Defect prediction, Transfer learning, Source project selection",125-136,,Information and Software Technology
40,@article: ZHANG2020106296,Testing and verification of neural-network-based safety-critical control software: A systematic literature review,Jin Zhang and Jingyue Li,2020,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584920300471,https://doi.org/10.1016/j.infsof.2020.106296,"Context: Neural Network (NN) algorithms have been successfully adopted in a number of Safety-Critical Cyber-Physical Systems (SCCPSs). Testing and Verification (T&V) of NN-based control software in safety-critical domains are gaining interest and attention from both software engineering and safety engineering researchers and practitioners. Objective: With the increase in studies on the T&V of NN-based control software in safety-critical domains, it is important to systematically review the state-of-the-art T&V methodologies, to classify approaches and tools that are invented, and to identify challenges and gaps for future studies. Method: By searching the six most relevant digital libraries, we retrieved 950 papers on the T&V of NN-based Safety-Critical Control Software (SCCS). Then we filtered the papers based on the predefined inclusion and exclusion criteria and applied snowballing to identify new relevant papers. Results: To reach our result, we selected 83 primary papers published between 2011 and 2018, applied the thematic analysis approach for analyzing the data extracted from the selected papers, presented the classification of approaches, and identified challenges. Conclusion: The approaches were categorized into five high-order themes, namely, assuring robustness of NNs, improving the failure resilience of NNs, measuring and ensuring test completeness, assuring safety properties of NN-based control software, and improving the interpretability of NNs. From the industry perspective, improving the interpretability of NNs is a crucial need in safety-critical applications. We also investigated nine safety integrity properties within four major safety lifecycle phases to investigate the achievement level of T&V goals in IEC 61508-3. Results show that correctness, completeness, freedom from intrinsic faults, and fault tolerance have drawn most attention from the research community. However, little effort has been invested in achieving repeatability, and no reviewed study focused on precisely defined testing configuration or defense against common cause failure","Software testing and verification, Neural network, Safety-critical control software, Systematic literature review",106296,,Information and Software Technology
41,@article: LIMSETTHO201887,Cross project defect prediction using class distribution estimation and oversampling,Nachai Limsettho and Kwabena Ebo Bennin and Jacky W. Keung and Hideaki Hata and Kenichi Matsumoto,2018,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584918300533,https://doi.org/10.1016/j.infsof.2018.04.001,Conte,"Cross-Project defect prediction, Software fault prediction, Oversampling, Class imbalance learning, Class distribution estimation",87-102,,Information and Software Technology
42,@article: ZHOU20191,Is deep learning better than traditional approaches in tag recommendation for software information sites?,Pingyi Zhou and Jin Liu and Xiao Liu and Zijiang Yang and John Grundy,2019,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584919300047,https://doi.org/10.1016/j.infsof.2019.01.002,Conte,"Deep learning, Data analysis, Tag recommendation, Software information site, Software object",1-13,,Information and Software Technology
43,@article: PERKUSICH2020106241,Intelligent software engineering in the context of agile software development: A systematic literature review,Mirko Perkusich and Lenardo {Chaves e Silva} and Alexandre Costa and Felipe Ramos and Renata Saraiva and Arthur Freire and Ednaldo Dilorenzo and Emanuel Dantas and Danilo Santos and Kyller Gorgônio and Hyggo Almeida and Angelo Perkusich,2020,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584919302587,https://doi.org/10.1016/j.infsof.2019.106241,"CONTEXT: Intelligent Software Engineering (ISE) refers to the application of intelligent techniques to software engineering. We define an “intelligent technique” as a technique that explores data (from digital artifacts or domain experts) for knowledge discovery, reasoning, learning, planning, natural language processing, perception or supporting decision-making. OBJECTIVE: The purpose of this study is to synthesize and analyze the state of the art of the field of applying intelligent techniques to Agile Software Development (ASD). Furthermore, we assess its maturity and identify adoption risks. METHOD: Using a systematic literature review, we identified 104 primary studies, resulting in 93 unique studies. RESULTS: We identified that there is a positive trend in the number of studies applying intelligent techniques to ASD. Also, we determined that reasoning under uncertainty (mainly, Bayesian network), search-based solutions, and machine learning are the most popular intelligent techniques in the context of ASD. In terms of purposes, the most popular ones are effort estimation, requirements prioritization, resource allocation, requirements selection, and requirements management. Furthermore, we discovered that the primary goal of applying intelligent techniques is to support decision making. As a consequence, the adoption risks in terms of the safety of the current solutions are low. Finally, we highlight the trend of using explainable intelligent techniques. CONCLUSION: Overall, although the topic area is up-and-coming, for many areas of application, it is still in its infancy. So, this means that there is a need for more empirical studies, and there are a plethora of new opportunities for researchers","Intelligent software engineering, Agile software development, Search-based software engineering, Machine learning, Bayesian networks, Artificial intelligence",106241,,Information and Software Technology
44,@article: REZAEINASAB2021111046,Automated identification of security discussions in microservices systems: Industrial surveys and experiments,Ali {Rezaei Nasab} and Mojtaba Shahin and Peng Liang and Mohammad Ehsan Basiri and Seyed Ali {Hoseyni Raviz} and Hourieh Khalajzadeh and Muhammad Waseem and Amineh Naseri,2021,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121221001436,https://doi.org/10.1016/j.jss.2021.111046,"Lack of awareness and knowledge of microservices-specific security challenges and solutions often leads to ill-informed security decisions in microservices system development. We claim that identifying and leveraging security discussions scattered in existing microservices systems can partially close this gap. We define security discussion as “a paragraph from developer discussions that includes design decisions, challenges, or solutions relating to security”. We first surveyed 67 practitioners and found that securing microservices systems is a unique challenge and that having access to security discussions is useful for making security decisions. The survey also confirms the usefulness of potential tools that can automatically identify such security discussions. We developed fifteen machine/deep learning models to automatically identify security discussions. We applied these models on a manually constructed dataset consisting of 4,813 security discussions and 12,464 non-security discussions. We found that all the models can effectively identify security discussions: an average precision of 84.86%, recall of 72.80%, F1-score of 77.89%, AUC of 83.75% and G-mean 82.77%. DeepM1, a deep learning model, performs the best, achieving above 84% in all metrics and significantly outperforms three baselines. Finally, the practitioners’ feedback collected from a validation survey reveals that security discussions identified by DeepM1 have promising applications in practice","Microservices architecture, Security, Machine learning, Deep learning, Automation",111046,,Journal of Systems and Software
45,@article: ZHOU2020110572,Improving software bug-specific named entity recognition with deep neural network,Cheng Zhou and Bin Li and Xiaobing Sun,2020,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121220300534,https://doi.org/10.1016/j.jss.2020.110572,"There is a large volume of bug data in the bug repository, which contains rich bug information. Existing studies on bug data mining mainly rely on using information retrieval (IR) technology to search relevant historical bug reports. These studies basically treat a bug report as a closed unit, ignoring the semantic and structural information within it. Named-entity recognition (NER) is an important task of information extraction (IE) technology. Based on NER, fine-grained factual information could be comprehensively extracted to further form structured data, which provides a new way to improve the accessibility of bug information. However, bug NER is different from general NER tasks. Bug reports are free-form text, which include a mixed language environment studded with code, abbreviations and software-specific vocabularies. In this paper, we propose a deep neural network approach for bug-specific entity recognition called DBNER using bidirectional long short-term memory (LSTM) with Conditional Random Fields decoding model (CRF). DBNER extracts multiple features from the massive bug data and uses attention mechanism to improve the consistency of entity tags in the bug reports. Experiment results show that the F1-score reaches an average of 91.19%. In addition, in cross-project experiments, the DBNER’s F1-score reaches an average of 84%","Software bug analysis, Named entity recognition, Software bug corpus, LSTM-CRF",110572,,Journal of Systems and Software
46,@article: HU2020110773,Neural joint attention code search over structure embeddings for software Q&A sites,Gang Hu and Min Peng and Yihan Zhang and Qianqian Xie and Mengting Yuan,2020,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121220301886,https://doi.org/10.1016/j.jss.2020.110773,"Code search is frequently needed in software Q&A sites for software development. Over the years, various code search engines and techniques have been explored to support user query. Early approaches often utilize text retrieval models to match textual code fragments for natural query, but fail to build sufficient semantic correlations. Some recent advanced neural methods focus on restructuring bi-modal networks to measure the semantic similarity. However, they ignore potential structure information of source codes and the joint attention information from natural queries. In addition, they mostly focus on specific code structures, rather than general code fragments in software Q&A sites. In this paper, we propose NJACS, a novel two-way attention-based neural network for retrieving code fragments in software Q&A sites, which aligns and focuses the more structure informative parts of source codes to natural query. Instead of directly learning bi-modal unified vector representations, NJACS first embeds the queries and codes using a bidirectional LSTM with pre-trained structure embeddings separately, then learns an aligned joint attention matrix for query-code mappings, and finally derives the pooling-based projection vectors in different directions to guide the attention-based representations. On different benchmark search codebase collected from StackOverflow, NJACS outperforms state-of-art baselines with 7.5% to 6% higher Recall@1 and MRR, respectively. Moreover, our designed structure embeddings can be leveraged for other deep-learning-based software tasks","Code search, Software Q&A sites, Joint attention, Structure embeddings",110773,,Journal of Systems and Software
47,@article: SPIEKER2020110574,Adaptive metamorphic testing with contextual bandits,Helge Spieker and Arnaud Gotlieb,2020,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121220300558,https://doi.org/10.1016/j.jss.2020.110574,"Metamorphic Testing is a software testing paradigm which aims at using necessary properties of a system under test, called metamorphic relations, to either check its expected outputs, or to generate new test cases. Metamorphic Testing has been successful to test programs for which a full oracle is not available or to test programs for which there are uncertainties on expected outputs such as learning systems. In this article, we propose Adaptive Metamorphic Testing as a generalization of a simple yet powerful reinforcement learning technique, namely contextual bandits, to select one of the multiple metamorphic relations available for a program. By using contextual bandits, Adaptive Metamorphic Testing learns which metamorphic relations are likely to transform a source test case, such that it has higher chance to discover faults. We present experimental results over two major case studies in machine learning, namely image classification and object detection, and identify weaknesses and robustness boundaries. Adaptive Metamorphic Testing efficiently identifies weaknesses of the tested systems in context of the source test case","Software testing, Metamorphic testing, Contextual bandits, Machine learning",110574,,Journal of Systems and Software
48,@article: YU2017366,A feature matching and transfer approach for cross-company defect prediction,Qiao Yu and Shujuan Jiang and Yanmei Zhang,2017,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121217301346,https://doi.org/10.1016/j.jss.2017.06.070,"Software defect prediction has drawn much attention of researchers in software engineering. Traditional defect prediction methods aim to build the prediction model based on historical data. For a new project or a project with limited historical data, we cannot build a good prediction model. Therefore, researchers have proposed the cross-project defect prediction (CPDP) and cross-company defect prediction (CCDP) methods to share the historical data among different projects. However, the features of cross-company datasets are often heterogeneous, which may affect the feasibility of CCDP. To address the heterogeneous features of CCDP, this paper presents a feature matching and transfer (FMT) approach. First, we conduct feature selection for the source project and get the distribution curves of selected features. Similarly, we also get the distribution curves of all features in the target project. Second, according to the ‘distance’ of different distribution curves, we design a feature matching algorithm to convert the heterogeneous features into the matched features. Finally, we can achieve feature transfer from the source project to the target project. All experiments are conducted on 16 datasets from NASA and PROMISE, and the results show that FMT is effective for CCDP","Software defect prediction, Heterogeneous features, Feature matching, Feature transfer",366-378,,Journal of Systems and Software
49,@article: YU2022111219,Exploiting gated graph neural network for detecting and explaining self-admitted technical debts,Jiaojiao Yu and Kunsong Zhao and Jin Liu and Xiao Liu and Zhou Xu and Xin Wang,2022,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121222000036,https://doi.org/10.1016/j.jss.2022.111219,"Self-admitted technical debt (SATD) refers to a specific type of technical debt that is introduced intentionally in the software development and maintenance processes. SATD enables practitioners to take some temporary solutions instead of making comprehensive decisions, which will lead to the high complexity of the software. However, most existing studies relied on manual methods for detecting SATDs. A recent study proposed a method HATD that used a hybrid attention-based method to automatically detect SATDs and it achieved the state-of-the-art performance. However, HATD mainly focused on the locality of the comment instances and lacked of the relationship between long-distance and discontinuous comment instances. To address such an issue, in this work, we propose a novel approach named GGSATD. Specifically, GGSATD first builds the graph for comment instances and then employs the gated graph neural network to iteratively update node representation. The global representation can be obtained by the soft attention mechanism and pooling operation. Experiments on 10 projects show that our GGSATD method obtains promising performance against five baseline methods in both within-project and cross-project scenarios. Extended experiments on seven real-world projects illustrate the effectiveness of our GGSATD method","Technical debt, Self-admitted technical debt, Gated graph neural network, Attention mechanism",111219,,Journal of Systems and Software
50,@article: GARBA2022111120,Self-adaptive mobile web service discovery framework for Dynamic Mobile Environment,Salisu Garba and Radziah Mohamad and Nor Azizah Saadon,2022,,0164-1212,https://www.sciencedirect.com/science/article/pii/S016412122100217X,https://doi.org/10.1016/j.jss.2021.111120,"This paper proposes a self-adaptive mobile web service (MWS) discovery framework for a dynamic mobile environment (DME) to deal with MWS proliferation, dynamic context, and irrelevant MWS discovery challenges. The main contribution of this research includes an improvement of the matchmaking algorithm, enhanced MWS categorization approach, and extensible meta-context ontology that represents the context information in DME. This was achieved by enabling the self-adaptive matchmaker to learn MWS relevance using a Modified-Negative Selection Algorithm (M-NSA) and retrieve the most relevant MWS based on the current context of the discovery. To assess the proposed framework, series of experiments was carried out using publicly-available datasets. The performance of the framework is evaluated against the state-of-the-art frameworks. It was found that the proposed framework is more effective and attained better binary and graded relevance when subjected to context variations which are prevalent in DME. This is useful for service-based application designers and other MWS clients","Self-adaptive, Mobile web service, Service discovery, Negative Selection Algorithm, Dynamic Mobile Environment",111120,,Journal of Systems and Software
51,@article: LEI2022111141,Deep learning application on code clone detection: A review of current knowledge,Maggie Lei and Hao Li and Ji Li and Namrata Aundhkar and Dae-Kyoo Kim,2022,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121221002387,https://doi.org/10.1016/j.jss.2021.111141,"Bad smells in code are indications of low code quality representing potential threats to the maintainability and reusability of software. Code clone is a type of bad smells caused by code fragments that have the same functional semantics with syntactic variations. In the recent years, the research on duplicate code has been dramatically geared up by deep learning techniques powered by advances in computing power. However, there exists little work studying the current state-of-art and future prospects in the area of applying deep learning to code clone detection. In this paper, we present a systematic review of the literature on the application of deep learning on code clone detection. We aim to find and study the most recent work on the subject, discuss their limitations and challenges, and provide insights on the future work","Code clone, Code smell, Deep learning, Duplicate code, Machine learning, Literature review",111141,,Journal of Systems and Software
52,@article: MIRYEGANEH2021110961,GloBug: Using global data in Fault Localization,Nima Miryeganeh and Sepehr Hashtroudi and Hadi Hemmati,2021,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121221000583,https://doi.org/10.1016/j.jss.2021.110961,"Fault Localization (FL) is an important first step in software debugging and is mostly manual in the current practice. Many methods have been proposed over years to automate the FL process, including information retrieval (IR)-based techniques. These methods localize the fault based on the similarity of the reported bug report and the source code. Newer variations of IR-based FL (IRFL) techniques also look into the history of bug reports and leverage them during the localization. However, all existing IRFL techniques limit themselves to the current project’s data (local data). In this study, we introduce Globug, which is an IRFL framework consisting of methods that use models pre-trained on the global data (extracted from open-source benchmark projects). In Globug, we investigate two heuristics: (a) the effect of global data on a state-of-the-art IR-FL technique, namely BugLocator, and (b) the application of a Word Embedding technique (Doc2Vec) together with global data. Our large scale experiment on 51 software projects shows that using global data improves BugLocator on average 6.6% and 4.8% in terms of MRR (Mean Reciprocal Rank) and MAP (Mean Average Precision), with over 14% in a majority (64% and 54% in terms of MRR and MAP, respectively) of the cases. This amount of improvement is significant compared to the improvement rates that five other state-of-the-art IRFL tools provide over BugLocator. In addition, training the models globally is a one-time offline task with no overhead on BugLocator’s run-time fault localization. Our study, however, shows that a Word Embedding-based global solution did not further improve the results","Automated Fault Localization, Information Retrieval, Word Embedding, TF.IDF, Doc2Vec, Global training",110961,,Journal of Systems and Software
53,@article: SCHEUNER2020110708,Function-as-a-Service performance evaluation: A multivocal literature review,Joel Scheuner and Philipp Leitner,2020,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121220301527,https://doi.org/10.1016/j.jss.2020.110708,"Function-as-a-Service (FaaS) is one form of the serverless cloud computing paradigm and is defined through FaaS platforms (e.g., AWS Lambda) executing event-triggered code snippets (i.e., functions). Many studies that empirically evaluate the performance of such FaaS platforms have started to appear but we are currently lacking a comprehensive understanding of the overall domain. To address this gap, we conducted a multivocal literature review (MLR) covering 112 studies from academic (51) and grey (61) literature. We find that existing work mainly studies the AWS Lambda platform and focuses on micro-benchmarks using simple functions to measure CPU speed and FaaS platform overhead (i.e., container cold starts). Further, we discover a mismatch between academic and industrial sources on tested platform configurations, find that function triggers remain insufficiently studied, and identify HTTP API gateways and cloud storages as the most used external service integrations. Following existing guidelines on experimentation in cloud systems, we discover many flaws threatening the reproducibility of experiments presented in the surveyed studies. We conclude with a discussion of gaps in literature and highlight methodological suggestions that may serve to improve future FaaS performance evaluation studies","Cloud computing, Serverless, Function-as-a-Service, Performance, Benchmarking, Multivocal literature review",110708,,Journal of Systems and Software
54,@article: AUNG2022111133,Multi-triage: A multi-task learning framework for bug triage,Thazin Win Win Aung and Yao Wan and Huan Huo and Yulei Sui,2022,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121221002302,https://doi.org/10.1016/j.jss.2021.111133,"Assigning developers and allocating issue types are two important tasks in the bug triage process. Existing approaches tackle these two tasks separately, which is time-consuming due to repetition of effort and negating the values of correlated information between tasks. In this paper, a multi-triage model is proposed that resolves both tasks simultaneously via multi-task learning (MTL). First, both tasks can be regarded as a classification problem, based on historical issue reports. Second, performances on both tasks can be improved by jointly interpreting the representations of the issue report information. To do so, a text encoder and abstract syntax tree (AST) encoder are used to extract the feature representation of bug descriptions and code snippets accordingly. Finally, due to the disproportionate ratio of class labels in training datasets, the contextual data augmentation approach is introduced to generate syntactic issue reports to balance the class labels. Experiments were conducted on eleven open-source projects to demonstrate the effectiveness of this model compared with state-of-the-art methods","Bug triage, Recommendation system, Multi-task learning, Deep learning",111133,,Journal of Systems and Software
55,@article: GIRAY2021111031,A software engineering perspective on engineering machine learning systems: State of the art and challenges,Görkem Giray,2021,,0164-1212,https://www.sciencedirect.com/science/article/pii/S016412122100128X,https://doi.org/10.1016/j.jss.2021.111031,Contex,"Software engineering, Software development, Software process, Machine learning, Deep learning, Systematic literature review",111031,,Journal of Systems and Software
56,@article: PEREIRA2021111044,Learning software configuration spaces: A systematic literature review,Juliana Alves Pereira and Mathieu Acher and Hugo Martin and Jean-Marc Jézéquel and Goetz Botterweck and Anthony Ventresque,2021,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121221001412,https://doi.org/10.1016/j.jss.2021.111044,"Most modern software systems (operating systems like Linux or Android, Web browsers like Firefox or Chrome, video encoders like ffmpeg, x264 or VLC, mobile and cloud applications, etc.) are highly configurable. Hundreds of configuration options, features, or plugins can be combined, each potentially with distinct functionality and effects on execution time, security, energy consumption, etc. Due to the combinatorial explosion and the cost of executing software, it is quickly impossible to exhaustively explore the whole configuration space. Hence, numerous works have investigated the idea of learning it from a small sample of configurations’ measurements. The pattern “sampling, measuring, learning” has emerged in the literature, with several practical interests for both software developers and end-users of configurable systems. In this systematic literature review, we report on the different application objectives (e.g., performance prediction, configuration optimization, constraint mining), use-cases, targeted software systems, and application domains. We review the various strategies employed to gather a representative and cost-effective sample. We describe automated software techniques used to measure functional and non-functional properties of configurations. We classify machine learning algorithms and how they relate to the pursued application. Finally, we also describe how researchers evaluate the quality of the learning process. The findings from this systematic review show that the potential application objective is important; there are a vast number of case studies reported in the literature related to particular domains or software systems. Yet, the huge variant space of configurable systems is still challenging and calls to further investigate the synergies between artificial intelligence and software engineering","Systematic literature review, Software product lines, Machine learning, Configurable systems",111044,,Journal of Systems and Software
57,@article: BARBEZ2020110486,A machine-learning based ensemble method for anti-patterns detection,Antoine Barbez and Foutse Khomh and Yann-Gaël Guéhéneuc,2020,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121219302602,https://doi.org/10.1016/j.jss.2019.110486,"Anti-patterns are poor solutions to recurring design problems. Several empirical studies have highlighted their negative impact on program comprehension, maintainability, as well as fault-proneness. A variety of detection approaches have been proposed to identify their occurrences in source code. However, these approaches can identify only a subset of the occurrences and report large numbers of false positives and misses. Furthermore, a low agreement is generally observed among different approaches. Recent studies have shown the potential of machine-learning models to improve this situation. However, such algorithms require large sets of manually-produced training-data, which often limits their application in practice. In this paper, we present SMAD (SMart Aggregation of Anti-patterns Detectors), a machine-learning based ensemble method to aggregate various anti-patterns detection approaches on the basis of their internal detection rules. Thus, our method uses several detection tools to produce an improved prediction from a reasonable number of training examples. We implemented SMAD for the detection of two well known anti-patterns: God Class and Feature Envy. With the results of our experiments conducted on eight java projects, we show that: (1) Our method clearly improves the so aggregated tools; (2) SMAD significantly outperforms other ensemble methods","Software quality, Anti-patterns, Machine learning, Ensemble methods",110486,,Journal of Systems and Software
58,@article: VALSAMIS2017249,Employing traditional machine learning algorithms for big data streams analysis: The case of object trajectory prediction,Angelos Valsamis and Konstantinos Tserpes and Dimitrios Zissis and Dimosthenis Anagnostopoulos and Theodora Varvarigou,2017,,0164-1212,https://www.sciencedirect.com/science/article/pii/S016412121630084X,https://doi.org/10.1016/j.jss.2016.06.016,"In this paper, we model the trajectory of sea vessels and provide a service that predicts in near-real time the position of any given vessel in 4′, 10′, 20′ and 40′ time intervals. We explore the necessary tradeoffs between accuracy, performance and resource utilization is explored given the large volume and update rates of input data. We start with building models based on well-established machine learning algorithms using static datasets and multi-scan training approaches and identify the best candidate to be used in implementing a single-pass predictive approach, under real-time constraints. The results are measured in terms of accuracy and performance and are compared against the baseline kinematic equations. Results show that it is possible to efficiently model the trajectory of multiple vessels using a single model, which is trained and evaluated using an adequately large, static dataset, thus achieving a significant gain in terms of resource usage while not compromising accuracy","Trajectory prediction, Real-time query response, Data streams, Machine learning",249-257,,Journal of Systems and Software
59,@article: WU2020110456,CVE-assisted large-scale security bug report dataset construction method,Xiaoxue Wu and Wei Zheng and Xiang Chen and Fang Wang and Dejun Mu,2020,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121219302304,https://doi.org/10.1016/j.jss.2019.110456,"Identifying SBRs (security bug reports) is crucial for eliminating security issues during software development. Machine learning are promising ways for SBR prediction. However, the effectiveness of the state-of-the-art machine learning models depend on high-quality datasets, while gathering large-scale datasets are expensive and tedious. To solve this issue, we propose an automated data labeling approach based on iterative voting classification. It starts with a small group of ground-truth traing samples, which can be labeled with the help of authoritative vulnerability records hosted in CVE (Common Vulnerabilities and Exposures). The accuracy of the prediction model is improved with an iterative voting strategy. By using this approach, we label over 80k bug reports from OpenStack and 40k bug reports from Chromium. The correctness of these labels are then manually reviewed by three experienced security testing members. Finally, we construct a large-scale SBR dataset with 191 SBRs and 88,472 NSBRs (non-security bug reports) from OpenStack; and improve the quality of existing SBR dataset Chromium by identifying 64 new SBRs from previously labeled NSBRs and filtering out 173 noise bug reports from this dataset. These share datasets as well as the proposed dataset construction method help to promote research progress in SBR prediction research domain","Security bug report prediction, Voting classification, Dataset construction, Common vulnerabilities and exposures",110456,,Journal of Systems and Software
60,@article: XIAO2018159,Feedback-based integrated prediction: Defect prediction based on feedback from software testing process,Peng Xiao and Bin Liu and Shihai Wang,2018,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121218301067,https://doi.org/10.1016/j.jss.2018.05.029,"Test resource constraints is a common phenomenon in software testing. Using defect prediction to guide the resource allocation can significantly improve the efficiency and effectiveness of available test resources. However, traditional defect prediction (t-DP) is a static strategy, where the predictor cannot be dynamically adjusted during the software testing process (STP). This paper combines defect prediction with feedback control in STP and proposes a feedback-based defect prediction model, where the test results generated during STP is used as feedback information for on-line adjustment of predictor to optimize the prediction result. In addition, a novel approach called feedback-based integrated prediction (FIP) is proposed to improve the prediction accuracy, where a global predictor and a local predictor are employed to make an integrated prediction using the weight to adjust the effects of predictors at different test stages. A systematic experiment is conducted to investigate the performance of the FIP over 10 public data sets. Results show that FIP has better prediction efficiency and better robustness for external data than the t-DP, especially when the percentage of the test modules is 40%","Test resource constraints, Software testing, Defect prediction, Feedback control, Integrated prediction",159-171,,Journal of Systems and Software
61,@article: PALOMBA2021110847,Predicting the emergence of community smells using socio-technical metrics: A machine-learning approach,Fabio Palomba and Damian Andrew Tamburri,2021,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121220302375,https://doi.org/10.1016/j.jss.2020.110847,"Community smells represent sub-optimal conditions appearing within software development communities (e.g., non-communicating sub-teams, deviant contributors, etc.) that may lead to the emergence of social debt and increase the overall project’s cost. Previous work has studied these smells under different perspectives, investigating their nature, diffuseness, and impact on technical aspects of source code. Furthermore, it has been shown that some socio-technical metrics like, for instance, the well-known socio-technical congruence, can potentially be employed to foresee their appearance. Yet, there is still a lack of knowledge of the actual predictive power of such socio-technical metrics. In this paper, we aim at tackling this problem by empirically investigating (i) the potential value of socio-technical metrics as predictors of community smells and (ii) what is the performance of within- and cross-project community smell prediction models based on socio-technical metrics. To this aim, we exploit a dataset composed of 60 open-source projects and consider four community smells such as Organizational Silo, Black Cloud, Lone Wolf, and Bottleneck. The key results of our work report that a within-project solution can reach F-Measure and AUC-ROC of 77% and 78%, respectively, while cross-project models still require improvements, being however able to reach an F-Measure of 62% and overcome a random baseline. Among the metrics investigated, socio-technical congruence, communicability, and turnover-related metrics are the most powerful predictors of the emergence of community smells","Community smells, Social debt, Empirical software engineering",110847,,Journal of Systems and Software
62,@article: LIU2020110547,Modeling programs hierarchically with stack-augmented LSTM,Fang Liu and Lu Zhang and Zhi Jin,2020,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121220300297,https://doi.org/10.1016/j.jss.2020.110547,"Programming language modeling has attracted extensive attention in recent years, and it plays an essential role in program processing fields. Statistical language models, which are initially designed for natural languages, have been generally used for modeling programming languages. However, different from natural languages, programming languages contain explicit and hierarchical structure that is hard to learn by traditional statistical language models. To address this challenge, we propose a novel Stack-Augmented LSTM neural network for programming language modeling. Adding a stack memory component into the LSTM network enables our model to capture the hierarchical information of programs through the PUSH and POP operations, which further allows our model capturing the long-term dependency in the programs. We evaluate the proposed model on three program analysis tasks, i.e., code completion, program classification, and code summarization. Evaluation results show that our proposed model outperforms baseline models in all the three tasks, indicating that by capturing the structural information of programs with a stack, our proposed model can represent programs more precisely","Programming language modeling, Hierarchical structure, Deep learning, Software engineering",110547,,Journal of Systems and Software
63,@article: ZHANG2020110585,Automated defect identification via path analysis-based features with transfer learning,Yuwei Zhang and Dahai Jin and Ying Xing and Yunzhan Gong,2020,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121220300662,https://doi.org/10.1016/j.jss.2020.110585,"Recently, artificial intelligence techniques have been widely applied to address various specialized tasks in software engineering, such as code generation, defect identification, and bug repair. Despite the diffuse usage of static analysis tools in automatically detecting potential software defects, developers consider the large number of reported alarms and the expensive cost of manual inspection to be a key barrier to using them in practice. To automate the process of defect identification, researchers utilize machine learning algorithms with a set of hand-engineered features to build classification models for identifying alarms as actionable or unactionable. However, traditional features often fail to represent the deep syntactic structure of alarms. To bridge the gap between programs’ syntactic structure and defect identification features, this paper first extracts a set of novel fine-grained features at variable-level, called path-variable characteristic, by applying path analysis techniques in the feature extraction process. We then raise a two-stage transfer learning approach based on our proposed features, called feature ranking-matching based transfer learning, to increase the performance of cross-project defect identification. Our experimental results for eight open-source projects show that the proposed features at variable-level are promising and can yield significant improvement on both within-project and cross-project defect identification","Machine learning, Automated defect identification, Path analysis, Transfer learning, Model evaluation",110585,,Journal of Systems and Software
64,@article: LIN2020110767,Black-box adversarial sample generation based on differential evolution,Junyu Lin and Lei Xu and Yingqi Liu and Xiangyu Zhang,2020,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121220301850,https://doi.org/10.1016/j.jss.2020.110767,"Deep Neural Networks (DNNs) are being used in various daily tasks such as object detection, speech processing, and machine translation. However, it is known that DNNs suffer from robustness problems — perturbed inputs called adversarial samples leading to misbehaviors of DNNs. In this paper, we propose a black-box technique called Black-box Momentum Iterative Fast Gradient Sign Method (BMI-FGSM) to test the robustness of DNN models. The technique does not require any knowledge of the structure or weights of the target DNN. Compared to existing white-box testing techniques that require accessing model internal information such as gradients, our technique approximates gradients through Differential Evolution and uses approximated gradients to construct adversarial samples. Experimental results show that our technique can achieve 100% success in generating adversarial samples to trigger misclassification, and over 95% success in generating samples to trigger misclassification to a specific target output label. It also demonstrates better perturbation distance and better transferability. Compared to the state-of-the-art black-box technique, our technique is more efficient. Furthermore, we conduct testing on the commercial Aliyun API and successfully trigger its misbehavior within a limited number of queries, demonstrating the feasibility of real-world black-box attack","Adversarial samples, Differential evolution, Black-box testing, Deep Neural Network",110767,,Journal of Systems and Software
65,@article: AUCH2020110669,Similarity-based analyses on software applications: A systematic literature review,Maximilian Auch and Manuel Weber and Peter Mandl and Christian Wolff,2020,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121220301278,https://doi.org/10.1016/j.jss.2020.110669,"In empirical studies on processes, practices, and techniques of software engineering, automation and machine learning are gaining popularity. In order to extract knowledge from existing software projects, a sort of similarity analysis is often performed using different methodologies, data and metadata. This systematic literature review focuses therefore on existing approaches of similarity-, categorization- and relevance-based analysis on software applications. In total, 136 relevant publications and patents were identified between 2002 and 2019 according to the established inclusion and exclusion criteria, which perform a calculation of software similarity in general or to support certain software engineering phases","Software similarity, Secondary study, Machine learning",110669,,Journal of Systems and Software
66,@article: SHARMA2021110936,Code smell detection by deep direct-learning and transfer-learning,Tushar Sharma and Vasiliki Efstathiou and Panos Louridas and Diomidis Spinellis,2021,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121221000339,https://doi.org/10.1016/j.jss.2021.110936,Contex,"Code smells, Smell detection tools, Deep learning, Transfer-learning",110936,,Journal of Systems and Software
67,@article: NGUYEN2021110860,Convolutional neural networks for enhanced classification mechanisms of metamodels,Phuong T. Nguyen and Davide {Di Ruscio} and Alfonso Pierantonio and Juri {Di Rocco} and Ludovico Iovino,2021,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121220302508,https://doi.org/10.1016/j.jss.2020.110860,"Conventional wisdom on Model-Driven Engineering suggests that metamodels are crucial elements for modeling environments consisting of graphical editors, transformations, code generators, and analysis tools. Software repositories are commonly used in practice for locating existing artifacts provided that a classification procedure is available. However, the manual classification of metamodel in repositories produces results that are influenced by the subjectivity of human perception besides being tedious and prone to errors. Therefore, automated techniques for classifying metamodels stored in repositories are highly desirable and stringent. In this work, we propose memoCNN as a novel approach to classification of metamodels. In particular, we consider metamodels as data points and classify them using supervised learning techniques. A convolutional neural network has been built to learn from labeled data, and use the trained weights to group unlabeled metamodels. A comprehensive experimental evaluation proves that the proposal effectively categorizes input data and outperforms a state-of-the-art baseline",,110860,,Journal of Systems and Software
68,@article: SHEN2020110728,From API to NLI: A new interface for library reuse,Qi Shen and Shijun Wu and Yanzhen Zou and Zixiao Zhu and Bing Xie,2020,,0164-1212,https://www.sciencedirect.com/science/article/pii/S016412122030162X,https://doi.org/10.1016/j.jss.2020.110728,"Developers frequently reuse APIs from existing libraries to implement certain functionality. However, learning APIs is difficult due to their large scale and complexity. In this paper, we design an abstract framework NLI2Code to ease the reuse process. Under the framework, users can reuse library functionalities with a high-level, automatically-generated NLI (Natural Language Interface) instead of the detailed API elements. The framework consists of three components: a functional feature extractor to summarize the frequently-used library functions in natural language form, a code pattern miner to give a code template for each functional feature, and a synthesizer to complete code patterns into well-typed snippets. From the perspective of a user, a reuse task under NLI2Code starts from choosing a functional feature and our framework will guide the user to synthesize the desired solution. We instantiated the framework as a tool to reuse Java libraries. The evaluation shows our tool can generate a high-quality natural language interface and save half of the coding time for newcomers to solve real-world programming tasks","Library reuse, Code pattern, Program synthesis",110728,,Journal of Systems and Software
69,@article: GAO2022111118,Sharing runtime permission issues for developers based on similar-app review mining,Hongcan Gao and Chenkai Guo and Guangdong Bai and Dengrong Huang and Zhen He and Yanfeng Wu and Jing Xu,2022,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121221002156,https://doi.org/10.1016/j.jss.2021.111118,"The Android operating system introduces an ask-on-first-use permission policy after 6.0 version to regulate access to user data, which raises Permission-Related Issues (PRIS for short). Relevant research has been conducted to identify the PRIS through investigating users’ opinions towards runtime permissions. These efforts mainly focus on helping users understand and be aware of permissions, but neglect to assist developers in discovering permission requirements. In this paper, we propose a novel framework named PRISharer, which mines potential permission issues from the reviews of similar apps to assist developers in discovering possible permission requirements at runtime. PRISharer first builds a deep fine-grained classifier to identify similar apps, and then employs sentiment analysis based keywords extraction to mine permission-related reviews from similar apps’ reviews. Finally, the <category, permission, issues> mappings based on a multi-label learning method are generated to provide a PRIS profile for developers. The results of comparative experiments on more than 12 million reviews of 17,741 Android apps demonstrate that PRISharer achieves (i) superior performance in terms of F1-score for PRIS analysis, with an average improvement of 24.4%, (ii) the best recall (89.3%) in extracting permission-related reviews and (iii) 82.4% positive responses by expert developers, through which the effectiveness of PRISharer is well verified","Android, Runtime permission, Permission-Related Issues (PRIS), User reviews, Machine learning",111118,,Journal of Systems and Software
70,@article: GOLZADEH2021110911,A ground-truth dataset and classification model for detecting bots in GitHub issue and PR comments,Mehdi Golzadeh and Alexandre Decan and Damien Legay and Tom Mens,2021,,0164-1212,https://www.sciencedirect.com/science/article/pii/S016412122100008X,https://doi.org/10.1016/j.jss.2021.110911,"Bots are frequently used in Github repositories to automate repetitive activities that are part of the distributed software development process. They communicate with human actors through comments. While detecting their presence is important for many reasons, no large and representative ground-truth dataset is available, nor are classification models to detect and validate bots on the basis of such a dataset. This paper proposes a ground-truth dataset, based on a manual analysis with high interrater agreement, of pull request and issue comments in 5,000 distinct Github accounts of which 527 have been identified as bots. Using this dataset we propose an automated classification model to detect bots, taking as main features the number of empty and non-empty comments of each account, the number of comment patterns, and the inequality between comments within comment patterns. We obtained a very high weighted average precision, recall and F1-score of 0.98 on a test set containing 40% of the data. We integrated the classification model into an open source command-line tool to allow practitioners to detect which accounts in a given Github repository actually correspond to bots","Distributed software development, Bot identification, GitHub repositories, Text similarity, Classification model",110911,,Journal of Systems and Software
71,@article: BI2021111005,Mining Architecture Tactics and Quality Attributes knowledge in Stack Overflow,Tingting Bi and Peng Liang and Antony Tang and Xin Xia,2021,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121221001023,https://doi.org/10.1016/j.jss.2021.111005,Contex,"Architecture Tactic, Quality Attribute, Knowledge mining, Empirical analysis, Stack Overflow",111005,,Journal of Systems and Software
72,@article: JIANG2021111027,Investigating and recommending co-changed entities for JavaScript programs,Zijian Jiang and Hao Zhong and Na Meng,2021,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121221001242,https://doi.org/10.1016/j.jss.2021.111027,"JavaScript (JS) is one of the most popular programming languages due to its flexibility and versatility, but maintaining JS code is tedious and error-prone. In our research, we conducted an empirical study to characterize the relationship between co-changed software entities (e.g., functions and variables), and built a machine learning (ML)-based approach to recommend additional entity to edit given developers’ code changes. Specifically, we first crawled 14,747 commits in 10 open-source projects; for each commit, we created at least one change dependency graph (CDG) to model the referencer–referencee relationship between co-changed entities. Next, we extracted the common subgraphs between CDGs to locate recurring co-change patterns between entities. Finally, based on those patterns, we extracted code features from co-changed entities and trained an ML model that recommends entities-to-change given a program commit. According to our empirical investigation, (1) three recurring patterns commonly exist in all projects; (2) 80%–90% of co-changed function pairs either invoke the same function(s), access the same variable(s), or contain similar statement(s); (3) our ML-based approach CoRec recommended entity changes with high accuracy (73%–78%). CoRec complements prior work because it suggests changes based on program syntax, textual similarity, as well as software history; it achieved higher accuracy than two existing tools in our evaluation","Multi-entity edit, Change suggestion, Machine learning, JavaScript",111027,,Journal of Systems and Software
73,@article: COTRONEO2021111043,Enhancing the analysis of software failures in cloud computing systems with deep learning,Domenico Cotroneo and Luigi {De Simone} and Pietro Liguori and Roberto Natella,2021,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121221001400,https://doi.org/10.1016/j.jss.2021.111043,"Identifying the failure modes of cloud computing systems is a difficult and time-consuming task, due to the growing complexity of such systems, and the large volume and noisiness of failure data. This paper presents a novel approach for analyzing failure data from cloud systems, in order to relieve human analysts from manually fine-tuning the data for feature engineering. The approach leverages Deep Embedded Clustering (DEC), a family of unsupervised clustering algorithms based on deep learning, which uses an autoencoder to optimize data dimensionality and inter-cluster variance. We applied the approach in the context of the OpenStack cloud computing platform, both on the raw failure data and in combination with an anomaly detection pre-processing algorithm. The results show that the performance of the proposed approach, in terms of purity of clusters, is comparable to, or in some cases even better than manually fine-tuned clustering, thus avoiding the need for deep domain knowledge and reducing the effort to perform the analysis. In all cases, the proposed approach provides better performance than unsupervised clustering when no feature engineering is applied to the data. Moreover, the distribution of failure modes from the proposed approach is closer to the actual frequency of the failure modes","Failure mode analysis, Software failures, Fault injection, Cloud computing, Deep learning, OpenStack",111043,,Journal of Systems and Software
74,@article: NAFI2020110491,A universal cross language software similarity detector for open source software categorization,Kawser Wazed Nafi and Banani Roy and Chanchal K. Roy and Kevin A. Schneider,2020,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121219302651,https://doi.org/10.1016/j.jss.2019.110491,"While there are novel approaches for detecting and categorizing similar software applications, previous research focused on detecting similarity in applications written in the same programming language and not on detecting similarity in applications written in different programming languages. Cross-language software similarity detection is inherently more challenging due to variations in language, application structures, support libraries used, and naming conventions. In this paper we propose a novel model, CroLSim, to detect similar software applications across different programming languages. We define a semantic relationship among cross-language libraries and API methods (both local and third party) using functional descriptions and a word-vector learning model. Our experiments show that CroLSim can successfully detect cross-language similar software applications, which outperforms all existing approaches (mean average precision rate of 0.65, confidence rate of 3.6, and 75% highly rated successful queries). Furthermore, we applied CroLSim to a source code repository to see whether our model can recommend cross-language source code fragments if queried directly with source code. From our experiments we found that CroLSim can recommend cross-language functional similar source code when source code is directly used as a query (average precision=0.28, recall=0.85, and F-Measure=0.40)","API Calls, Doc2Vec, Cross-Language software similarity detection, Singular value decomposition",110491,,Journal of Systems and Software
75,@article: XU2019110402,LDFR: Learning deep feature representation for software defect prediction,Zhou Xu and Shuai Li and Jun Xu and Jin Liu and Xiapu Luo and Yifeng Zhang and Tao Zhang and Jacky Keung and Yutian Tang,2019,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121219301761,https://doi.org/10.1016/j.jss.2019.110402,"Software Defect Prediction (SDP) aims to detect defective modules to enable the reasonable allocation of testing resources, which is an economically critical activity in software quality assurance. Learning effective feature representation and addressing class imbalance are two main challenges in SDP. Ideally, the more discriminative the features learned from the modules and the better the rescue performed on the imbalance issue, the more effective it should be in detecting defective modules. In this study, to solve these two challenges, we propose a novel framework named LDFR by Learning Deep Feature Representation from the defect data for SDP. Specifically, we use a deep neural network with a new hybrid loss function that consists of a triplet loss to learn a more discriminative feature representation of the defect data and a weighted cross-entropy loss to remedy the imbalance issue. To evaluate the effectiveness of the proposed LDFR framework, we conduct extensive experiments on a benchmark dataset with 27 defect data (each with three types of features), using three traditional and three effort-aware indicators. Overall, the experimental results demonstrate the superiority of our LDFR framework in detecting defective modules when compared with 27 baseline methods, except in terms of the indicator of Precision","Software defect prediction, Deep feature representation, Triplet loss, Weighted cross-entropy loss, Deep neural network",110402,,Journal of Systems and Software
76,@article: SOBHY2020110428,Run-time evaluation of architectures: A case study of diversification in IoT,Dalia Sobhy and Leandro Minku and Rami Bahsoon and Tao Chen and Rick Kazman,2020,,0164-1212,https://www.sciencedirect.com/science/article/pii/S016412121930202X,https://doi.org/10.1016/j.jss.2019.110428,"Run-time properties of modern software system environments, such as Internet of Things (IoT), are a challenge for existing software architecture evaluation methods. Such systems are largely data-driven, characterized by their dynamism, unpredictability in operation, hyper-connectivity, and scale. Properties, such as performance, delayed delivery, and scalability, are acknowledged to pose great risk and are difficult to evaluate at design-time. Run-time evaluation could potentially be used to complement design-time evaluation, enabling significant deviations from the expected performance values to be captured. However, there are no systematic software architecture evaluation methods that intertwine and interleave design-time and run-time evaluation. This paper addresses this gap by proposing a novel run-time architecture evaluation method suited for systems that exhibit uncertainty and dynamism in their operation. Our method uses machine learning and cost-benefit analysis at run-time to continuously profile the architecture decisions made, to assess their added value. We demonstrate the applicability and effectiveness of this approach in the context of an IoT system architecture, where some architecture design decisions were diversified to meet Quality of Service (QoS) requirements. Our approach provides run-time assessment for these decisions which can inform deployment, refinement, and/or phasing-out decisions","Run-time architecture evaluation, Runtime architecture evaluation, Software architectures for dynamic environments, Internet of things, IoT, Design diversity",110428,,Journal of Systems and Software
77,@article: ZHAO2022111108,Precise Learning of Source Code Contextual Semantics via Hierarchical Dependence Structure and Graph Attention Networks,Zhehao Zhao and Bo Yang and Ge Li and Huai Liu and Zhi Jin,2022,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121221002053,https://doi.org/10.1016/j.jss.2021.111108,"Deep learning is being used extensively in a variety of software engineering tasks, e.g., program classification and defect prediction. Although the technique eliminates the required process of feature engineering, the construction of source code model significantly affects the performance on those tasks. Most recent works was mainly focused on complementing AST-based source code models by introducing contextual dependencies extracted from CFG. However, all of them pay little attention to the representation of basic blocks, which are the basis of contextual dependencies. In this paper, we integrated AST and CFG and proposed a novel source code model embedded with hierarchical dependencies. Based on that, we also designed a neural network that depends on the graph attention mechanism. Specifically, we introduced the syntactic structural of the basic block, i.e., its corresponding AST, in source code model to provide sufficient information and fill the gap. We have evaluated this model on three practical software engineering tasks and compared it with other state-of-the-art methods. The results show that our model can significantly improve the performance. For example, compared to the best performing baseline, our model reduces the scale of parameters by 50% and achieves 4% improvement on accuracy on program classification task","Graph neural network, Program analysis, Deep learning, Abstract syntax Tree, Control flow graph",111108,,Journal of Systems and Software
78,@article: GENCNAYEBI2017207,A systematic literature review: Opinion mining studies from mobile app store user reviews,Necmiye Genc-Nayebi and Alain Abran,2017,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121216302291,https://doi.org/10.1016/j.jss.2016.11.027,"As mobile devices have overtaken fixed Internet access, mobile applications and distribution platforms have gained in importance. App stores enable users to search for, purchase and install mobile applications and then give feedback in the form of reviews and ratings. A review might contain information about the user’s experience with the app and opinion of it, feature requests and bug reports. Hence, reviews are valuable not only to users who would like to find out what others think about an app, but also to developers and software companies interested in customer feedback. The rapid increase in the number of applications and total app store revenue has accelerated app store data mining and opinion aggregation studies. While development companies and app store regulators have pursued upfront opinion mining studies for business intelligence and marketing purposes, research interest into app ecosystem and user reviews is relatively new. In addition to studies examining online product reviews, there are now some academic studies focused on mobile app stores and user reviews. The objectives of this systematic literature review are to identify proposed solutions for mining online opinions in app store user reviews, challenges and unsolved problems in the domain, any new contributions to software requirements evolution and future research direction","Mobile application, App stores opinion mining, Systematic literature review, Requirements engineering",207-219,,Journal of Systems and Software
79,@article: CONINCK201852,"DIANNE: a modular framework for designing, training and deploying deep neural networks on heterogeneous distributed infrastructure",Elias De Coninck and Steven Bohez and Sam Leroux and Tim Verbelen and Bert Vankeirsbilck and Pieter Simoens and Bart Dhoedt,2018,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121218300487,https://doi.org/10.1016/j.jss.2018.03.032,"Deep learning has shown tremendous results on various machine learning tasks, but the nature of the problems being tackled and the size of state-of-the-art deep neural networks often require training and deploying models on distributed infrastructure. DIANNE is a modular framework designed for dynamic (re)distribution of deep learning models and procedures. Besides providing elementary network building blocks as well as various training and evaluation routines, DIANNE focuses on dynamic deployment on heterogeneous distributed infrastructure, abstraction of Internet of Things (IoT) sensors, integration with external systems and graphical user interfaces to build and deploy networks, while retaining the performance of similar deep learning frameworks. In this paper the DIANNE framework is proposed as an all-in-one solution for deep learning, enabling data and model parallelism though a modular design, offloading to local compute power, and the ability to abstract between simulation and real environment","Artificial neural networks, Distributed applications, Machine learning, Internet of Things",52-65,,Journal of Systems and Software
80,@article: AGHAMOHAMMADI2020110800,Generating summaries for methods of event-driven programs: An Android case study,Alireza Aghamohammadi and Maliheh Izadi and Abbas Heydarnoori,2020,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121220302065,https://doi.org/10.1016/j.jss.2020.110800,"The lack of proper documentation makes program comprehension a cumbersome process for developers. Source code summarization is one of the existing solutions to this problem. Many approaches have been proposed to summarize source code in recent years. A prevalent weakness of these solutions is that they do not pay much attention to interactions among elements of software. An element is simply a callable code snippet such as a method or even a clickable button. As a result, these approaches cannot be applied to event-driven programs, such as Android applications, because they have specific features such as numerous interactions between their elements. To tackle this problem, we propose a novel approach based on deep neural networks and dynamic call graphs to generate summaries for methods of event-driven programs. First, we collect a set of comment/code pairs from Github and train a deep neural network on the set. Afterward, by exploiting a dynamic call graph, the Pagerank algorithm, and the pre-trained deep neural network, we generate summaries. An empirical evaluation with 14 real-world Android applications and 42 participants indicates 32.3% BLEU4 which is a definite improvement compared to the existing state-of-the-art techniques. We also assessed the informativeness and naturalness of our generated summaries from developers’ perspectives and showed they are sufficiently understandable and informative","Source code summarization, Neural machine translation, Event-driven programs, Deep learning",110800,,Journal of Systems and Software
81,@article: MOSTAEEN2020110686,A machine learning based framework for code clone validation,Golam Mostaeen and Banani Roy and Chanchal K. Roy and Kevin Schneider and Jeffrey Svajlenko,2020,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121220301394,https://doi.org/10.1016/j.jss.2020.110686,"A code clone is a pair of code fragments, within or between software systems that are similar. Since code clones often negatively impact the maintainability of a software system, several code clone detection techniques and tools have been proposed and studied over the last decade. However, the clone detection tools are not always perfect and their clone detection reports often contain a number of false positives or irrelevant clones from specific project management or user perspective. To detect all possible similar source code patterns in general, the clone detection tools work on the syntax level while lacking user-specific preferences. This often means the clones must be manually inspected before analysis in order to remove those false positives from consideration. This manual clone validation effort is very time-consuming and often error-prone, in particular for large-scale clone detection. In this paper, we propose a machine learning approach for automating the validation process. First, a training dataset is built by taking code clones from several clone detection tools for different subject systems and then manually validating those clones. Second, several features are extracted from those clones to train the machine learning model by the proposed approach. The trained algorithm is then used to automatically validate clones without human inspection. Thus the proposed approach can be used to remove the false positive clones from the detection results, automatically evaluate the precision of any clone detectors for any given set of datasets, evaluate existing clone benchmark datasets, or even be used to build new clone benchmarks and datasets with minimum effort. In an experiment with clones detected by several clone detectors in several different software systems, we found our approach has an accuracy of up to 87.4% when compared against the manual validation by multiple expert judges. The proposed method also shows better results in several comparative studies with the existing related approaches for clone classification","Code clones, Validation, Machine learning, Clone management",110686,,Journal of Systems and Software
82,@article: BORG2021102007,Video–based observation in impact evaluation,Simon Borg,2021,,0149-7189,https://www.sciencedirect.com/science/article/pii/S0149718921001026,https://doi.org/10.1016/j.evalprogplan.2021.102007,"This paper reviews the literature on the use of video–based observation (VBO) with particular attention to monitoring and evaluation (M&E) on development projects. While the use of video both as a research tool and as a strategy for supporting professional development is well–documented across several disciplines, the extent to which VBO has been utilized in M&E contexts is less clearly defined. In order to provide theoretically–grounded recommendations for the development and implementation of one organisation’s innovative VBO impact evaluation scheme, this review examines recent evidence of VBO in M&E contexts and draws on VBO literature more generally to identify its advantages and challenges together with advice for enhancing its effectiveness. Based on this analysis, the paper highlights a number of practical issues that should be considered when VBO is being developed for M&E in development contexts, particularly where videos are being made by participants themselves. The value of VBO in responding to COVID–19 and reducing carbon emissions is also noted","Video-based observation, Training, Impact, Evaluation, Professional development",102007,,Evaluation and Program Planning
83,@article: ENSMINGER2015124,Case study of an evaluation coaching model: Exploring the role of the evaluator,David C. Ensminger and Leanne M. Kallemeyn and Tania Rempert and James Wade and Megan Polanin,2015,,0149-7189,https://www.sciencedirect.com/science/article/pii/S014971891500004X,https://doi.org/10.1016/j.evalprogplan.2015.01.002,"This study examined the role of the external evaluator as a coach. More specifically, using an evaluative inquiry framework (Preskill and Torres, 1999a, Preskill and Torres, 1999b), it explored the types of coaching that an evaluator employed to promote individual, team and organizational learning. The study demonstrated that evaluation coaching provided a viable means for an organization with a limited budget to conduct evaluations through support of a coach. It also demonstrated how the coaching processes supported the development of evaluation capacity within the organization. By examining coaching models outside of the field of evaluation, this study identified two forms of coaching — results coaching and developmental coaching — that promoted evaluation capacity building and have not been previously discussed in the evaluation literature","Case study, Evaluation capacity building, Evaluation coaching, Evaluator role, Organizational learning",124-136,,Evaluation and Program Planning
84,@article: KOCAMAN2021100058,Spark NLP: Natural Language Understanding at Scale,Veysel Kocaman and David Talby,2021,,2665-9638,https://www.sciencedirect.com/science/article/pii/S2665963821000063,https://doi.org/10.1016/j.simpa.2021.100058,"Spark NLP is a Natural Language Processing (NLP) library built on top of Apache Spark ML. It provides simple, performant & accurate NLP annotations for machine learning pipelines that can scale easily in a distributed environment. Spark NLP comes with 1100+ pretrained pipelines and models in more than 192+ languages. It supports nearly all the NLP tasks and modules that can be used seamlessly in a cluster. Downloaded more than 2.7 million times and experiencing 9x growth since January 2020, Spark NLP is used by 54% of healthcare organizations as the world’s most widely used NLP library in the enterprise","Spark, Natural language processing, Deep learning, Tensorflow, Cluster",100058,,Software Impacts
85,@article: ZHAO2021100081,OpenICS: Open image compressive sensing toolbox and benchmark,Jonathan Zhao and Márk Lakatos-Tóth and Matthew Westerham and Zhikang Zhang and Avi Moskoff and Fengbo Ren,2021,,2665-9638,https://www.sciencedirect.com/science/article/pii/S2665963821000282,https://doi.org/10.1016/j.simpa.2021.100081,"The real-world application of image compressive sensing is largely limited by the lack of standardization in implementation and evaluation. To address this limitation, we present OpenICS, an image compressive sensing toolbox that implements multiple popular image compressive sensing algorithms into a unified framework with a standardized user interface. Furthermore, a corresponding benchmark is also proposed to provide a fair and complete evaluation of the implemented algorithms. We hope this work can serve the growing research community of compressive sensing and the industry to facilitate the development and application of image compressive sensing","Compressive sensing, Computer vision, Machine learning, Signal processing, Image processing",100081,,Software Impacts
86,@article: GUIBON2022100237,Few-shot emotion recognition in conversation with sequential prototypical networks,Gaël Guibon and Matthieu Labeau and Luce Lefeuvre and Chloé Clavel,2022,,2665-9638,https://www.sciencedirect.com/science/article/pii/S2665963822000100,https://doi.org/10.1016/j.simpa.2022.100237,"Detecting emotions in a conversational context benefits several industrial cases such as customer service, user appraisal from speech recognition, and so on. However, in most cases, research data differ from real data due to them being private, confidential, or difficult to label. In this work we present ProtoSeq, an adaptation of the Prototypical Networks to enable dealing with sequences in a few-shot learning way, reducing the need for labeling confidential data","Few-shot learning, Sequence labeling, Emotion recognition in conversation, Pytorch, Prototypical networks",100237,,Software Impacts
87,@article: KHAIRUDDIN2022100226,Web application with data centric approach to ship powering prediction using deep learning,Jauhari Khairuddin and Adi Maimun and Kazuo Hiekata and Chee Loon Siow and Arifah Ali,2022,,2665-9638,https://www.sciencedirect.com/science/article/pii/S2665963822000057,https://doi.org/10.1016/j.simpa.2022.100226,"This work describes an AI-based web application to predict passenger ship powering requirements. The data centric approach is developed based on the actual passenger ship design data as a design tool to assist naval architects to quickly estimate the ship brake power. It emphasised on the preliminary design stage to minimise design tasks and laborious calculations. Based on the study, it is observed that the model shows good agreement to the existing empirical method results with 10% mean absolute errors. Significantly, this presents the approach ability to facilitate faster and effective preliminary design, and scalability for large and complex systems","Ship design, Simulation, Artificial Intelligence, Deep Learning, Data centric, Web application",100226,,Software Impacts
88,@article: ELHACHIMI2022100240,Data Science Toolkit: An all-in-one python library to help researchers and practitioners in implementing data science-related algorithms with less effort,Chouaib {El Hachimi} and Salwa Belaqziz and Saïd Khabba and Abdelghani Chehbouni,2022,,2665-9638,https://www.sciencedirect.com/science/article/pii/S2665963822000124,https://doi.org/10.1016/j.simpa.2022.100240,"Data Science Toolkit (DST) is a python library built as a wrapper layer on top of several libraries to increase the abstraction level of the code, making its users more efficient and productive. The current version is widely used in our ongoing research activities that focus on optimizing agricultural management practices using artificial intelligence. DST adopts an object-oriented approach in implementing data science algorithms and is therefore composed of multiple classes such as the DataFrame class that adds additional functionalities to the standard pandas dataframe and the Model class that facilitates the building, training, and evaluation of machine learning models","Data science, Machine learning, Data processing, Data visualization, Data representation",100240,,Software Impacts
89,@article: SHEDLIGERI2021100064,CodedRecon: Video reconstruction for coded exposure imaging techniques,Prasan Shedligeri and Anupama S and Kaushik Mitra,2021,,2665-9638,https://www.sciencedirect.com/science/article/pii/S2665963821000129,https://doi.org/10.1016/j.simpa.2021.100064,"We present CodedRecon, a deep learning based framework for video reconstruction from coded exposure imaging techniques. It is a fully differentiable framework consisting of a coded exposure sensor simulation module and a deep-neural network module that learns to reconstruct the video sequence from the input coded exposure measurement. The reconstruction neural network is fully-convolutional and incorporates a spatially varying convolutional layer for exposure aware feature extraction from coded exposure measurements. The users can input measurements from both global and pixel-wise coded exposure techniques and reconstruct a video sequence with 16 frames per input measurement. The framework can be used for benchmarking various coded exposure techniques and the framework’s spatially varying convolutional layer can facilitate further research in the field","Computational photography, Video reconstruction, Coded exposure techniques",100064,,Software Impacts
90,@article: HASANI2022100210,"COV-ADSX: An Automated Detection System using X-ray Images, Deep Learning, and XGBoost for COVID-19",Sharif Hasani and Hamid Nasiri,2022,,2665-9638,https://www.sciencedirect.com/science/article/pii/S2665963821000932,https://doi.org/10.1016/j.simpa.2021.100210,"Following the COVID-19 pandemic, scientists have been looking for different ways to diagnose COVID-19, and these efforts have led to a variety of solutions. One of the common methods of detecting infected people is chest radiography. In this paper, an Automated Detection System using X-ray images (COV-ADSX) is proposed, which employs a deep neural network and XGBoost to detect COVID-19. COV-ADSX was implemented using the Django web framework, which allows the user to upload an X-ray image and view the results of the COVID-19 detection and image’s heatmap, which helps the expert to evaluate the chest area more accurately","Chest X-ray Images, COVID-19, Deep Neural Networks, DenseNet169, XGBoost",100210,,Software Impacts
91,@article: KIM2021100054,Open-source toolkit for end-to-end Korean speech recognition,Soohwan Kim and Seyoung Bae and Cheolhwang Won,2021,,2665-9638,https://www.sciencedirect.com/science/article/pii/S2665963821000026,https://doi.org/10.1016/j.simpa.2021.100054,"A modular and extensible end-to-end Korean automatic speech recognition (ASR) toolkit based on the deep learning library PyTorch called as KoSpeech11This paper is written based on our technical report available at: https://arxiv.org/abs/2009.03092. was released as an opensource software. Several ASR open-source toolkits have been released, but all of them deal with non-Korean languages. For this reason, The purpose of KoSpeech is to provide a customizable training environment for Korean ASR researchers. Furthermore, KoSpeech provides more than fifty options. Researchers can conveniently customize various hyperparameters. Because of these advantages, KoSpeech can be a very useful toolkit for Korean ASR researchers and could be a guideline for those who research Korean speech recognition","End-to-End (E2E), Korean, Automatic speech recognition (ASR), Open-source software, Speech processing",100054,,Software Impacts
92,@article: ALVAREZGONZALEZ2021100179,Emotion-Core: An Open Source framework for emotion detection research,Nurudin Alvarez-Gonzalez and Andreas Kaltenbrunner and Vicenç Gómez,2021,,2665-9638,https://www.sciencedirect.com/science/article/pii/S2665963821000774,https://doi.org/10.1016/j.simpa.2021.100179,"Identifying emotions from text is crucial for a variety of real world tasks. We describe Emotion-Core, an Open-Source framework for training, evaluating, and showcasing textual Emotion Detection models. Our framework is composed of two components: Emotion Classification and EmotionUI, which allow researchers to easily extend and reuse existing emotion detection solutions. We discuss the potential impact of our software project, including a recent publication in the findings of the International conference on Empirical Methods in Natural Language Processing (EMNLP 2021). Our code is available and free to use for interested researchers","Natural language processing, Emotion detection, Multilabel classification, Research showcase",100179,,Software Impacts
93,@article: BELOUSOV2021100115,MobileStyleGAN.pytorch: PyTorch-based toolkit to compress StyleGAN2 model,Sergei Belousov,2021,,2665-9638,https://www.sciencedirect.com/science/article/pii/S2665963821000452,https://doi.org/10.1016/j.simpa.2021.100115,"In recent years, the use of Generative Adversarial Networks (GANs) has become very popular in generative image modeling. While style-based GAN architectures yield state-of-the-art results in high-fidelity image synthesis, computationally, they are highly complex. In our work, we focus on the performance optimization of style-based generative models. We introduce an open-source toolkit called MobileStyleGAN.pytorch to compress the StyleGAN2 model","Image synthesis, StyleGAN, MobileStyleGAN, Generative Adversarial Networks, CNN compression",100115,,Software Impacts
94,@article: ZHANG2021103021,MeshingNet3D: Efficient generation of adapted tetrahedral meshes for computational mechanics,Zheyan Zhang and Peter K. Jimack and He Wang,2021,,0965-9978,https://www.sciencedirect.com/science/article/pii/S0965997821000508,https://doi.org/10.1016/j.advengsoft.2021.103021,"We describe a new algorithm for the generation of high quality tetrahedral meshes using artificial neural networks. The goal is to generate close-to-optimal meshes in the sense that the error in the computed finite element (FE) solution (for a target system of partial differential equations (PDEs)) is as small as it could be for a prescribed number of nodes or elements in the mesh. In this paper we illustrate and investigate our proposed approach by considering the equations of linear elasticity, solved on a variety of three-dimensional geometries. This class of PDE is selected due to its equivalence to an energy minimization problem, which therefore allows a quantitative measure of the relative accuracy of different meshes (by comparing the energy associated with the respective FE solutions on these meshes). Once the algorithm has been introduced it is evaluated on a variety of test problems, each with its own distinctive features and geometric constraints, in order to demonstrate its effectiveness and computational efficiency","Optimal mesh generation, Finite element methods, Machine learning, Artificial neural networks",103021,,Advances in Engineering Software
95,@article: SIM2021102957,GANs and DCGANs for generation of topology optimization validation curve through clustering analysis,Eun-A Sim and Seunghye Lee and Jeongmin Oh and Jaehong Lee,2021,,0965-9978,https://www.sciencedirect.com/science/article/pii/S0965997820310036,https://doi.org/10.1016/j.advengsoft.2020.102957,"This paper presents a novel combination of Generative Adversarial Networks (GANs) and Clustering Analysis (CA) for topology optimization. Based on the results from the topology analysis, new data are generated by the GANs and Deep Convolutional GANs (DCGANs). K-means Clustering Analysis is employed to select optimized valid data with the minimum compliance and the discreteness of design variables out of generated data through the GANs and the DCGANs. Finally, a Topology Optimization Validation Curve (TOVC) is successfully developed by collecting the optimized valid data through the entire volume fraction of the structure. The adaptability and the efficiency of the proposed method is verified for topology optimization of the well-known MBB beams","Generative adversarial networks, Clustering analysis, Topology optimization, Deep convolutional GANs, Topology optimization validation curve",102957,,Advances in Engineering Software
96,@article: HARNOUNE2021100042,BERT based clinical knowledge extraction for biomedical knowledge graph construction and analysis,Ayoub Harnoune and Maryem Rhanoui and Mounia Mikram and Siham Yousfi and Zineb Elkaimbillah and Bouchra {El Asri},2021,,2666-9900,https://www.sciencedirect.com/science/article/pii/S2666990021000410,https://doi.org/10.1016/j.cmpbup.2021.100042,"Background: Knowledge is evolving over time, often as a result of new discoveries or changes in the adopted methods of reasoning. Also, new facts or evidence may become available, leading to new understandings of complex phenomena. This is particularly true in the biomedical field, where scientists and physicians are constantly striving to find new methods of diagnosis, treatment and eventually cure. Knowledge Graphs (KGs) offer a real way of organizing and retrieving the massive and growing amount of biomedical knowledge. Objective: We propose an end-to-end approach for knowledge extraction and analysis from biomedical clinical notes using the Bidirectional Encoder Representations from Transformers (BERT) model and Conditional Random Field (CRF) layer. Methods: The approach is based on knowledge graphs, which can effectively process abstract biomedical concepts such as relationships and interactions between medical entities. Besides offering an intuitive way to visualize these concepts, KGs can solve more complex knowledge retrieval problems by simplifying them into simpler representations or by transforming the problems into representations from different perspectives. We created a biomedical Knowledge Graph using using Natural Language Processing models for named entity recognition and relation extraction. The generated biomedical knowledge graphs (KGs) are then used for question answering. Results: The proposed framework can successfully extract relevant structured information with high accuracy (90.7% for Named-entity recognition (NER), 88% for relation extraction (RE)), according to experimental findings based on real-world 505 patient biomedical unstructured clinical notes. Conclusions:In this paper, we propose a novel end-to-end system for the construction of a biomedical knowledge graph from clinical textual using a variation of BERT models","Knowledge graph, Biomedical informatics, Clinical data, Natural language processing, BERT",100042,,Computer Methods and Programs in Biomedicine Update
97,@article: SALVI2021100004,Impact of stain normalization and patch selection on the performance of convolutional neural networks in histological breast and prostate cancer classification,Massimo Salvi and Filippo Molinari and U Rajendra Acharya and Luca Molinaro and Kristen M. Meiburger,2021,,2666-9900,https://www.sciencedirect.com/science/article/pii/S2666990021000033,https://doi.org/10.1016/j.cmpbup.2021.100004,Backgrou,"Convolutional neural networks, Deep learning, Digital pathology, Image analysis, Pre-processing",100004,,Computer Methods and Programs in Biomedicine Update
98,@article: ALZUBAIDI2021100025,Role of deep learning in early detection of COVID-19: Scoping review,Mahmood Alzubaidi and Haider Dhia Zubaydi and Ali Abdulqader Bin-Salem and Alaa A Abd-Alrazaq and Arfan Ahmed and Mowafa Househ,2021,,2666-9900,https://www.sciencedirect.com/science/article/pii/S2666990021000240,https://doi.org/10.1016/j.cmpbup.2021.100025,Backgrou,"Deep learning, Machine learning, COVID-19, Coronavirus",100025,,Computer Methods and Programs in Biomedicine Update
99,@article: LAMBERTI2021100023,Blood cell classification using interpretable shape features: A Comparative study of SVM models and CNN-Based approaches,William Franz Lamberti,2021,,2666-9900,https://www.sciencedirect.com/science/article/pii/S2666990021000227,https://doi.org/10.1016/j.cmpbup.2021.100023,"Background and Objective: Models to count blood cells have been extensively studied, but there are very few for classifying potential blood cells. This is crucial for verifying that what these systems are counting are in fact the correct object of interest. Furthermore, we have very little insight into which features are important for differentiating these classes in computational models. Methods:This paper presents a competitive solution for classifying red blood cells, white blood cells, and platelets from each other. Results:We were able to achieve an overall classification rate of about 99% and outperformed convolutional neural networks by about 10% by using the Blood Cell Count Dataset with a support vector machine, a polynomial kernel, and interpretable and explainable features. Further, we are also able to identify that the important features for classifying the three classes are the number of corners, the proportion of the area of the cell over the relevant area the cell occupies, the major axis relative length of the cell, and the relevant area surrounding the cell. Conclusion: We built a model for blood cell classification that is more interpretable and explainable while also outperforming the state-of-the-art","Blood cell classification, Shape classification, Explainable machine learning",100023,,Computer Methods and Programs in Biomedicine Update
100,@article: HASAN2021100022,A Hybrid Method of Covid-19 Patient Detection from Modified CT-Scan/Chest-X-Ray Images Combining Deep Convolutional Neural Network And Two- Dimensional Empirical Mode Decomposition,Nahian Ibn Hasan,2021,,2666-9900,https://www.sciencedirect.com/science/article/pii/S2666990021000215,https://doi.org/10.1016/j.cmpbup.2021.100022,"The outbreak of the SARS-CoV-2/Covid-19 virus in 2019-2020 has made the world look for fast and accurate detection methods of the disease. The most commonly used tools for detecting Covid patients are Chest-X-ray or Chest-CT-scans of the patient. However, sometimes it’s hard for the physicians to diagnose the SARS-CoV-2 infection from the raw image. Moreover, sometimes, deep-learning-based techniques, using raw images, fail to detect the infection. Hence, this paper represents a hybrid method employing both traditional signal processing and deep learning technique for quick detection of SARS-CoV-2 patients based on the CT-scan and Chest-X-ray images of a patient. Unlike the other AI-based methods, here, a CT-scan/Chest-X-ray image is decomposed by two-dimensional Empirical Mode Decomposition (2DEMD), and it generates different orders of Intrinsic Mode Functions (IMFs). Next, The decomposed IMF signals are fed into a deep Convolutional Neural Network (CNN) for feature extraction and classification of Covid patients and Non-Covid patients. The proposed method is validated on three publicly available SARS-CoV-2 data sets using two deep CNN architectures. In all the databases, the modified CT-scan/Chest-X-ray image provides a better result than the raw image in terms of classification accuracy of two fundamental CNNs. This paper represents a new viewpoint of extracting preprocessed features from the raw image using 2DEMD","Two dimensional EMD, CNN, COVID-19, CT-Scan, Chest-X-Ray, Deep learning, IMF, Hybrid",100022,,Computer Methods and Programs in Biomedicine Update
101,@article: RAHMAN2021100015,IoT Enabled Automated Object Recognition for the Visually Impaired,Md. Atikur Rahman and Muhammad Sheikh Sadi,2021,,2666-9900,https://www.sciencedirect.com/science/article/pii/S2666990021000148,https://doi.org/10.1016/j.cmpbup.2021.100015,ABSTRA,"Object Recognition, Visually Impaired, Single Shot Detection, Internet of Things (IoT), Currency Recognition",100015,,Computer Methods and Programs in Biomedicine Update
102,@article: CALDERON2021100036,BILSK: A bilinear convolutional neural network approach for skin lesion classification,Camilo Calderón and Karen Sanchez and Sergio Castillo and Henry Arguello,2021,,2666-9900,https://www.sciencedirect.com/science/article/pii/S2666990021000355,https://doi.org/10.1016/j.cmpbup.2021.100036,"Background and objective: Skin lesions are areas of the dermis that have an abnormal growth or appearance compared to the surrounding area. They can be harmless such as a small scrape or severe as skin cancer. These dermis abnormalities increase in size over time and cause morbidity problems. Correct diagnosis of these skin lesions is crucial for successful treatment, which is generally too expensive. Convolutional neural networks (CNN) have been investigated for the classification of skin lesions with different training methods and techniques. However, the best results obtained by previous works show that there is a wide range to be achieved regarding detection, precision, and computational costs. Methods: Therefore, in this paper, we present a bilinear CNN approach capable of classifying seven skin lesions classes with the highest accuracy of the state-of-the-art and low computational cost. The framework proposed includes a data augmentation step to correct the data imbalance problem, transfer learning, and fine-tuning to improve the classification performance while reducing the computational cost. Several simulations were executed over the HAM10000 dataset. Results: The results show that a bilinear approach composed of the ResNet50 and the VGG16 architectures, increases accuracy by 2.7% compared to the state-of-the-art. Specifically, the proposed approach achieves an average of 0.9321 accuracy, 0.9292 precision, 0.9300 recall, 0.9321 F1 score, 0.9810 AUC, and requires 238.6 min for training. Conclusions: This performance increase can help to support the clinician diagnosis in order to provide a second opinion which can reduce the morbidity and treatment costs","Bilinear, Skin lesion, Neural network, Classification, Deep learning",100036,,Computer Methods and Programs in Biomedicine Update
103,@article: SAEEDIZADEH2021100007,COVID TV-Unet: Segmenting COVID-19 chest CT images using connectivity imposed Unet,Narges Saeedizadeh and Shervin Minaee and Rahele Kafieh and Shakib Yazdani and Milan Sonka,2021,,2666-9900,https://www.sciencedirect.com/science/article/pii/S2666990021000069,https://doi.org/10.1016/j.cmpbup.2021.100007,"The novel corona-virus disease (COVID-19) pandemic has caused a major outbreak in more than 200 countries around the world, leading to a severe impact on the health and life of many people globally. By October 2020, more than 44 million people were infected, and more than 1,000,000 deaths were reported. Computed Tomography (CT) images can be used as an alternative to the time-consuming RT-PCR test, to detect COVID-19. In this work we propose a segmentation framework to detect chest regions in CT images, which are infected by COVID-19. An architecture similar to a Unet model was employed to detect ground glass regions on a voxel level. As the infected regions tend to form connected components (rather than randomly distributed voxels), a suitable regularization term based on 2D-anisotropic total-variation was developed and added to the loss function. The proposed model is therefore called ”TV-Unet”. Experimental results obtained on a relatively large-scale CT segmentation dataset of around 900 images, incorporating this new regularization term leads to a 2% gain on overall segmentation performance compared to the Unet trained from scratch. Our experimental analysis, ranging from visual evaluation of the predicted segmentation results to quantitative assessment of segmentation performance (precision, recall, Dice score, and mIoU) demonstrated great ability to identify COVID-19 associated regions of the lungs, achieving a mIoU rate of over 99%, and a Dice score of around 86%","Deep learning, Computed tomography, COVID-19, Image segmentation, Convolutional encoder decoder, Total variation",100007,,Computer Methods and Programs in Biomedicine Update
104,@article: MAYYA2021100013,Automated microaneurysms detection for early diagnosis of diabetic retinopathy: A Comprehensive review,Veena Mayya and Sowmya {Kamath S․} and Uma Kulkarni,2021,,2666-9900,https://www.sciencedirect.com/science/article/pii/S2666990021000124,https://doi.org/10.1016/j.cmpbup.2021.100013,"Diabetic retinopathy (DR), a chronic disease in which the retina is damaged due to small vessel damage caused by diabetes mellitus, is one of the leading causes of vision impairment in diabetic patients. Detection of the earliest clinical sign of the advent of DR is a critical requirement for intervention and effective treatment. Ophthalmologists are trained to identify DR, based on examining specific minute changes in the eye - microaneurysms, retinal haemorrhages, macular edema and changes in the retinal blood vessels. Segmentation of microaneurysms (MA) is a critical requirement for the early diagnosis of DR and has been the primary focus of the research community over the past few years. In this work, a systematic review of existing literature is carried out to examine the diagnostic use of automated MA detection and segmentation for early DR diagnosis. We mainly focus on existing early DR diagnosis techniques to understand their strengths and weaknesses. Though early diagnosis is performed using colour fundus photography, fluorescein angiography or optical coherence tomography angiography images, our study is limited to colour fundus based techniques. The early DR diagnosis methodologies reviewed in this article can be broadly classified into classical image processing, conventional machine learning (ML), and deep learning (DL) based techniques. Though significant progress has been achieved in these three classes of early DR diagnosis, several challenges and gaps still exist, underscoring a considerable scope for the development of fully automated, user-friendly early DR diagnosis and grading systems. We discuss in detail the challenges that need to be addressed in designing such effective, efficient, and robust algorithms for early DR diagnosis systems and also the ample scope for future research in this area","Diabetic retinopathy, Microaneurysm segmentation, Automated detection, Healthcare informatics, Interpretability, Predictive analytics, Machine learning",100013,,Computer Methods and Programs in Biomedicine Update
105,@article: SHAHBAZ2015405,Automatic generation of valid and invalid test data for string validation routines using web searches and regular expressions,Muzammil Shahbaz and Phil McMinn and Mark Stevenson,2015,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642314001725,https://doi.org/10.1016/j.scico.2014.04.008,"Classic approaches to automatic input data generation are usually driven by the goal of obtaining program coverage and the need to solve or find solutions to path constraints to achieve this. As inputs are generated with respect to the structure of the code, they can be ineffective, difficult for humans to read, and unsuitable for testing missing implementation. Furthermore, these approaches have known limitations when handling constraints that involve operations with string data types. This paper presents a novel approach for generating string test data for string validation routines, by harnessing the Internet. The technique uses program identifiers to construct web search queries for regular expressions that validate the format of a string type (such as an email address). It then performs further web searches for strings that match the regular expressions, producing examples of test cases that are both valid and realistic. Following this, our technique mutates the regular expressions to drive the search for invalid strings, and the production of test inputs that should be rejected by the validation routine. The paper presents the results of an empirical study evaluating our approach. The study was conducted on 24 string input validation routines collected from 10 open source projects. While dynamic symbolic execution and search-based testing approaches were only able to generate a very low number of values successfully, our approach generated values with an accuracy of 34% on average for the case of valid strings, and 99% on average for the case of invalid strings. Furthermore, whereas dynamic symbolic execution and search-based testing approaches were only capable of detecting faults in 8 routines, our approach detected faults in 17 out of the 19 validation routines known to contain implementation errors","Test data generation, Web searches, Regular expressions",405-425,,Science of Computer Programming
106,@article: ALOMAR2022102693,SATDBailiff-mining and tracking self-admitted technical debt,Eman Abdullah AlOmar and Ben Christians and Mihal Busho and Ahmed Hamad AlKhalid and Ali Ouni and Christian Newman and Mohamed Wiem Mkaouer,2022,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642321000861,https://doi.org/10.1016/j.scico.2021.102693,"Self-Admitted Technical Debt (SATD) is a metaphorical concept to describe the self-documented addition of technical debt to a software project in the form of source code comments. SATD can linger in projects and degrade source-code quality, but it can also be more visible than unintentionally added or undocumented technical debt. Understanding the implications of adding SATD to a software project is important because developers can benefit from a better understanding of the quality trade-offs they are making. However, empirical studies, analyzing the survivability and removal of SATD comments, are challenged by potential code changes or SATD comment updates that may interfere with properly tracking their appearance, existence, and removal. In this paper, we propose SATDBailiff, a tool that uses an existing state-of-the-art SATD detection tool, to identify SATD in method comments, then properly track their lifespan. SATDBailiff is given as input links to open source projects, and its output is a list of all identified SATDs, and for each detected SATD, SATDBailiff reports all its associated changes, including any updates to its text, all the way to reporting its removal. The goal of SATDBailiff is to aid researchers and practitioners in better tracking SATDs instances, and providing them with a reliable tool that can be easily extended. SATDBailiff was validated using a dataset of previously detected and manually validated SATD instances. SATDBailiff is publicly available as an open source, along with the manual analysis of SATD instances associated with its validation, on the project website.11https://smilevo.github.io/self-affirmed-refactoring/SCP20_index.htm","Self-admitted technical debt, Mining software repositories",102693,,Science of Computer Programming
107,@article: KALLIS2021102598,Predicting issue types on GitHub,Rafael Kallis and Andrea {Di Sorbo} and Gerardo Canfora and Sebastiano Panichella,2021,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642320302069,https://doi.org/10.1016/j.scico.2020.102598,"Software maintenance and evolution involves critical activities for the success of software projects. To support such activities and keep code up-to-date and error-free, software communities make use of issue trackers, i.e., tools for signaling, handling, and addressing the issues occurring in software systems. However, in popular projects, tens or hundreds of issue reports are daily submitted. In this context, identifying the type of each submitted report (e.g., bug report, feature request, etc.) would facilitate the management and the prioritization of the issues to address. To support issue handling activities, in this paper, we propose Ticket Tagger, a GitHub app analyzing the issue title and description through machine learning techniques to automatically recognize the types of reports submitted on GitHub and assign labels to each issue accordingly. We empirically evaluated the tool's prediction performance on about 30,000 GitHub issues. Our results show that the Ticket Tagger can identify the correct labels to assign to GitHub issues with reasonably high effectiveness. Considering these results and the fact that the tool is designed to be easily integrated in the GitHub issue management process, Ticket Tagger consists in a useful solution for developers","Software maintenance and evolution, Issue reports management, Labeling unstructured data",102598,,Science of Computer Programming
108,@article: RAZAKH2021100789,PND: Physics-informed neural-network software for molecular dynamics applications,Taufeq Mohammed Razakh and Beibei Wang and Shane Jackson and Rajiv K. Kalia and Aiichiro Nakano and Ken-ichi Nomura and Priya Vashishta,2021,,2352-7110,https://www.sciencedirect.com/science/article/pii/S2352711021000972,https://doi.org/10.1016/j.softx.2021.100789,"We have developed PND, a differential equation solver software based on a physics-informed neural network (PINN) for molecular dynamics simulators. Based on automatic differentiation technique provided by PyTorch, our software allows users to flexibly implement equation of motion for atoms, initial and boundary conditions, and conservation laws as loss function to train the network. PND comes with a parallel molecular dynamic engine in order to examine and optimize loss function design, and different conservation laws and boundary conditions, and hyperparameters, thereby accelerating PINN-based development for molecular applications","Molecular dynamics, Machine learning, Differential equation solver",100789,,SoftwareX
109,@article: ARAQUE2022100921,GSITK: A sentiment analysis framework for agile replication and development,Oscar Araque and J. Fernando Sánchez-Rada and Carlos A. Iglesias,2022,,2352-7110,https://www.sciencedirect.com/science/article/pii/S2352711021001643,https://doi.org/10.1016/j.softx.2021.100921,"GSITK is a framework to perform a wide variety of sentiment analysis tasks, including dataset acquisition, text preprocessing, model design, and performance evaluation. The framework is oriented to both researchers and practitioners, easing the replication of previous sentiment models, as well as offering implementations of common tasks. This is achieved by building several abstractions on top of popular libraries such as scikit-learn and NLTK. In this way, GSITK allows users to implement complex sentiment pipelines using comprehensible Python code. The framework is Open Source and has been used successfully in several research projects and competitions","Sentiment analysis, Word embeddings, Machine learning, Natural language processing",100921,,SoftwareX
110,@article: LUCCHESE2020100614,RankEval: Evaluation and investigation of ranking models,Claudio Lucchese and Cristina Ioana Muntean and Franco Maria Nardini and Raffaele Perego and Salvatore Trani,2020,,2352-7110,https://www.sciencedirect.com/science/article/pii/S2352711020303277,https://doi.org/10.1016/j.softx.2020.100614,"RankEval is a Python open-source tool for the analysis and evaluation of ranking models based on ensembles of decision trees. Learning-to-Rank (LtR) approaches that generate tree-ensembles are considered the most effective solution for difficult ranking tasks and several impactful LtR libraries have been developed aimed at improving ranking quality and training efficiency. However, these libraries are not very helpful in terms of hyper-parameters tuning and in-depth analysis of the learned models, and even the implementation of most popular Information Retrieval (IR) metrics differ among them, thus making difficult to compare different models. RankEval overcomes these limitations by providing a unified environment where to perform an easy, comprehensive inspection and assessment of ranking models trained using different machine learning libraries. The tool focuses on ensuring efficiency, flexibility and extensibility and is fully interoperable with most popular LtR libraries","Learning to Rank, Evaluation, Analysis",100614,,SoftwareX
111,@article: MONTOYA2021100889,TreeTool: A tool for detecting trees and estimating their DBH using forest point clouds,Omar Montoya and Octavio Icasio-Hernández and Joaquín Salas,2021,,2352-7110,https://www.sciencedirect.com/science/article/pii/S2352711021001485,https://doi.org/10.1016/j.softx.2021.100889,"Trees’ inventory is an essential task in ecological assessment efforts in the fight against climate change. The diameter at breast height (DBH) of a tree is critical in forest inventory, particularly in estimating carbon content. This document presents TreeTool, a software tool written in Python to detect trees and measure their DBH from forest dense point clouds. The software performed acceptably against others in completeness, accuracy, location error, and diameter error benchmarks","Detecting trees, Dense point clouds, Segmentation, Forestry",100889,,SoftwareX
112,@article: SANDERS2019100347,Deep learning application engine (DLAE): Development and integration of deep learning algorithms in medical imaging,Jeremiah W. Sanders and Justin R. Fletcher and Steven J. Frank and Ho-Ling Liu and Jason M. Johnson and Zijian Zhou and Henry Szu-Meng Chen and Aradhana M. Venkatesan and Rajat J. Kudchadker and Mark D. Pagel and Jingfei Ma,2019,,2352-7110,https://www.sciencedirect.com/science/article/pii/S2352711019302535,https://doi.org/10.1016/j.softx.2019.100347,"Herein we introduce a deep learning (DL) application engine (DLAE) system concept, present potential uses of it, and describe pathways for its integration in clinical workflows. An open-source software application was developed to provide a code-free approach to DL for medical imaging applications. DLAE supports several DL techniques used in medical imaging, including convolutional neural networks, fully convolutional networks, generative adversarial networks, and bounding box detectors. Several example applications using clinical images were developed and tested to demonstrate the capabilities of DLAE. Additionally, a model deployment example was demonstrated in which DLAE was used to integrate two trained models into a commercial clinical software package","Medical imaging, Software, Deep learning, Algorithm development",100347,,SoftwareX
113,@article: MURAVYEV2022100956,tx2_fcnn_node: An open-source ROS compatible tool for monocular depth reconstruction,Kirill Muravyev and Andrey Bokovoy and Konstantin Yakovlev,2022,,2352-7110,https://www.sciencedirect.com/science/article/pii/S2352711021001837,https://doi.org/10.1016/j.softx.2021.100956,"We present tx2_fcnn_node – a Robot Operating System (ROS) compatible tool that is aimed at seamless integration of various monocular depth reconstruction neural networks to the robotic software based on ROS (which is a de-facto standard in the area of robotics). Our tool simplifies the process of deploying, evaluating, and comparing depth reconstruction neural networks both on real robots and in simulation. We complement our software with a set of the precompiled neural networks which can be used off the shelf, with some of them being able to demonstrate near real-time performance when running onboard compact embedded platforms, e.g. Nvidia Jetson TX2, that are often used nowadays both in academia and industry","Autonomous navigation, Robot operating system, Depth reconstruction, Vision-based simultaneous localization and mapping",100956,,SoftwareX
114,@article: RENAUD2020100462,iScore: An MPI supported software for ranking protein–protein docking models based on a random walk graph kernel and support vector machines,Nicolas Renaud and Yong Jung and Vasant Honavar and Cunliang Geng and Alexandre M.J.J. Bonvin and Li C. Xue,2020,,2352-7110,https://www.sciencedirect.com/science/article/pii/S2352711019303061,https://doi.org/10.1016/j.softx.2020.100462,"Computational docking is a promising tool to model three-dimensional (3D) structures of protein–protein complexes, which provides fundamental insights of protein functions in the cellular life. Singling out near-native models from the huge pool of generated docking models (referred to as the scoring problem) remains as a major challenge in computational docking. We recently published iScore, a novel graph kernel based scoring function. iScore ranks docking models based on their interface graph similarities to the training interface graph set. iScore uses a support vector machine approach with random-walk graph kernels to classify and rank protein–protein interfaces. Here, we present the software for iScore. The software provides executable scripts that fully automate the computational workflow. In addition, the creation and analysis of the interface graph can be distributed across different processes using Message Passing interface (MPI) and can be offloaded to GPUs thanks to dedicated CUDA kernels","Protein–protein docking, Scoring, Graph kernel functions, Support vector machines, MPI, Position-specific scoring matrix (PSSM)",100462,,SoftwareX
115,@article: ZARSKI2021100893,KrakN: Transfer Learning framework and dataset for infrastructure thin crack detection,Mateusz Żarski and Bartosz Wójcik and Jarosław Adam Miszczak,2021,,2352-7110,https://www.sciencedirect.com/science/article/pii/S2352711021001503,https://doi.org/10.1016/j.softx.2021.100893,"Monitoring the technical condition of infrastructure is a crucial element of its maintenance. Although there are many deep learning models intended for this purpose, they are severely limited in their application due to labour-intensive gathering of new datasets and high demand for computing power during model training. To overcome these limiting factors we propose a KrakN framework. It enables end-to-end development of unique infrastructure defect detectors on digital images, achieving an accuracy of above 90%. The framework also supports the semi-automatic creation of new datasets and has modest computing power requirements. It can be used to immediately implement deep learning in the process of infrastructure management and, due to its architecture based on transfer learning, allows low metric loss when used across different datasets. We also demonstrate that thanks to its scalability and modular structure, the presented framework is easily modifiable, and can be used in realistic scenarios","Infrastructure maintenance, Structural health monitoring, Deep learning, Transfer learning",100893,,SoftwareX
116,@article: JUNG2021100795,AniLength: GUI-based automatic worm length measurement software using image processing and deep neural network,Sang-Kyu Jung,2021,,2352-7110,https://www.sciencedirect.com/science/article/pii/S235271102100100X,https://doi.org/10.1016/j.softx.2021.100795,"Accurately measuring the length of an animal’s body is essential to studying the effects of various chemicals, genes, and the environment on the animal’s growth. AniLength was developed to measure the body length of small worms present in images using hybrid image processing and deep neural network (DNN)-based image classification. The software not only includes a pretrained DNN model learned from approximately 16,000 images using ResNet-V2-101 for Caenorhabditis elegans analysis, but it can also perform new training using custom training images. AniLength is a user-friendly GUI-based software that runs on Microsoft Windows","Body length, Deep learning, Image analysis, Worm",100795,,SoftwareX
117,@article: AHMAD2021100854,MicroVIP: Microscopy image simulation on the Virtual Imaging Platform,Ali Ahmad and Guillaume Vanel and Sorina Camarasu-Pop and Axel Bonnet and Carole Frindel and David Rousseau,2021,,2352-7110,https://www.sciencedirect.com/science/article/pii/S235271102100131X,https://doi.org/10.1016/j.softx.2021.100854,"MicroVIP is an open source software that assembles, in a unified web-application running on distributed computing resources, simulators of the main fluorescent microscopy imaging modalities (with existing codes or newly developed). MicroVIP provides realistic simulated images including several sources of noise (microfluidic blur effect, diffraction, Poisson noise, camera read out noise). MicroVIP also includes a module which simulates single cells with fluorescent markers and a module to analyze the simulated images with textural and pointillist feature spaces. MicroVIP is shown to be of value for supervised machine learning. It allow to automatically generate large sets of training images and virtual instrumentation to optimize the optical parameters before realizing real experiments","Microscopy image simulation, Virtual Imaging Platform, Machine learning",100854,,SoftwareX
118,@article: ALVESOLIVEIRA2020100461,"Software architecture for YOLO, a creativity-stimulating robot",Patrícia Alves-Oliveira and Samuel Gomes and Ankita Chandak and Patrícia Arriaga and Guy Hoffman and Ana Paiva,2020,,2352-7110,https://www.sciencedirect.com/science/article/pii/S2352711019302468,https://doi.org/10.1016/j.softx.2020.100461,"YOLO is a social robot designed and developed to stimulate creativity in children through storytelling activities. Children use it as a character in their stories. This article details the artificial intelligence software developed for YOLO. The implemented software schedules through several Creativity Behaviors to find the ones that stimulate creativity more effectively. YOLO can choose between convergent and divergent thinking techniques, two important processes of creative thought. These techniques were developed based on the psychological theories of creativity development and on research from creativity experts who work with children. Besides promoting creativity, this software allows the creation of Social Behaviors that enable the robot to behave as a believable character. We built 3 main social behavior parameters: Exuberant, Aloof, and Harmonious. These behaviors are meant to ease immersive play and the process of character creation. The 3 social behaviors were based on psychological theories of personality and developed using children’s input during co-design studies. Overall, this work presents the design, development, and usage of social robots that might nurture intrinsic human abilities, such as the ability to be creative","Social robotics, Artificial intelligence, Human–robot interaction, Creativity, Open software",100461,,SoftwareX
119,@article: ZENG2020105700,Generating diagnostic report for medical image by high-middle-level visual information incorporation on double deep learning models,Xianhua Zeng and Li Wen and Yang Xu and Conghui Ji,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260720315339,https://doi.org/10.1016/j.cmpb.2020.105700,"Background and objectives: Writing diagnostic reports for medical images is a heavy and tedious work. The automatic generation of medical image diagnostic reports can assist doctors to reduce their workload and improve diagnosis efficiency. It is of great significance to introduce image caption algorithm into medical image processing. Existing approaches attempt to generate medical image diagnostic reports using image caption algorithms but without taking the accuracy of pathological information in generated diagnostic reports into account. Methods: To solve the mentioned problem, we propose a Semantic Fusion Network (SFNet) including a lesion area detection model and a diagnostic generation model. The lesion area detection model can extract visual and pathological information from medical image, and the diagnostic report generation model can learn to fuse the two kinds of information to generate reports. Thus, the pathological information in the generated diagnostic reports can be more accurate. Results: Experimental results have verified the performance of our model (Accuracy increases 1.2% on the Ultrasound Image Dataset and 2.4% on the Open-i X-ray Image Dataset), compared with the model only using visual feature to generate diagnostic reports. Conclusions: This work utilizes computer algorithms to generate the more accurate diagnostic reports for medical images automatically, which expands the application of computer-aided diagnosis and promotes the implementation of deep learning in the medical image analysis field","Image caption, Medical image, Object detection, Pathological information, Computer-aided diagnosis",105700,,Computer Methods and Programs in Biomedicine
120,@article: KARTHIK2020105728,Neuroimaging and deep learning for brain stroke detection - A review of recent advancements and future prospects,R. Karthik and R. Menaka and Annie Johnson and Sundar Anand,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260720315613,https://doi.org/10.1016/j.cmpb.2020.105728,Background and objecti,"Stroke, CNN, FCN, Deep learning, Lesion, Detection, Segmentation",105728,,Computer Methods and Programs in Biomedicine
121,@article: CAO2021106033,Breast mass detection in digital mammography based on anchor-free architecture,Haichao Cao and Shiliang Pu and Wenming Tan and Junyan Tong,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721001085,https://doi.org/10.1016/j.cmpb.2021.106033,Background and objecti,"Breast mass detection, Anchor-free architecture, Image enhancement method, Data augmentation method, Training method",106033,,Computer Methods and Programs in Biomedicine
122,@article: SHI2022106615,Domain adaptation based on rough adjoint inconsistency and optimal transport for identifying autistic patients,Chun-lei Shi and Xian-wei Xin and Jia-cai Zhang,2022,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721006891,https://doi.org/10.1016/j.cmpb.2021.106615,Background and Objecti,"Autism spectrum disorder, Domain adaptation, Rough adjoint inconsistency, Optimal transport",106615,,Computer Methods and Programs in Biomedicine
123,@article: YANG2019A1,Deep into Patient care: An automated deep learning approach for reshaping patient care in clinical setting,Hsuan-Chia Yang and Tahmina Nasrin Poly and Yu-Chuan {(Jack) Li,2019,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260718317097,https://doi.org/10.1016/j.cmpb.2018.11.007,,,A1-A2,,Computer Methods and Programs in Biomedicine
124,@article: YASIN2021106007,EEG based Major Depressive disorder and Bipolar disorder detection using Neural Networks:A review,Sana Yasin and Syed Asad Hussain and Sinem Aslan and Imran Raza and Muhammad Muzammel and Alice Othmani,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721000821,https://doi.org/10.1016/j.cmpb.2021.106007,"Mental disorders represent critical public health challenges as they are leading contributors to the global burden of disease and intensely influence social and financial welfare of individuals. The present comprehensive review concentrate on the two mental disorders: Major depressive Disorder (MDD) and Bipolar Disorder (BD) with noteworthy publications during the last ten years. There is a big need nowadays for phenotypic characterization of psychiatric disorders with biomarkers. Electroencephalography (EEG) signals could offer a rich signature for MDD and BD and then they could improve understanding of pathophysiological mechanisms underling these mental disorders. In this review, we focus on the literature works adopting neural networks fed by EEG signals. Among those studies using EEG and neural networks, we have discussed a variety of EEG based protocols, biomarkers and public datasets for depression and bipolar disorder detection. We conclude with a discussion and valuable recommendations that will help to improve the reliability of developed models and for more accurate and more deterministic computational intelligence based systems in psychiatry. This review will prove to be a structured and valuable initial point for the researchers working on depression and bipolar disorders recognition by using EEG signals","Electroencephalogram(EEG), Major Depressive disorder(MDD), Bipolar disorder(BD), Artificial neural networks, biomedical informatics",106007,,Computer Methods and Programs in Biomedicine
125,@article: DURSUN2021106279,Development of convolutional neural networks for recognition of tenogenic differentiation based on cellular morphology,Gözde Dursun and Saurabh Balkrishna Tandale and Rutwik Gulakala and Jörg Eschweiler and Mersedeh Tohidnezhad and Bernd Markert and Marcus Stoffel,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721003539,https://doi.org/10.1016/j.cmpb.2021.106279,"Background and objective: The use of automated systems for image recognition is highly preferred for regenerative medicine applications to evaluate stem cell differentiation early in the culturing state with non-invasive methodologies instead of invasive counterparts. Bone marrow-derived mesenchymal stem cells (BMSCs) are able to differentiate into desired cell phenotypes, and thereby promise a proper cell source for tendon regeneration. The therapeutic success of stem cell therapy requires cellular characterization prior to the implantation of cells. The foremost problem is that traditional characterization techniques require cellular material which would be more useful for cell therapy, complex laboratory procedures, and human expertise. Convolutional neural networks (CNNs), a class of deep neural networks, have recently made great improvements in image-based classifications, recognition, and detection tasks. We, therefore, aim to develop a potential CNN model in order to recognize differentiated stem cells by learning features directly from image data of unlabelled cells. Methods: The differentiation of bone marrow mesenchymal stem cells (BMSCs) into tenocytes was induced with the treatment of bone morphogenetic protein-12 (BMP-12). Following the treatment and incubation step, the phase-contrast images of cells were obtained and immunofluorescence staining has been applied to characterize the differentiated state of BMSCs. CNN models were developed and trained with the phase-contrast cell images. The comparison of CNN models was performed with respect to prediction performance and training time. Moreover, we have evaluated the effect of image enhancement method, data augmentation, and fine-tuning training strategy to increase classification accuracy of CNN models. The best model was integrated into a mobile application. Results: All the CNN models can fit the biological data extracted from immunofluorescence characterization. CNN models enable the cell classification with satisfactory accuracies. The best result in terms of accuracy and training time is achieved by the model proposed based on Inception-ResNet V2 trained from scratch using image enhancement and data augmentation strategies (96.80%, 434.55 sec). Conclusion: Our study reveals that the CNN models show good performance by identifying stem cell differentiation. Importantly this technique provides a faster and real-time tool in comparison to traditional methods enabling the adjustment of culture conditions during cultivation to improve the yield of therapeutic stem cells","Convolutional neural network, Image recognition, Stem cell differentiation",106279,,Computer Methods and Programs in Biomedicine
126,@article: SHEN2021106019,Mass Image Synthesis in Mammogram with Contextual Information Based on GANs,Tianyu Shen and Kunkun Hao and Chao Gou and Fei-Yue Wang,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721000948,https://doi.org/10.1016/j.cmpb.2021.106019,"Background and Objective: In medical imaging, the scarcity of labeled lesion data has hindered the application of many deep learning algorithms. To overcome this problem, the simulation of diverse lesions in medical images is proposed. However, synthesizing labeled mass images in mammograms is still challenging due to the lack of consistent patterns in shape, margin, and contextual information. Therefore, we aim to generate various labeled medical images based on contextual information in mammograms. Methods:In this paper, we propose a novel approach based on GANs to generate various mass images and then perform contextual infilling by inserting the synthetic lesions into healthy screening mammograms. Through incorporating features of both realistic mass images and corresponding masks into the adversarial learning scheme, the generator can not only learn the distribution of the real mass images but also capture the matching shape, margin and context information. Results:To demonstrate the effectiveness of our proposed method, we conduct experiments on publicly available mammogram database of DDSM and a private database provided by Nanfang Hospital in China. Qualitative and quantitative evaluations validate the effectiveness of our approach. Additionally, through the data augmentation by image generation of the proposed method, an improvement of 5.03% in detection rate can be achieved over the same model trained on original real lesion images. Conclusions:The results show that the data augmentation based on our method increases the diversity of dataset. Our method can be viewed as one of the first steps toward generating labeled breast mass images for precise detection and can be extended in other medical imaging domains to solve similar problems","medical image synthesis, generative adversarial network, mammogram, mass detection",106019,,Computer Methods and Programs in Biomedicine
127,@article: SEO2021106424,A personalized blood glucose level prediction model with a fine-tuning strategy: A proof-of-concept study,Wonju Seo and Sung-Woon Park and Namho Kim and Sang-Man Jin and Sung-Min Park,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721004983,https://doi.org/10.1016/j.cmpb.2021.106424,Backgrou,"Diabetes, Deep neural network, Continuous glucose monitoring, Data-driven approach, Blood glucose management",106424,,Computer Methods and Programs in Biomedicine
128,@article: LI2021106048,Development of a deep learning-based image quality control system to detect and filter out ineligible slit-lamp images: A multicenter study,Zhongwen Li and Jiewei Jiang and Kuan Chen and Qinxiang Zheng and Xiaotian Liu and Hongfei Weng and Shanjun Wu and Wei Chen,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721001231,https://doi.org/10.1016/j.cmpb.2021.106048,Background and objecti,"Artificial intelligence, Deep learning, Image quality, Slit lamp",106048,,Computer Methods and Programs in Biomedicine
129,@article: YAN2020105528,Automated gleason grading on prostate biopsy slides by statistical representations of homology profile,Chaoyang Yan and Kazuaki Nakane and Xiangxue Wang and Yao Fu and Haoda Lu and Xiangshan Fan and Michael D. Feldman and Anant Madabhushi and Jun Xu,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260719316001,https://doi.org/10.1016/j.cmpb.2020.105528,"Background and Objective:Gleason grading system is currently the clinical gold standard for determining prostate cancer aggressiveness. Prostate cancer is typically classified into one of 5 different categories with 1 representing the most indolent disease and 5 reflecting the most aggressive disease. Grades 3 and 4 are the most common and difficult patterns to be discriminated in clinical practice. Even though the degree of gland differentiation is the strongest determinant of Gleason grade, manual grading is subjective and is hampered by substantial inter-reader disagreement, especially with regard to intermediate grade groups. Methods:To capture the topological characteristics and the degree of connectivity between nuclei around the gland, the concept of Homology Profile (HP) for prostate cancer grading is presented in this paper. HP is an algebraic tool, whereby, certain algebraic invariants are computed based on the structure of a topological space. We utilized the Statistical Representation of Homology Profile (SRHP) features to quantify the extent of glandular differentiation. The quantitative characteristics which represent the image patch are fed into a supervised classifier model for discrimination of grade patterns 3 and 4. Results:On the basis of the novel homology profile, we evaluated 43 digitized images of prostate biopsy slides annotated for regions corresponding to Grades 3 and 4. The quantitative patch-level evaluation results showed that our approach achieved an Area Under Curve (AUC) of 0.96 and an accuracy of 0.89 in terms of discriminating Grade 3 and 4 patches. Our approach was found to be superior to comparative methods including handcrafted cellular features, Stacked Sparse Autoencoder (SSAE) algorithm and end-to-end supervised learning method (DLGg). Also, slide-level quantitative and qualitative evaluation results reflect the ability of our approach in discriminating Gleason Grade 3 from 4 patterns on H&E tissue images. Conclusions:We presented a novel Statistical Representation of Homology Profile (SRHP) approach for automated Gleason grading on prostate biopsy slides. The most discriminating topological descriptions of cancerous regions for grade 3 and 4 in prostate cancer were identified. Moreover, these characteristics of homology profile are interpretable, visually meaningful and highly consistent with the rubric employed by pathologists for the task of Gleason grading","Prostate cancer, Gleason grading, Digitized needle biopsy samples, Homology Profile, Statistical representation",105528,,Computer Methods and Programs in Biomedicine
130,@article: MAHBOD2020105725,The effects of skin lesion segmentation on the performance of dermatoscopic image classification,Amirreza Mahbod and Philipp Tschandl and Georg Langs and Rupert Ecker and Isabella Ellinger,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260720315583,https://doi.org/10.1016/j.cmpb.2020.105725,Background and Objecti,"Skin cancer, dermatoscopy, medical image analysis, deep learning, effect of segmentation on classification",105725,,Computer Methods and Programs in Biomedicine
131,@article: GUO2021106124,"Automatic analysis system of calcaneus radiograph: Rotation-invariant landmark detection for calcaneal angle measurement, fracture identification and fracture region segmentation",Jia Guo and Yuxuan Mu and Dong Xue and Huiqi Li and Junxian Chen and Huanxin Yan and Hailin Xu and Wei Wang,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721001991,https://doi.org/10.1016/j.cmpb.2021.106124,Background and objecti,"Calcaneus fractures, Calcaneus radiograph, Landmark detection, Fracture detection, Convolutional neural network, Image segmentation",106124,,Computer Methods and Programs in Biomedicine
132,@article: ELGENDY2021106112,A Novel Marker Detection System for People with Visual Impairment Using the Improved Tiny-YOLOv3 Model,Mostafa Elgendy and Cecilia Sik-Lanyi and Arpad Kelemen,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721001875,https://doi.org/10.1016/j.cmpb.2021.106112,Background and Objecti,"Assistive technology, Visually impaired, Indoor navigation, Markers, Deep learning, Tiny-YOLOv3",106112,,Computer Methods and Programs in Biomedicine
133,@article: HUANG2021106480,Deep learning network for medical volume data segmentation based on multi axial plane fusion,Bo Huang and Ziran Wei and Xianhua Tang and Hamido Fujita and Qingping Cai and Yongbin Gao and Tao Wu and Liang Zhou,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S016926072100554X,https://doi.org/10.1016/j.cmpb.2021.106480,"Background and Objective: High-dimensional data generally contains more accurate information for medical image, e.g., computerized tomography (CT) data can depict the three dimensional structure of organs more precisely. However, the data in high-dimension often needs enormous computation and has high memory requirements in the deep learning convolution networks, while dimensional reduction usually leads to performance degradation. Methods: In this paper, a two-dimensional deep learning segmentation network was proposed for medical volume data based on multi-pinacoidal plane fusion to cover more information under the control of computation.This approach has conducive compatibility while using the model proposed to extract the global information between different inputs layers. Results: Our approach has worked in different backbone network. Using the approach, DeepUnet’s Dice coefficient (Dice) and Positive Predictive Value (PPV) are 0.883 and 0.982 showing the satisfied progress. Various backbones can enjoy the profit of the method. Conclusions: Through the comparison of different backbones, it can be found that the proposed network with multi-pinacoidal plane fusion can achieve better results both quantitively and qualitatively","Convolutional neural networks, Image segmentation, Computerized tomography, Feature fusion",106480,,Computer Methods and Programs in Biomedicine
134,@article: MARZULLO2021105834,Towards realistic laparoscopic image generation using image-domain translation,Aldo Marzullo and Sara Moccia and Michele Catellani and Francesco Calimeri and Elena De Momi,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260720316679,https://doi.org/10.1016/j.cmpb.2020.105834,"Background and ObjectivesOver the last decade, Deep Learning (DL) has revolutionized data analysis in many areas, including medical imaging. However, there is a bottleneck in the advancement of DL in the surgery field, which can be seen in a shortage of large-scale data, which in turn may be attributed to the lack of a structured and standardized methodology for storing and analyzing surgical images in clinical centres. Furthermore, accurate annotations manually added are expensive and time consuming. A great help can come from the synthesis of artificial images; in this context, in the latest years, the use of Generative Adversarial Neural Networks (GANs) achieved promising results in obtaining photo-realistic images. MethodsIn this study, a method for Minimally Invasive Surgery (MIS) image synthesis is proposed. To this aim, the generative adversarial network pix2pix is trained to generate paired annotated MIS images by transforming rough segmentation of surgical instruments and tissues into realistic images. An additional regularization term was added to the original optimization problem, in order to enhance realism of surgical tools with respect to the background. Results Quantitative and qualitative (i.e., human-based) evaluations of generated images have been carried out in order to assess the effectiveness of the method. ConclusionsExperimental results show that the proposed method is actually able to translate MIS segmentations to realistic MIS images, which can in turn be used to augment existing data sets and help at overcoming the lack of useful images; this allows physicians and algorithms to take advantage from new annotated instances for their training","Generative Adversarial Networks, Minimally Invasive Surgery, Image translation, Data Augmentation",105834,,Computer Methods and Programs in Biomedicine
135,@article: ZHENG2022106602,Phonetic posteriorgram-based voice conversion system to improve speech intelligibility of dysarthric patients,Wei-Zhong Zheng and Ji-Yan Han and Chen-Kai Lee and Yu-Yi Lin and Shu-Han Chang and Ying-Hui Lai,2022,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721006763,https://doi.org/10.1016/j.cmpb.2021.106602,Background and Objecti,"Dysarthric patient, Deep learning, Voice conversion, Phonetic posteriorgram",106602,,Computer Methods and Programs in Biomedicine
136,@article: CHOI2021106251,Video recognition of simple mastoidectomy using convolutional neural networks: Detection and segmentation of surgical tools and anatomical regions,Joonmyeong Choi and Sungman Cho and Jong Woo Chung and Namkug Kim,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721003254,https://doi.org/10.1016/j.cmpb.2021.106251,"A simple mastoidectomy is used to remove inflammation of the mastoid cavity and to create a route to the skull base and middle ear. However, due to the complexity and difficulty of the simple mastoidectomy, implementing robot vision for assisted surgery is a challenge. To overcome this issue using a convolutional neural network architecture in a surgical environment, each surgical instrument and anatomical region must be distinguishable in real time. To meet this condition, we used the latest instance segmentation architecture, YOLACT. In this study, a data set comprising 5,319 extracted frames from 70 simple mastoidectomy surgery videos were used. Six surgical tools and five anatomic regions were identified for the training. The YOLACT-based model in the surgical environment was trained and evaluated for real-time object detection and semantic segmentation. Detection accuracies of surgical tools and anatomic regions were 91.2% and 56.5% in mean average precision, respectively. Additionally, the dice similarity coefficient metric for segmentation of the five anatomic regions was 48.2%. The mean frames per second of this model was 32.3, which is sufficient for real-time robotic applications","Anatomical region, Object detection, Semantic segmentation, Simple mastoidectomy, Surgical tool",106251,,Computer Methods and Programs in Biomedicine
137,@article: BONAVITA2020105172,Integration of convolutional neural networks for pulmonary nodule malignancy assessment in a lung cancer classification pipeline,Ilaria Bonavita and Xavier Rafael-Palou and Mario Ceresa and Gemma Piella and Vicent Ribas and Miguel A. {González Ballester},2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260719300975,https://doi.org/10.1016/j.cmpb.2019.105172,Background and Objecti,"Lung cancer, Nodule malignancy, Deep learning, Machine learning",105172,,Computer Methods and Programs in Biomedicine
138,@article: ALMASNI2020105351,Multiple skin lesions diagnostics via integrated deep convolutional networks for segmentation and classification,Mohammed A. Al-masni and Dong-Hyun Kim and Tae-Seong Kim,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260719321698,https://doi.org/10.1016/j.cmpb.2020.105351,Background and objecti,"CAD, Classification, CNN, Deep learning, ISIC, Melanoma, Skin lesion, Segmentation",105351,,Computer Methods and Programs in Biomedicine
139,@article: BLANCO2020105264,Boosting ICD multi-label classification of health records with contextual embeddings and label-granularity,Alberto Blanco and Olatz Perez-de-Viñaspre and Alicia Pérez and Arantza Casillas,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260719311745,https://doi.org/10.1016/j.cmpb.2019.105264,"Background and objective:This work deals with clinical text mining, a field of Natural Language Processing applied to biomedical informatics. The aim is to classify Electronic Health Records with respect to the International Classification of Diseases, which is the foundation for the identification of international health statistics, and the standard for reporting diseases and health conditions. Within the framework of data mining, the goal is the multi-label classification, as each health record has assigned multiple International Classification of Diseases codes. We investigate five Deep Learning architectures with a dataset obtained from the Basque Country Health System, and six different perspectives derived from shifts in the input and the output. Methods:We evaluate a Feed Forward Neural Network as the baseline and several Recurrent models based on the Bidirectional GRU architecture, putting our research focus on the text representation layer and testing three variants, from standard word embeddings to meta word embeddings techniques and contextual embeddings. Results:The results showed that the recurrent models overcome the non-recurrent model. The meta word embeddings techniques are capable of beating the standard word embeddings, but the contextual embeddings exhibit as the most robust for the downstream task overall. Additionally, the label-granularity alone has an impact on the classification performance. Conclusions:The contributions of this work are a) a comparison among five classification approaches based on Deep Learning on a Spanish dataset to cope with the multi-label health text classification problem; b) the study of the impact of document length and label-set size and granularity in the multi-label context; and c) the study of measures to mitigate multi-label text classification problems related to label-set size and sparseness","Electronic health record, International classification of diseases, Multi-label classification, Recurrent neural networks, Contextual embeddings, Label-granularity",105264,,Computer Methods and Programs in Biomedicine
140,@article: KIM2019105063,Development of an automatic muscle atrophy measuring algorithm to calculate the ratio of supraspinatus in supraspinous fossa using deep learning,Joo Young Kim and Kyunghan Ro and Sungmin You and Bo Rum Nam and Sunhyun Yook and Hee Seol Park and Jae Chul Yoo and Eunkyoung Park and Kyeongwon Cho and Baek Hwan Cho and In Young Kim,2019,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260719303608,https://doi.org/10.1016/j.cmpb.2019.105063,Background and objecti,"Medicine, Deep learning, Segmentation, Orthopedics, Rotator cuff tear",105063,,Computer Methods and Programs in Biomedicine
141,@article: ALSAIH2020105566,Deep learning architectures analysis for age-related macular degeneration segmentation on optical coherence tomography scans,K. Alsaih and M.Z. Yusoff and T.B. Tang and I. Faye and F. Mériaudeau,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260719324290,https://doi.org/10.1016/j.cmpb.2020.105566,"Background and objectives: Aged people usually are more to be diagnosed with retinal diseases in developed countries. Retinal capillaries leakage into the retina swells and causes an acute vision loss, which is called age-related macular degeneration (AMD). The disease can not be adequately diagnosed solely using fundus images as depth information is not available. The variations in retina volume assist in monitoring ophthalmological abnormalities. Therefore, high-fidelity AMD segmentation in optical coherence tomography (OCT) imaging modality has raised the attention of researchers as well as those of the medical doctors. Many methods across the years encompassing machine learning approaches and convolutional neural networks (CNN) strategies have been proposed for object detection and image segmentation. Methods: In this paper, we analyze four wide-spread deep learning models designed for the segmentation of three retinal fluids outputting dense predictions in the RETOUCH challenge data. We aim to demonstrate how a patch-based approach could push the performance for each method. Besides, we also evaluate the methods using the OPTIMA challenge dataset for generalizing network performance. The analysis is driven into two sections: the comparison between the four approaches and the significance of patching the images. Results: The performance of networks trained on the RETOUCH dataset is higher than human performance. The analysis further generalized the performance of the best network obtained by fine-tuning it and achieved a mean Dice similarity coefficient (DSC) of 0.85. Out of the three types of fluids, intraretinal fluid (IRF) is more recognized, and the highest DSC value of 0.922 is achieved using Spectralis dataset. Additionally, the highest average DSC score is 0.84, which is achieved by PaDeeplabv3+ model using Cirrus dataset. Conclusions: The proposed method segments the three fluids in the retina with high DSC value. Fine-tuning the networks trained on the RETOUCH dataset makes the network perform better and faster than training from scratch. Enriching the networks with inputting a variety of shapes by extracting patches helped to segment the fluids better than using a full image","Retinal fluids, Segmentation, SD-OCT volumes, deep learning, Patches",105566,,Computer Methods and Programs in Biomedicine
142,@article: YU2020105674,Detection of peripherally inserted central catheter (PICC) in chest X-ray images: A multi-task deep learning model,Dingding Yu and Kaijie Zhang and Lingyan Huang and Bonan Zhao and Xiaoshan Zhang and Xin Guo and Miaomiao Li and Zheng Gu and Guosheng Fu and Minchun Hu and Yan Ping and Ye Sheng and Zhenjie Liu and Xianliang Hu and Ruiyi Zhao,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260720315078,https://doi.org/10.1016/j.cmpb.2020.105674,Background and Objecti,"Deep learning, Multi-task learning, Picc, Segmentation, Tip detection, Chest x-ray images",105674,,Computer Methods and Programs in Biomedicine
143,@article: FIORENTINO2021105771,A regression framework to head-circumference delineation from US fetal images,Maria Chiara Fiorentino and Sara Moccia and Morris Capparuccini and Sara Giamberini and Emanuele Frontoni,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260720316047,https://doi.org/10.1016/j.cmpb.2020.105771,Background and Objectiv,"Fetal ultrasounds, Head circumference delineation, Regression networks, Convolutional neural networks",105771,,Computer Methods and Programs in Biomedicine
144,@article: TAGHANAKI201785,Pareto-optimal multi-objective dimensionality reduction deep auto-encoder for mammography classification,Saeid Asgari Taghanaki and Jeremy Kawahara and Brandon Miles and Ghassan Hamarneh,2017,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260716309269,https://doi.org/10.1016/j.cmpb.2017.04.012,Background and objecti,"Breast cancer, Computer aided diagnosis, Feature reduction, Auto-encoder, Multi-objective optimization",85-93,,Computer Methods and Programs in Biomedicine
145,@article: GUO2021106423,Effective integration of object boundaries and regions for improving the performance of medical image segmentation by using two cascaded networks,Wei Guo and Guodong Zhang and Zhaoxuan Gong and Qiang Li,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721004971,https://doi.org/10.1016/j.cmpb.2021.106423,Background and Objectiv,"Object segmentation, Two cascaded networks, Integration of object region and boundary",106423,,Computer Methods and Programs in Biomedicine
146,@article: BAYDILLI2020105645,Learn from one data set to classify all – A multi-target domain adaptation approach for white blood cell classification,Yusuf Yargı Baydilli and Umit Atila and Abdullah Elen,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260720314784,https://doi.org/10.1016/j.cmpb.2020.105645,"Background and objective: Traditional machine learning methods assume that both training and test data come from the same distribution. In this way, it becomes possible to achieve high successes when modelling on the same domain. Unfortunately, in real-world problems, direct transfer between domains is adversely affected due to differences in the data collection process and the internal dynamics of the data. In order to cope with such drawbacks, researchers use a method called “domain adaptation”, which enables the successful transfer of information learned in one domain to other domains. In this study, a model that can be used in the classification of white blood cells (WBC) and is not affected by domain differences was proposed. Methods: Only one data set was used as source domain, and an adaptation process was created that made possible the learned knowledge to be used effectively in other domains (multi-target domain adaptation). While constructing the model, we employed data augmentation, data generation and fine-tuning processes, respectively. Results: The proposed model has been able to extract “domain-invariant” features and achieved high success rates in the tests performed on nine different data sets. Multi-target domain adaptation accuracy was measured as %98.09. Conclusions: At the end of the study, it has been observed that the proposed model ignores the domain differences and it can adapt in a successful way to target domains. In this way, it becomes possible to classify unlabeled samples rapidly by using only a few number of labeled ones","Medical data analysis, White blood cells (WBC), Deep learning, Multi-target domain adaptation, Classification",105645,,Computer Methods and Programs in Biomedicine
147,@article: JAKUBICEK2020105081,Learning–based vertebra localization and labeling in 3D CT data of possibly incomplete and pathological spines,Roman Jakubicek and Jiri Chmelik and Jiri Jan and Petr Ourednicek and Lukas Lambert and Giampaolo Gavelli,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S016926071930762X,https://doi.org/10.1016/j.cmpb.2019.105081,Background and objecti,"Vertebra detection, Learning-based approach, Convolution neural network, Pathological vertebrae",105081,,Computer Methods and Programs in Biomedicine
148,@article: MOON2021105819,Automatic stenosis recognition from coronary angiography using convolutional neural networks,Jong Hak Moon and Da Young Lee and Won Chul Cha and Myung Jin Chung and Kyu-Sung Lee and Baek Hwan Cho and Jin Ho Choi,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260720316527,https://doi.org/10.1016/j.cmpb.2020.105819,Background and objecti,"Coronary angiography, Coronary artery stenosis, Deep learning, Stenosis recognition, Automated screening",105819,,Computer Methods and Programs in Biomedicine
149,@article: VU2019119,A dense multi-path decoder for tissue segmentation in histopathology images,Quoc Dang Vu and Jin Tae Kwak,2019,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260718312938,https://doi.org/10.1016/j.cmpb.2019.03.007,Background and Objecti,"Tissue segmentation, Digital pathology, Convolutional neural networks, Dense decoder",119-129,,Computer Methods and Programs in Biomedicine
150,@article: NOH2019237,Scale-space approximated convolutional neural networks for retinal vessel segmentation,Kyoung Jin Noh and Sang Jun Park and Soochahn Lee,2019,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260719302226,https://doi.org/10.1016/j.cmpb.2019.06.030,"Background and objective: Retinal fundus images are widely used to diagnose retinal diseases and can potentially be used for early diagnosis and prevention of chronic vascular diseases and diabetes. While various automatic retinal vessel segmentation methods using deep learning have been proposed, they are mostly based on common CNN structures developed for other tasks such as classificatio","Retinal vessel segmentation, Convolutional neural networks, Multi-scale representation, Scale-space approximation",237-246,,Computer Methods and Programs in Biomedicine
151,@article: LU201961,Extracting chemical-protein interactions from biomedical literature via granular attention based recurrent neural networks,Hongbin Lu and Lishuang Li and Xinyu He and Yang Liu and Anqiao Zhou,2019,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260719301257,https://doi.org/10.1016/j.cmpb.2019.04.020,Background and objecti,"Natural language processing, Recurrent neural networks, Granular attention mechanism, Chemical-protein interactions extraction, Swish activation function",61-68,,Computer Methods and Programs in Biomedicine
152,@article: ZAHIA201851,Tissue classification and segmentation of pressure injuries using convolutional neural networks,Sofia Zahia and Daniel Sierra-Sosa and Begonya Garcia-Zapirain and Adel Elmaghraby,2018,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260717314864,https://doi.org/10.1016/j.cmpb.2018.02.018,"Background and Objectives: This paper presents a new approach for automatic tissue classification in pressure injuries. These wounds are localized skin damages which need frequent diagnosis and treatment. Therefore, a reliable and accurate systems for segmentation and tissue type identification are needed in order to achieve better treatment results. Methods: Our proposed system is based on a Convolutional Neural Network (CNN) devoted to performing optimized segmentation of the different tissue types present in pressure injuries (granulation, slough, and necrotic tissues). A preprocessing step removes the flash light and creates a set of 5x5 sub-images which are used as input for the CNN network. The network output will classify every sub-image of the validation set into one of the three classes studied. Results: The metrics used to evaluate our approach show an overall average classification accuracy of 92.01%, an average total weighted Dice Similarity Coefficient of 91.38%, and an average precision per class of 97.31% for granulation tissue, 96.59% for necrotic tissue, and 77.90% for slough tissue. Conclusions: Our system has been proven to make recognition of complicated structures in biomedical images feasible","Deep learning, Pressure injuries, Tissue type classification, Image segmentation, Convolutional neural networks",51-58,,Computer Methods and Programs in Biomedicine
153,@article: HUAULME2021106452,MIcro-surgical anastomose workflow recognition challenge report,Arnaud Huaulmé and Duygu Sarikaya and Kévin {Le Mut} and Fabien Despinoy and Yonghao Long and Qi Dou and Chin-Boon Chng and Wenjun Lin and Satoshi Kondo and Laura Bravo-Sánchez and Pablo Arbeláez and Wolfgang Reiter and Manoru Mitsuishi and Kanako Harada and Pierre Jannin,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721005265,https://doi.org/10.1016/j.cmpb.2021.106452,"Background and Objective: Automatic surgical workflow recognition is an essential step in developing context-aware computer-assisted surgical systems. Video recordings of surgeries are becoming widely accessible, as the operational field view is captured during laparoscopic surgeries. Head and ceiling mounted cameras are also increasingly being used to record videos in open surgeries. This makes videos a common choice in surgical workflow recognition. Additional modalities, such as kinematic data captured during robot-assisted surgeries, could also improve workflow recognition. This paper presents the design and results of the MIcro-Surgical Anastomose Workflow recognition on training sessions (MISAW) challenge whose objective was to develop workflow recognition models based on kinematic data and/or videos. Methods: The MISAW challenge provided a data set of 27 sequences of micro-surgical anastomosis on artificial blood vessels. This data set was composed of videos, kinematics, and workflow annotations. The latter described the sequences at three different granularity levels: phase, step, and activity. Four tasks were proposed to the participants: three of them were related to the recognition of surgical workflow at three different granularity levels, while the last one addressed the recognition of all granularity levels in the same model. We used the average application-dependent balanced accuracy (AD-Accuracy) as the evaluation metric. This takes unbalanced classes into account and it is more clinically relevant than a frame-by-frame score. Results: Six teams participated in at least one task. All models employed deep learning models, such as convolutional neural networks (CNN), recurrent neural networks (RNN), or a combination of both. The best models achieved accuracy above 95%, 80%, 60%, and 75% respectively for recognition of phases, steps, activities, and multi-granularity. The RNN-based models outperformed the CNN-based ones as well as the dedicated modality models compared to the multi-granularity except for activity recognition. Conclusion: For high levels of granularity, the best models had a recognition rate that may be sufficient for applications such as prediction of remaining surgical time. However, for activities, the recognition rate was still low for applications that can be employed clinically. The MISAW data set is publicly available at http://www.synapse.org/MISAW to encourage further research in surgical workflow recognition","Surgical process model, Workflow recognition, Multi-modality, OR of the future",106452,,Computer Methods and Programs in Biomedicine
154,@article: TANG2019289,Efficient skin lesion segmentation using separable-Unet with stochastic weight averaging,Peng Tang and Qiaokang Liang and Xintong Yan and Shao Xiang and Wei Sun and Dan Zhang and Gianmarc Coppola,2019,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260719306145,https://doi.org/10.1016/j.cmpb.2019.07.005,Background and objecti,"Separable convolutional block, Stochastic weight averaging, Skin lesion segmentation, Real-time segmentation",289-301,,Computer Methods and Programs in Biomedicine
155,@article: ALMASNI201885,Simultaneous detection and classification of breast masses in digital mammograms via a deep learning YOLO-based CAD system,Mohammed A. Al-masni and Mugahed A. Al-antari and Jeong-Min Park and Geon Gi and Tae-Yeon Kim and Patricio Rivera and Edwin Valarezo and Mun-Taek Choi and Seung-Moo Han and Tae-Seong Kim,2018,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260717314980,https://doi.org/10.1016/j.cmpb.2018.01.017,Background and objecti,"Breast cancer, Mass detection and classification, Computer Aided Diagnosis, Deep learning, You Only Look Once (YOLO)",85-94,,Computer Methods and Programs in Biomedicine
156,@article: PHAM2022106648,Generating future fundus images for early age-related macular degeneration based on generative adversarial networks,Quang T.M. Pham and Sangil Ahn and Jitae Shin and Su Jeong Song,2022,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260722000335,https://doi.org/10.1016/j.cmpb.2022.106648,"Background and objective: Age-related macular degeneration (AMD) is one of the most common diseases that can lead to blindness worldwide. Recently, various fundus image analyzing studies are done using deep learning methods to classify fundus images to aid diagnosis and monitor AMD disease progression. But until now, to the best of our knowledge, no attempt was made to generate future synthesized fundus images that can predict AMD progression. In this paper, we developed a deep learning model using fundus images for AMD patients with different time elapses to generate synthetic future fundus images. Method: We exploit generative adversarial networks (GANs) with additional drusen masks to maintain the pathological information. The dataset included 8196 fundus images from 1263 AMD patients. A proposed GAN-based model, called Multi-Modal GAN (MuMo-GAN), was trained to generate synthetic predicted-future fundus images. Results: The proposed deep learning model indicates that the additional drusen masks can help to learn the AMD progression. Our model can generate future fundus images with appropriate pathological features. The drusen development over time is depicted well. Both qualitative and quantitative experiments show that our model is more efficient to monitor the AMD disease as compared to other studies. Conclusion: This study could help individualized risk prediction for AMD patients. Compared to existing methods, the experimental results show a significant improvement in terms of tracking the AMD stage in both image-level and pixel-level","Age related macular degeneration, Fundus image, Generative Adversarial Network (GAN)",106648,,Computer Methods and Programs in Biomedicine
157,@article: ANDREINI2020105268,Image generation by GAN and style transfer for agar plate image segmentation,Paolo Andreini and Simone Bonechi and Monica Bianchini and Alessandro Mecocci and Franco Scarselli,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260719311216,https://doi.org/10.1016/j.cmpb.2019.105268,"Background and objectives. Deep learning models and specifically Convolutional Neural Networks (CNNs) are becoming the leading approach in many computer vision tasks, including medical image analysis. Nevertheless, the CNN training usually requires large sets of supervised data, which are often difficult and expensive to obtain in the medical field. To address the lack of annotated images, image generation is a promising method, which is becoming increasingly popular in the computer vision community. In this paper, we present a new approach to the semantic segmentation of bacterial colonies in agar plate images, based on deep learning and synthetic image generation, to increase the training set size. Indeed, semantic segmentation of bacterial colony is the basis for infection recognition and bacterial counting in Petri plate analysis. Methods. A convolutional neural network (CNN) is used to separate the bacterial colonies from the background. To face the lack of annotated images, a novel engine is designed — which exploits a generative adversarial network to capture the typical distribution of the bacterial colonies on agar plates — to generate synthetic data. Then, bacterial colony patches are superimposed on existing background images, taking into account both the local appearance of the background and the intrinsic opacity of the bacterial colonies, and a style transfer algorithm is used for further improve visual realism. Results. The proposed deep learning approach has been tested on the only public dataset available with pixel–level annotations for bacterial colony semantic segmentation in agar plates. The role of including synthetic data in the training of a segmentation CNN has been evaluated, showing how comparable performances can be obtained with respect to the use of real images. Qualitative results are also reported for a second public dataset in which the segmentation annotations are not provided. Conclusions. The use of a small set of real data, together with synthetic images, allows obtaining comparable results with respect to using a complete set of real images. Therefore, the proposed synthetic data generator is able to address the scarcity of biomedical data and provides a scalable and cheap alternative to human ground–truth supervision","Synthetic image generation, Semantic segmentation, Deep learning, Generative adversarial network, Agar plate image, Bacterial culture",105268,,Computer Methods and Programs in Biomedicine
158,@article: HAI2021106439,Multi-view features integrated 2D\3D Net for glomerulopathy histologic types classification using ultrasound images,Jinjin Hai and Kai Qiao and Jian Chen and Ningning Liang and Lijie Zhang and Bin Yan,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721005137,https://doi.org/10.1016/j.cmpb.2021.106439,Background and Objecti,"Renal ultrasound, Histologic types, Group convolution, 3D convolution, Multi-view features",106439,,Computer Methods and Programs in Biomedicine
159,@article: XU2022106576,Deep reconstruction-recoding network for unsupervised domain adaptation and multi-center generalization in colonoscopy polyp detection,Jianwei Xu and Qingwei Zhang and Yizhou Yu and Ran Zhao and Xianzhang Bian and Xiaoqing Liu and Jun Wang and Zhizheng Ge and Dahong Qian,2022,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721006507,https://doi.org/10.1016/j.cmpb.2021.106576,"Background and objective: Currently, the best performing methods in colonoscopy polyp detection are primarily based on deep neural networks (DNNs), which are usually trained on large amounts of labeled data. However, different hospitals use different endoscope models and set different imaging parameters, which causes the collected endoscopic images and videos to vary greatly in style. There may be variations in the color space, brightness, contrast, and resolution, and there are also differences between white light endoscopy (WLE) and narrow band image endoscopy (NBIE). We call these variations the domain shift. The DNN performance may decrease when the training data and the testing data come from different hospitals or different endoscope models. Additionally, it is quite difficult to collect enough new labeled data and retrain a new DNN model before deploying that DNN to a new hospital or endoscope model. Methods: To solve this problem, we propose a domain adaptation model called Deep Reconstruction-Recoding Network (DRRN), which jointly learns a shared encoding representation for two tasks: i) a supervised object detection network for labeled source data, and ii) an unsupervised reconstruction-recoding network for unlabeled target data. Through the DRRN, the object detection network's encoder not only learns the features from the labeled source domain, but also encodes useful information from the unlabeled target domain. Therefore, the distribution difference of the two domains’ feature spaces can be reduced. Results: We evaluate the performance of the DRRN on a series of cross-domain datasets. Compared with training the polyp detection network using only source data, the performance of the DRRN on the target domain is improved. Through feature statistics and visualization, it is demonstrated that the DRRN can learn the common distribution and feature invariance of the two domains. The distribution difference between the feature spaces of the two domains can be reduced. Conclusion: The DRRN can improve cross-domain polyp detection. With the DRRN, the generalization performance of the DNN-based polyp detection model can be improved without additional labeled data. This improvement allows the polyp detection model to be easily transferred to datasets from different hospitals or different endoscope models","Polyp detection, Domain adaptation, Multi center generalization, Adversarial learning",106576,,Computer Methods and Programs in Biomedicine
160,@article: MOMENI2021106127,Synthetic microbleeds generation for classifier training without ground truth,Saba Momeni and Amir Fazlollahi and Paul Yates and Christopher Rowe and Yongsheng Gao and Alan Wee-Chung Liew and Olivier Salvado,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721002029,https://doi.org/10.1016/j.cmpb.2021.106127,Background and Objecti,"Microbleeds detection, Data augmentation, Neural network, Synthetic data generation, Gaussian modeling",106127,,Computer Methods and Programs in Biomedicine
161,@article: DENG2020105489,Classification of breast density categories based on SE-Attention neural networks,Jian Deng and Yanyun Ma and Deng-ao Li and Jumin Zhao and Yi Liu and Hui Zhang,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260719311058,https://doi.org/10.1016/j.cmpb.2020.105489,"Background and objective: Breast density (BD) is an independent predictor of breast cancer risk factor. The automatic classification of BD has yet to resolve. In this paper, we propose an improved convolutional neural network (CNN) framework that integrates innovative SE-Attention mechanism to learn discriminative features, aiming for automatic BD classification in mammography. Methods: A new benchmarking dataset was constructed from 18157 BD images, manually segmented into 4 levels based on Breast Imaging and Reporting Data System (BI-RADS): A (fatty), B (fibro-glandular), C (heterogeneously dense) and D (extremely dense). The proposed method consists of three main phases: (i) data enhancement and normalization of breast images (ii) SE-Attention training for feature re-calibration and fusion to better classify density and (iii) designing the auxiliary loss. We adopt an attention approach where SE-Attention mechanism is used to learn the density features, which is different from previous works. Results: Experimental results demonstrate that the proposed framework obtains higher classification accuracy than the original network, such as Inception-V4, ResNeXt, DenseNet, increasing the performance from 89.97% to 92.17%, 89.64% to 91.57%, 89.20% to 91.79% respectively. Among them, improved Inception-V4 possesses the highest accuracy meanwhile DenseNet improves in the largest extent, both the original and improved methods are more effective than other state-of-the-art image descriptors regarding classification. Conclusions: We insist that our method will help radiologists provide reliable BD diagnostic services at the expert level, allowing them to focus on patients who are really in need","Breast density, Benchmarking dataset, SE-Attention, CNN",105489,,Computer Methods and Programs in Biomedicine
162,@article: NISHIO2020105711,Automatic detection of acute ischemic stroke using non-contrast computed tomography and two-stage deep learning model,Mizuho Nishio and Sho Koyasu and Shunjiro Noguchi and Takao Kiguchi and Kanako Nakatsu and Thai Akasaka and Hiroki Yamada and Kyo Itoh,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260720315443,https://doi.org/10.1016/j.cmpb.2020.105711,Background and objecti,"Acute ischemic stroke, Deep learning, Non-contrast computed tomography, Magnetic resonance imaging, Computer-aided detection",105711,,Computer Methods and Programs in Biomedicine
163,@article: LI2021106070,BSEResU-Net: An attention-based before-activation residual U-Net for retinal vessel segmentation,Di Li and Susanto Rahardja,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721001450,https://doi.org/10.1016/j.cmpb.2021.106070,Background and objectiv,"Deep learning, Fundus images, Loss functions, Residual blocks, Vessel segmentation",106070,,Computer Methods and Programs in Biomedicine
164,@article: LIU2019105014,Automatic delineation of ribs and clavicles in chest radiographs using fully convolutional DenseNets,Yunbi Liu and Xiao Zhang and Guangwei Cai and Yingyin Chen and Zhaoqiang Yun and Qianjin Feng and Wei Yang,2019,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260719306650,https://doi.org/10.1016/j.cmpb.2019.105014,Background and Objecti,"Chest radiograph, Rib and clavicle delineation, Fully convolutional DenseNet",105014,,Computer Methods and Programs in Biomedicine
165,@article: YIN201793,Recognition of emotions using multimodal physiological signals and an ensemble deep learning model,Zhong Yin and Mengyuan Zhao and Yongxiong Wang and Jingdong Yang and Jianhua Zhang,2017,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260716305090,https://doi.org/10.1016/j.cmpb.2016.12.005,Background and Objecti,"Emotion recognition, Affective computing, Physiological signals, Deep learning, Ensemble learning",93-110,,Computer Methods and Programs in Biomedicine
166,@article: KIM2021105833,Automatic detection and segmentation of lumbar vertebrae from X-ray images for compression fracture evaluation,Kang Cheol Kim and Hyun Cheol Cho and Tae Jun Jang and Jong Mun Choi and Jin Keun Seo,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260720316667,https://doi.org/10.1016/j.cmpb.2020.105833,"For compression fracture detection and evaluation, an automatic X-ray image segmentation technique that combines deep-learning and level-set methods is proposed. Automatic segmentation is much more difficult for X-ray images than for CT or MRI images because they contain overlapping shadows of thoracoabdominal structures including lungs, bowel gases, and other bony structures such as ribs. Additional difficulties include unclear object boundaries, the complex shape of the vertebra, inter-patient variability, and variations in image contrast. Accordingly, a structured hierarchical segmentation method is presented that combines the advantages of two deep-learning methods. Pose-driven learning is used to selectively identify the five lumbar vertebrae in an accurate and robust manner. With knowledge of the vertebral positions, M-net is employed to segment the individual vertebra. Finally, fine-tuning segmentation is applied by combining the level-set method with the previously obtained segmentation results. The performance of the proposed method was validated by 160 lumbar X-ray images, resulting in a mean Dice similarity metric of 91.60±2.22%. The results show that the proposed method achieves accurate and robust identification of each lumbar vertebra and fine segmentation of individual vertebra","Lumbar X-ray, Vertebra segmentation, Vertebra detection, Deep learning, Level-set",105833,,Computer Methods and Programs in Biomedicine
167,@article: GEGUNDEZARIAS2021106081,A new deep learning method for blood vessel segmentation in retinal images based on convolutional kernels and modified U-Net model,Manuel E. Gegundez-Arias and Diego Marin-Santos and Isaac Perez-Borrero and Manuel J. Vasallo-Vazquez,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721001565,https://doi.org/10.1016/j.cmpb.2021.106081,"Background and Objective: Automatic monitoring of retinal blood vessels proves very useful for the clinical assessment of ocular vascular anomalies or retinopathies. This paper presents an efficient and accurate deep learning-based method for vessel segmentation in eye fundus images. Methods: The approach consists of a convolutional neural network based on a simplified version of the U-Net architecture that combines residual blocks and batch normalization in the up- and downscaling phases. The network receives patches extracted from the original image as input and is trained with a novel loss function that considers the distance of each pixel to the vascular tree. At its output, it generates the probability of each pixel of the input patch belonging to the vascular structure. The application of the network to the patches in which a retinal image can be divided allows obtaining the pixel-wise probability map of the complete image. This probability map is then binarized with a certain threshold to generate the blood vessel segmentation provided by the method. Results: The method has been developed and evaluated in the DRIVE, STARE and CHASE_Db1 databases, which offer a manual segmentation of the vascular tree by each of its images. Using this set of images as ground truth, the accuracy of the vessel segmentations obtained for an operating point proposal (established by a single threshold value for each database) was quantified. The overall performance was measured using the area of its receiver operating characteristic curve. The method demonstrated robustness in the face of the variability of the fundus images of diverse origin, being capable of working with the highest level of accuracy in the entire set of possible points of operation, compared to those provided by the most accurate methods found in literature. Conclusions: The analysis of results concludes that the proposed method reaches better performance than the rest of state-of-art methods and can be considered the most promising for integration into a real tool for vascular structure segmentation","Deep learning, Convolutional neural networks, Blood vessel, Segmentation, Fundus images",106081,,Computer Methods and Programs in Biomedicine
168,@article: FU2021106381,Fusion of 3D lung CT and serum biomarkers for diagnosis of multiple pathological types on pulmonary nodules,Yu Fu and Peng Xue and Ning Li and Peng Zhao and Zhuodong Xu and Huizhong Ji and Zhili Zhang and Wentao Cui and Enqing Dong,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721004557,https://doi.org/10.1016/j.cmpb.2021.106381,Background and Objecti,"Multiple pathological types, Pulmonary nodules, Multi-resolution deep learning, Machine learning, Multimodal information fusion",106381,,Computer Methods and Programs in Biomedicine
169,@article: HUANG2019141,An empirical evaluation of deep learning for ICD-9 code assignment using MIMIC-III clinical notes,Jinmiao Huang and Cesar Osorio and Luke Wicent Sy,2019,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260718309945,https://doi.org/10.1016/j.cmpb.2019.05.024,Background and Objecti,"Deep learning, Clinical notes, Machine learning, ICD-9, Medical codes, RNNs, CNNs, MIMIC-III, Code assignment",141-153,,Computer Methods and Programs in Biomedicine
170,@article: DELAFUENTELOPEZ2020105378,Automatic gauze tracking in laparoscopic surgery using image texture analysis,Eusebio {de la Fuente López} and Álvaro {Muñoz García} and Lidia {Santos del Blanco} and Juan Carlos {Fraile Marinero} and Javier {Pérez Turiel},2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S016926071931291X,https://doi.org/10.1016/j.cmpb.2020.105378,Background and Objecti,"Computer-aided-surgery, Gossypiboma, Image Texture Analysis, Local Binary Patterns (LBP), Convolutional Neural Networks, Minimally Invasive Surgery",105378,,Computer Methods and Programs in Biomedicine
171,@article: EROGLU2021106369,Diagnosis and grading of vesicoureteral reflux on voiding cystourethrography images in children using a deep hybrid model,Yesim EROGLU and Kadir YILDIRIM and Ahmet ÇINAR and Muhammed YILDIRIM,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721004430,https://doi.org/10.1016/j.cmpb.2021.106369,Background and objecti,"Voiding cystourethrography, Deep learning, mRMR, Vesicoureteral Reflux, Classifiers, Children",106369,,Computer Methods and Programs in Biomedicine
172,@article: FERREIRA2019105053,Saliency-driven system models for cell analysis with deep learning,Daniel S. Ferreira and Geraldo L. B. Ramalho and Débora Torres and Alessandra H. G. Tobias and Mariana T. Rezende and Fátima N. S. Medeiros and Andrea G. C. Bianchi and Cláudia M. Carneiro and Daniela M. Ushizima,2019,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260718316870,https://doi.org/10.1016/j.cmpb.2019.105053,"Background and objectives: Saliency refers to the visual perception quality that makes objects in a scene to stand out from others and attract attention. While computational saliency models can simulate the expert’s visual attention, there is little evidence about how these models perform when used to predict the cytopathologist’s eye fixations. Saliency models may be the key to instrumenting fast object detection on large Pap smear slides under real noisy conditions, artifacts, and cell occlusions. This paper describes how our computational schemes retrieve regions of interest (ROI) of clinical relevance using visual attention models. We also compare the performance of different computed saliency models as part of cell screening tasks, aiming to design a computer-aided diagnosis systems that supports cytopathologists. Method: We record eye fixation maps from cytopathologists at work, and compare with 13 different saliency prediction algorithms, including deep learning. We develop cell-specific convolutional neural networks (CNN) to investigate the impact of bottom-up and top-down factors on saliency prediction from real routine exams. By combining the eye tracking data from pathologists with computed saliency models, we assess algorithms reliability in identifying clinically relevant cells. Results:The proposed cell-specific CNN model outperforms all other saliency prediction methods, particularly regarding the number of false positives. Our algorithm also detects the most clinically relevant cells, which are among the three top salient regions, with accuracy above 98% for all diseases, except carcinoma (87%). Bottom-up methods performed satisfactorily, with saliency maps that enabled ROI detection above 75% for carcinoma and 86% for other pathologies. Conclusions:ROIs extraction using our saliency prediction methods enabled ranking the most relevant clinical areas within the image, a viable data reduction strategy to guide automatic analyses of Pap smear slides. Top-down factors for saliency prediction on cell images increases the accuracy of the estimated maps while bottom-up algorithms proved to be useful for predicting the cytopathologist’s eye fixations depending on parameters, such as the number of false positive and negative. Our contributions are: comparison among 13 state-of-the-art saliency models to cytopathologists’ visual attention and deliver a method that the associate the most conspicuous regions to clinically relevant cells","Saliency prediction, Convolutional neural network, Cell analysis, Eye tracking experiment",105053,,Computer Methods and Programs in Biomedicine
173,@article: RYAN2021106368,Unsupervised domain adaptation for the segmentation of breast tissue in mammography images,Frances Ryan and Karen López-Linares Román and Blanca Zufiria Gerbolés and Kristin May Rebescher and Maialen Stephens Txurio and Rodrigo Cilla Ugarte and María Jesús García González and Iván Macía Oliver,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721004429,https://doi.org/10.1016/j.cmpb.2021.106368,"Background and Objective: Breast density refers to the proportion of glandular and fatty tissue in the breast and is recognized as a useful factor assessing breast cancer risk. Moreover, the segmentation of the high-density glandular tissue from mammograms can assist medical professionals visualizing and localizing areas that may require additional attention. Developing robust methods to segment breast tissues is challenging due to the variations in mammographic acquisition systems and protocols. Deep learning methods are effective in medical image segmentation but they often require large quantities of labelled data. Unsupervised domain adaptation is an area of research that employs unlabelled data to improve model performance on variations of samples derived from different sources. Methods: First, a U-Net architecture was used to perform segmentation of the fatty and glandular tissues with labelled data from a single acquisition device. Then, adversarial-based unsupervised domain adaptation methods were used to incorporate single unlabelled target domains, consisting of images from a different machine, into the training. Finally, the domain adaptation model was extended to include multiple unlabelled target domains by combining a reconstruction task with adversarial training. Results: The adversarial training was found to improve the generalization of the initial model on new domain data, demonstrating clearly improved segmentation of the breast tissues. For training with multiple unlabelled domains, combining a reconstruction task with adversarial training improved the stability of the training and yielded adequate segmentation results across all domains with a single model. Conclusions: Results demonstrated the potential for adversarial-based domain adaptation with U-Net architectures for segmentation of breast tissue in mammograms coming from several devices and demonstrated that domain-adapted models could achieve a similar agreement with manual segmentations. It has also been found that combining adversarial and reconstruction-based methods can provide a simple and effective solution for training with multiple unlabelled target domains","Deep learning, Unsupervised domain adaptation, Breast, Adversarial learning, Reconstruction, Multi-target",106368,,Computer Methods and Programs in Biomedicine
174,@article: ALANTARI2020105584,Evaluation of deep learning detection and classification towards computer-aided diagnosis of breast lesions in digital X-ray mammograms,Mugahed A. Al-antari and Seung-Moo Han and Tae-Seong Kim,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260720314176,https://doi.org/10.1016/j.cmpb.2020.105584,Background and Objecti,"Deep learning, Detection, Classification, Evaluation, Breast lesions, Computer-aided diagnosis (CAD)",105584,,Computer Methods and Programs in Biomedicine
175,@article: ATILA2020105192,Classification of DNA damages on segmented comet assay images using convolutional neural network,Ümit Atila and Yusuf Yargı Baydilli and Eftal Sehirli and Muhammed Kamil Turan,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260719300707,https://doi.org/10.1016/j.cmpb.2019.105192,Background and Objecti,"Comet assay, DNA damage, Convolutional neural Network, Deep learning",105192,,Computer Methods and Programs in Biomedicine
176,@article: BAE2020105119,Fully automated 3D segmentation and separation of multiple cervical vertebrae in CT images using a 2D convolutional neural network,Hyun-Jin Bae and Heejung Hyun and Younghwa Byeon and Keewon Shin and Yongwon Cho and Young Ji Song and Seong Yi and Sung-Uk Kuh and Jin S. Yeom and Namkug Kim,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260719312246,https://doi.org/10.1016/j.cmpb.2019.105119,Background and Objecti,"Cervical vertebrae, Spine CT, Spine segmentation, Convolutional neural network, Deep learning",105119,,Computer Methods and Programs in Biomedicine
177,@article: EUN2018215,Single-view 2D CNNs with fully automatic non-nodule categorization for false positive reduction in pulmonary nodule detection,Hyunjun Eun and Daeyeong Kim and Chanho Jung and Changick Kim,2018,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260718307491,https://doi.org/10.1016/j.cmpb.2018.08.012,"Background and Objective: In pulmonary nodule detection, the first stage, candidate detection, aims to detect suspicious pulmonary nodules. However, detected candidates include many false positives and thus in the following stage, false positive reduction, such false positives are reliably reduced. Note that this task is challenging due to 1) the imbalance between the numbers of nodules and non-nodules and 2) the intra-class diversity of non-nodules. Although techniques using 3D convolutional neural networks (CNNs) have shown promising performance, they suffer from high computational complexity which hinders constructing deep networks. To efficiently address these problems, we propose a novel framework using the ensemble of 2D CNNs using single views, which outperforms existing 3D CNN-based methods. Methods: Our ensemble of 2D CNNs utilizes single-view 2D patches to improve both computational and memory efficiency compared to previous techniques exploiting 3D CNNs. We first categorize non-nodules on the basis of features encoded by an autoencoder. Then, all 2D CNNs are trained by using the same nodule samples, but with different types of non-nodules. By extending the learning capability, this training scheme resolves difficulties of extracting representative features from non-nodules with large appearance variations. Note that, instead of manual categorization requiring the heavy workload of radiologists, we propose to automatically categorize non-nodules based on the autoencoder and k-means clustering. Results: We performed extensive experiments to validate the effectiveness of our framework based on the database of the lung nodule analysis 2016 challenge. The superiority of our framework is demonstrated through comparing the performance of five frameworks trained with differently constructed training sets. Our proposed framework achieved state-of-the-art performance (0.922 of the competition performance metric score) with low computational demands (789K of parameters and 1024M of floating point operations per second). Conclusion: We presented a novel false positive reduction framework, the ensemble of single-view 2D CNNs with fully automatic non-nodule categorization, for pulmonary nodule detection. Unlike previous 3D CNN-based frameworks, we utilized 2D CNNs using 2D single views to improve computational efficiency. Also, our training scheme using categorized non-nodules, extends the learning capability of representative features of different non-nodules. Our framework achieved state-of-the-art performance with low computational complexity","Computer-aided detection, Pulmonary nodule detection, False positive reduction, Automatic non-nodule categorization, Deep learning",215-224,,Computer Methods and Programs in Biomedicine
178,@article: MOSTAFA2020105640,Greedy based convolutional neural network optimization for detecting apnea,Sheikh Shanawaz Mostafa and Darío Baptista and Antonio G. Ravelo-García and Gabriel Juliá-Serdá and Fernando Morgado-Dias,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260720314735,https://doi.org/10.1016/j.cmpb.2020.105640,Background and objecti,"Optimization, Classification algorithms, sleep apnea, CNN, Hyperparameter",105640,,Computer Methods and Programs in Biomedicine
179,@article: HAN2020105651,Deep learning analysis in coronary computed tomographic angiography imaging for the assessment of patients with coronary artery stenosis,Dan Han and Jiayi Liu and Zhonghua Sun and Yu Cui and Yi He and Zhenghan Yang,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S016926072031484X,https://doi.org/10.1016/j.cmpb.2020.105651,Background and Objecti,"Coronary atherosclerotic stenosis, Coronary computed tomographic angiography, Convolutional neural network, Deep learning",105651,,Computer Methods and Programs in Biomedicine
180,@article: SAITI2020105628,Ensemble methods in combination with compartment models for blood glucose level prediction in type 1 diabetes mellitus,Kyriaki Saiti and Martin Macaš and Lenka Lhotská and Kateřina Štechová and Pavlína Pithová,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260720314619,https://doi.org/10.1016/j.cmpb.2020.105628,"Backgroung: Type 1 diabetes is a disease that adversely affects the daily life of a large percentage of people worldwide. Daily glucose levels regulation and useful advices provided to patients regarding their diet are essential for diabetes treatment. For this reason, the interest of the academic community has focused on developing innovative systems, such as decision support systems, based on glucose prediction algorithms. The present work presents the predictive capabilities of ensemble methods compared to individual algorithms while combining each method with compartment models for fast acting insulin absorption simulation. Methods: An approach of combining widely used glycemia prediction algorithms is proposed and three different ensemble methods (Linear, Bagging and Boosting metaregressor) are applied and evaluated on their ability to provide accurate predictions for 30, 45 and 60 minutes ahead prediction horizon. Moreover, glycemia levels, long and short acting insulin dosages and consumed carbohydrates from six type one people with diabetes are used as input data and the results are evaluated in terms of root-mean square error and Clarke error grid analysis. Results: According to results, ensemble methods can provide more accurate glucose concentration in comparison to individual algorithms. Bagging metaregressor, specifically, performed better than individual algorithms in all prediction horizons for small datasets. Bagging ensemble method improved the percentage in zone A according to Clarkes error grid analysis by 4% and in some cases by 9%. Moreover, compartment models are proved to improve results in combination with any method at any prediction horizon. This strengthen the potential practical usefulness of the ensemble methods and the importance of building accurate compartment models","Diabetes mellitus, Glucose prediction, Insulin pumps, Continuous glucose monitoring, Decision support systems, Ensemble method, Compartment models",105628,,Computer Methods and Programs in Biomedicine
181,@article: SALVI2020105506,Stain Color Adaptive Normalization (SCAN) algorithm: Separation and standardization of histological stains in digital pathology,Massimo Salvi and Nicola Michielli and Filippo Molinari,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260720305721,https://doi.org/10.1016/j.cmpb.2020.105506,Background and objecti,"Color deconvolution, Digital histopathology, H&E staining, Stain normalization, Whole-slide imaging",105506,,Computer Methods and Programs in Biomedicine
182,@article: BLANCO2020105079,A superpixel-driven deep learning approach for the analysis of dermatological wounds,Gustavo Blanco and Agma J.M. Traina and Caetano {Traina Jr.} and Paulo M. Azevedo-Marques and Ana E.S. Jorge and Daniel {de Oliveira} and Marcos V.N. Bedo,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260719306753,https://doi.org/10.1016/j.cmpb.2019.105079,Backgrou,"Deep learning, Superpixel segmentation, Dermatological wounds, Tissue recognition",105079,,Computer Methods and Programs in Biomedicine
183,@article: KIM2020105513,Web-based fully automated cephalometric analysis by deep learning,Hannah Kim and Eungjune Shim and Jungeun Park and Yoon-Ji Kim and Uilyong Lee and Youngjun Kim,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260719320206,https://doi.org/10.1016/j.cmpb.2020.105513,Background and Objecti,"Fully automated cephalometry, Automated landmark detection, Web-based application, Deep learning, Stacked hourglass network",105513,,Computer Methods and Programs in Biomedicine
184,@article: LIU2022106635,The effect of CT high-resolution imaging diagnosis based on deep residual network on the pathology of bladder cancer classification and staging,Dongmei Liu and Shubao Wang and Jing Wang,2022,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260722000207,https://doi.org/10.1016/j.cmpb.2022.106635,Background and objecti,"Residual network, Deep learning, Super-resolution processing, Non-local, CT, Staging of bladder cancer",106635,,Computer Methods and Programs in Biomedicine
185,@article: HUANG201767,MSFCN-multiple supervised fully convolutional networks for the osteosarcoma segmentation of CT images,Lin Huang and Wei Xia and Bo Zhang and Bensheng Qiu and Xin Gao,2017,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260716310926,https://doi.org/10.1016/j.cmpb.2017.02.013,Background and objecti,"Multiple supervised networks, Osteosarcoma segmentation, Convolutional neural networks",67-74,,Computer Methods and Programs in Biomedicine
186,@article: ZOU2021106327,A Robust Breast ultrasound segmentation method under noisy annotations,Haipeng Zou and Xun Gong and Jun Luo and Tianrui Li,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721004016,https://doi.org/10.1016/j.cmpb.2021.106327,"Background and Objective: A large-scale training data and accurate annotations are fundamental for current segmentation networks. However, the characteristic artifacts of ultrasound images always make the annotation task complicated, such as attenuation, speckle, shadows and signal dropout. Further complications arise as the contrast between the region of interest and background is often low. Without double-check from professionals, it is hard to guarantee that there is no noisy annotation in segmentation datasets. However, among the deep learning methods applied to ultrasound segmentation so far, no one can solve this problem.Method: Given a dataset with poorly labeled masks, including a certain amount of noises, we propose an end-to-end noisy annotation tolerance network (NAT-Net). NAT-Net can detect noise by the proposed noise index (NI) and dynamically correct noisy annotations in the training stage. Simultaneously, noise index is used to correct the noise along with the output of the learning model. This method does not need any auxiliary clean datasets or prior knowledge of noise distributions, so it is more general, robust and easier to apply than the existing methods. Results: NAT-Net outperforms previous state-of-the-art methods on synthesized data with different noise ratio. For real-world dataset with more complex noise types, the IoU of NAT-Net is higher than that of state-of-art approaches by nearly 6%. Experimental results show that our method can also achieve good results compared with the existing methods for clean dataset. Conclusion: The NAT-Net reduces manual interaction of data annotation, reduces dependence on medical personnel. After tumor segmentation, disease diagnosis efficiency is improved, which provides an auxiliary strategies for subsequent medical diagnosis systems based on ultrasound","Breast cancer, Ultrasound images, Tumor segmentation, Noisy annotation, Weakly supervised",106327,,Computer Methods and Programs in Biomedicine
187,@article: HE2021106379,MFB-LANN: A lightweight and updatable myocardial infarction diagnosis system based on convolutional neural networks and active learning,Ziyang He and Zhiyong Yuan and Panfeng An and Jianhui Zhao and Bo Du,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721004533,https://doi.org/10.1016/j.cmpb.2021.106379,"Background and objectives: 12 leads electrocardiogram (ECG) are widely used to diagnose myocardial infarction (MI). Generally, the symptoms of MI can be reflected by waveforms in the heartbeat, and the contribution of different ECG leads to different types of MI is different. Therefore, it is significant to use the heartbeat waveform features and the lead relationship features for multi-category MI diagnosis. Moreover, the challenge of individual differences and lightweight algorithms also need to be further resolved and explored in the ECG automatic diagnosis system. Methods: This paper presents a lightweight MI diagnosis system named multi-feature-branch lead attention neural network (MFB-LANN) via 12 leads ECG signals. It is designed based on the characteristics of the ECG lead. Specifically, 12 independent feature branches correspond to different leads, and each branch contains different convolutional layers to extract features in the heartbeat, then a novel attention module is developed named lead attention mechanism (LAM) to assign different weights to each feature branch. Finally all the weighted feature branches are fused for classification. Furthermore, to overcome individual differences, patient-specific scheme and active learning (AL) are used to train and update the model iteratively. Results: Experimental results based on Physikalisch-Technische Bundesanstalt (PTB) database shows that the MFB-LANN achieved satisfactory results with accuracy of 99.63% based on 5-fold cross validation under the intra-patient scheme. The patient-specific experiment yielded an average accuracy of 96.99% compared to the state-of-the-art. By contrast, the model achieved acceptable results on the hybrid database (PTB and PTB-XL), especially achieving 94.19% accuracy after the update. Moreover, the system can complete the update process and real-time diagnosis on the ARM Cortex-A72 platform. Conclusions: Experiments show that the proposed method for MI diagnosis has more obvious advantages compared to other recent methods, and it has great potential to be applied to the mobile medical field","Myocardial infarction (MI), Convolutional neural networks (CNN), Lead attention mechanism (LAM), Active learning (AL), Real-time diagnosis",106379,,Computer Methods and Programs in Biomedicine
188,@article: GUO2021105791,Automatic myocardial infarction detection in contrast echocardiography based on polar residual network,Yanhui Guo and Guo-Qing Du and Wen-Qian Shen and Chunlai Du and Pei-Na He and Siuly Siuly,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260720316242,https://doi.org/10.1016/j.cmpb.2020.105791,Purpo,"Infarct detection, Myocardial contrast echocardiography, Deep learning, Convolutional neural network, Polar system",105791,,Computer Methods and Programs in Biomedicine
189,@article: HA2021106374,Modality-agnostic self-supervised deep feature learning and fast instance optimisation for multimodal fusion in ultrasound-guided interventions,In Young Ha and Mattias P. Heinrich,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S016926072100448X,https://doi.org/10.1016/j.cmpb.2021.106374,"Background and Objective: Fast and robust alignment of pre-operative MRI planning scans to intra-operative ultrasound is an important aspect for automatically supporting image-guided interventions. Thus far, learning-based approaches have failed to tackle the intertwined objectives of fast inference computation time and robustness to unexpectedly large motion and misalignment. In this work, we propose a novel method that decouples deep feature learning and the computation of long ranging local displacement probability maps from fast and robust global transformation prediction. Methods: In our approach, we firstly train a convolutional neural network (CNN) to extract modality-agnostic features with sub-second computation times for both 3D volumes during inference. Using sparsity-based network weight pruning, the model complexity and computation times can be substantially reduced. Based on these features, a large discretized search range of 3D motion vectors is explored to compute a probabilistic displacement map for each control point. These 3D probability maps are employed in our newly proposed, computationally efficient, instance optimisation that robustly estimates the most likely globally linear transformation that best reflects the local displacement beliefs subject to outlier rejection. Results: Our experimental validation demonstrates state-of-the-art accuracy on the challenging CuRIOUS dataset with average target registration errors of 2.50 mm, model size of only 1.2 MByte and run times of approx. 3 seconds for a full 3D multimodal registration. Conclusion: We show that a significant improvement in accuracy and robustness can be gained with instance optimisation and our fast self-supervised deep learning model can achieve state-of-the-art accuracy on challenging registration task in only 3 seconds","Curious challenge, Discrete registration, Multimodal registration",106374,,Computer Methods and Programs in Biomedicine
190,@article: GARCIA2021105855,Glaucoma Detection from Raw SD-OCT Volumes: A Novel Approach Focused on Spatial Dependencies,Gabriel García and Adrián Colomer and Valery Naranjo,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260720316886,https://doi.org/10.1016/j.cmpb.2020.105855,"Background and objective:Glaucoma is the leading cause of blindness worldwide. Many studies based on fundus image and optical coherence tomography (OCT) imaging have been developed in the literature to help ophthalmologists through artificial-intelligence techniques. Currently, 3D spectral-domain optical coherence tomography (SD-OCT) samples have become more important since they could enclose promising information for glaucoma detection. To analyse the hidden knowledge of the 3D scans for glaucoma detection, we have proposed, for the first time, a deep-learning methodology based on leveraging the spatial dependencies of the features extracted from the B-scans. Methods:The experiments were performed on a database composed of 176 healthy and 144 glaucomatous SD-OCT volumes centred on the optic nerve head (ONH). The proposed methodology consists of two well-differentiated training stages: a slide-level feature extractor and a volume-based predictive model. The slide-level discriminator is characterised by two new, residual and attention, convolutional modules which are combined via skip-connections with other fine-tuned architectures. Regarding the second stage, we first carried out a data-volume conditioning before extracting the features from the slides of the SD-OCT volumes. Then, Long Short-Term Memory (LSTM) networks were used to combine the recurrent dependencies embedded in the latent space to provide a holistic feature vector, which was generated by the proposed sequential-weighting module (SWM). Results:The feature extractor reports AUC values higher than 0.93 both in the primary and external test sets. Otherwise, the proposed end-to-end system based on a combination of CNN and LSTM networks achieves an AUC of 0.8847 in the prediction stage, which outperforms other state-of-the-art approaches intended for glaucoma detection. Additionally, Class Activation Maps (CAMs) were computed to highlight the most interesting regions per B-scan when discerning between healthy and glaucomatous eyes from raw SD-OCT volumes. Conclusions:The proposed model is able to extract the features from the B-scans of the volumes and combine the information of the latent space to perform a volume-level glaucoma prediction. Our model, which combines residual and attention blocks with a sequential weighting module to refine the LSTM outputs, surpass the results achieved from current state-of-the-art methods focused on 3D deep-learning architectures","Glaucoma detection, SD-OCT volumes, Convolutional attention blocks, Residual connections, LSTM networks, Sequential-weighting module",105855,,Computer Methods and Programs in Biomedicine
191,@article: SHI2021105807,Cervical cell classification with graph convolutional network,Jun Shi and Ruoyu Wang and Yushan Zheng and Zhiguo Jiang and Haopeng Zhang and Lanlan Yu,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260720316400,https://doi.org/10.1016/j.cmpb.2020.105807,Background and objecti,"Cervical cancer screening, Cervical cytology, Cervical cell classification, Graph convolutional network",105807,,Computer Methods and Programs in Biomedicine
192,@article: NAHAVANDI2022106541,Application of artificial intelligence in wearable devices: Opportunities and challenges,Darius Nahavandi and Roohallah Alizadehsani and Abbas Khosravi and U Rajendra Acharya,2022,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721006155,https://doi.org/10.1016/j.cmpb.2021.106541,Background and objectiv,"Wearable devices, Healthcare, Machine learning, Deep learning, Internet of things",106541,,Computer Methods and Programs in Biomedicine
193,@article: WU201887,Decision based on big data research for non-small cell lung cancer in medical artificial system in developing country,Jia Wu and Yanlin Tan and Zhigang Chen and Ming Zhao,2018,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260717308301,https://doi.org/10.1016/j.cmpb.2018.03.004,"Non-small cell lung cancer (NSCLC) is a high risk cancer and is usually scanned by PET–CT for testing, predicting and then give the treatment methods. However, in the actual hospital system, at least 640 images must be generated for each patient through PET–CT scanning. Especially in developing countries, a huge number of patients in NSCLC are attended by doctors. Artificial system can predict and make decision rapidly. According to explore and research artificial medical system, the selection of artificial observations also can result in low work efficiency for doctors. In this study, data information of 2,789,675 patients in three hospitals in China are collected, compiled, and used as the research basis; these data are obtained through image acquisition and diagnostic parameter machine decision-making method on the basis of the machine diagnosis and medical system design model of adjuvant therapy. By combining image and diagnostic parameters, the machine decision diagnosis auxiliary algorithm is established. Experimental result shows that the accuracy has reached 77% in NSCLC","NSCLC, PET–CT, Medical decision making, Big data, Image, Diagnostic parameters",87-101,,Computer Methods and Programs in Biomedicine
194,@article: ATTIA201917,Digital hair segmentation using hybrid convolutional and recurrent neural networks architecture,Mohamed Attia and Mohammed Hossny and Hailing Zhou and Saeid Nahavandi and Hamed Asadi and Anousha Yazdabadi,2019,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260719300884,https://doi.org/10.1016/j.cmpb.2019.05.010,Background and Objecti,"Dermatology, Hair detection, Hair segmentation, Deep learning",17-30,,Computer Methods and Programs in Biomedicine
195,@article: KHALILI2021106063,Automatic Sleep Stage Classification Using Temporal Convolutional Neural Network and New Data Augmentation Technique from Raw Single-Channel EEG,Ebrahim Khalili and Babak {Mohammadzadeh Asl},2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721001383,https://doi.org/10.1016/j.cmpb.2021.106063,"Background and objective: This paper presents a new framework for automatic classification of sleep stages using a deep learning algorithm from single-channel EEG signals. Each segmented EEG signal appended with its label of stages is fed into a deep learning model to create an automatic sleep stage classification. This is one of the most important problems that is critical to the realization of monitoring patients with sleep disorder. Methods: In the present study, a neural network architecture is introduced utilizing Convolutional Neural Networks (CNNs) to extract features, followed by Temporal Convolutional Neural Network to extract the temporal features from the extracted features vector of CNN. Finally, the performance of our model is improved by a Conditional Random Field layer. We also employed a new data augmentation technique to enhance the CNNs training which has auxiliary effects. Results: We evaluated our model by two different single-channel EEG signals (i.e., Fpz-Cz and Pz-Oz EEG channels) from two public sleep datasets, named Sleep-EDF-2013 and Sleep-EDF-2018. The evaluation results on both datasets showed that our model obtains the best total accuracy and kappa score (EDF-2013: 85.39%- 0.80, EDF-2018: 82.46%- 0.76) compared to the state-of-the-art methods. Conclusions: This study will possibly allow us to have a wearable sleep monitoring system with a single-channel EEG. Also, unlike hand-crafted features methods, our model finds its own patterns through training epochs, and therefore, it may minimize engineering bias","Sleep stage classification, Single channel EEG, Deep learning, Temporal Convolutional Neural Network, Data augmentation",106063,,Computer Methods and Programs in Biomedicine
196,@article: SUN201845,Integrating genomic data and pathological images to effectively predict breast cancer clinical outcome,Dongdong Sun and Ao Li and Bo Tang and Minghui Wang,2018,,0169-2607,https://www.sciencedirect.com/science/article/pii/S016926071830018X,https://doi.org/10.1016/j.cmpb.2018.04.008,Background and objecti,"Breast cancer survival prediction, Genomic data, Pathological image, Multiple kernel learning",45-53,,Computer Methods and Programs in Biomedicine
197,@article: LEE2020105385,Enhancement of surgical hand gesture recognition using a capsule network for a contactless interface in the operating room,A-reum Lee and Yongwon Cho and Seongho Jin and Namkug Kim,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260719309976,https://doi.org/10.1016/j.cmpb.2020.105385,"Background and objective:Hand gesture recognition systems in operating rooms (ORs) are crucial for browsing and controlling computer-aided devices, which have been developed to decrease the risk of contamination during surgical procedures. Methods:We proposed the use of hand gesture recognition to enhance accuracies and recognition areas with the capsule network (CapsNet) of deep neural network and Leap Motionâ Our method includes the i) extraction and preprocessing of infrared (IR) images (60 frames per second) from Leap Motion™, ii) training of various types of networks, and iii) gesture recognition evaluation in the OR. We trained the images of training dataset (N=903) and tested images (N=100) using five types of surgical hand gestures including hovering, grab, click, one peak, and two peaks by 10 subjects with various types of augmentation methods including rotate (0∘, 90∘, 180∘), scale, translation, illumination, and resize. Results: CapsNet achieved a classification accuracy of 86.46% (around 10% improvement) compared with 73.67% for the baseline convolutional neural network (CNN) and 76.4% for VGG16. Conclusions: In conclusion, the accuracy of hand gesture recognition with CapsNet was better than that of conventional CNNs, which could be used to navigate and manipulate various types of computer-aided devices and applications through contactless gesture interaction","Capsule network, Convolutional neural network, Deep learning, Hand gesture recognition, Operating room",105385,,Computer Methods and Programs in Biomedicine
198,@article: CHAKRABARTI2021106335,A channel independent generalized seizure detection method for pediatric epileptic seizures,Satarupa Chakrabarti and Aleena Swetapadma and Prasant Kumar Pattnaik,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721004090,https://doi.org/10.1016/j.cmpb.2021.106335,Background and objecti,"Epilepsy, Electroencephalogram, Seizure, Long short-term memory, Deep learning, Intracranial electroencephalogram",106335,,Computer Methods and Programs in Biomedicine
199,@article: LIEW2021106114,Automatic colonic polyp detection using integration of modified deep residual convolutional neural network and ensemble learning approaches,Win Sheng Liew and Tong Boon Tang and Cheng-Hung Lin and Cheng-Kai Lu,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721001899,https://doi.org/10.1016/j.cmpb.2021.106114,Background and Objecti,"colorectal cancer (CRC), polyps, deep residual network, principal component analysis, AdaBoost ensemble learning",106114,,Computer Methods and Programs in Biomedicine
200,@article: ZHANG2019104978,Automatic cataract grading methods based on deep learning,Hongyan Zhang and Kai Niu and Yanmin Xiong and Weihua Yang and ZhiQiang He and Hongxin Song,2019,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260719307163,https://doi.org/10.1016/j.cmpb.2019.07.006,Background and objecti,"Cataract, Six-level grading, Deep convolutional neural network, Feature fusion, Stacking, Support vector machine",104978,,Computer Methods and Programs in Biomedicine
201,@article: LIU2020105755,Cardiac magnetic resonance image segmentation based on convolutional neural network,Duqiu Liu and Zheng Jia and Ming Jin and Qian Liu and Zhiliang Liao and Junyan Zhong and Haowen Ye and Gang Chen,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260720315881,https://doi.org/10.1016/j.cmpb.2020.105755,Objecti,"Cardiac magnetic resonance imaging, Medical image, Convolutional neural network, Image saliency, Image segmentation",105755,,Computer Methods and Programs in Biomedicine
202,@article: DING2021106447,Deep attention branch networks for skin lesion classification,Saisai Ding and Zhongyi Wu and Yanyan Zheng and Zhaobang Liu and Xiaodong Yang and Xiaokai Yang and Gang Yuan and Jing Xie,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721005216,https://doi.org/10.1016/j.cmpb.2021.106447,Background and Objecti,"Dermoscopy image, Skin lesion classification, Attention branch, Class activation mapping, Loss weighting, Class imbalance",106447,,Computer Methods and Programs in Biomedicine
203,@article: SU20191,Extraction of risk factors for cardiovascular diseases from Chinese electronic medical records,Jia Su and Jinpeng Hu and Jingchi Jiang and Jing Xie and Yang Yang and Bin He and Jinfeng Yang and Yi Guan,2019,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260718311489,https://doi.org/10.1016/j.cmpb.2019.01.007,Background and objecti,"Risk factor, Cardiovascular diseases, Information extraction, Machine learning, Chinese electronic medical records",1-10,,Computer Methods and Programs in Biomedicine
204,@article: YANG2022106616,3D multi-scale residual fully convolutional neural network for segmentation of extremely large-sized kidney tumor,Ehwa Yang and Chan Kyo Kim and Yi Guan and Bang-Bon Koo and Jae-Hun Kim,2022,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260722000013,https://doi.org/10.1016/j.cmpb.2022.106616,Background and objecti,"Kidney, Kidney tumor, Medical image, Segmentation, Deep learning, Fully convolutional neural network",106616,,Computer Methods and Programs in Biomedicine
205,@article: CHEN2022106580,TypeSeg: A type-aware encoder-decoder network for multi-type ultrasound images co-segmentation,Fang Chen and Haoran Ye and Daoqiang Zhang and Hongen Liao,2022,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721006544,https://doi.org/10.1016/j.cmpb.2021.106580,Purpo,"Multi-type ultrasound images, Type-aware information, Encoder-decoder network",106580,,Computer Methods and Programs in Biomedicine
206,@article: WILDEBOER2020105316,Artificial intelligence in multiparametric prostate cancer imaging with focus on deep-learning methods,Rogier R. Wildeboer and Ruud J.G. {van Sloun} and Hessel Wijkstra and Massimo Mischi,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260719310442,https://doi.org/10.1016/j.cmpb.2020.105316,"Prostate cancer represents today the most typical example of a pathology whose diagnosis requires multiparametric imaging, a strategy where multiple imaging techniques are combined to reach an acceptable diagnostic performance. However, the reviewing, weighing and coupling of multiple images not only places additional burden on the radiologist, it also complicates the reviewing process. Prostate cancer imaging has therefore been an important target for the development of computer-aided diagnostic (CAD) tools. In this survey, we discuss the advances in CAD for prostate cancer over the last decades with special attention to the deep-learning techniques that have been designed in the last few years. Moreover, we elaborate and compare the methods employed to deliver the CAD output to the operator for further medical decision making","Artificial intelligence, Computer-aided diagnosis, Computer-aided detection, Machine learning, Prostate cancer, Multiparametric imaging, Magnetic resonance imaging, Ultrasound",105316,,Computer Methods and Programs in Biomedicine
207,@article: LIU2021106269,ECG quality assessment based on hand-crafted statistics and deep-learned S-transform spectrogram features,GUOYANG LIU and XIAO HAN and LAN TIAN and WEIDONG ZHOU and HUI LIU,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721003436,https://doi.org/10.1016/j.cmpb.2021.106269,"Background and Objective Electrocardiogram (ECG) quality assessment is significant for automatic diagnosis of cardiovascular disease and reducing the massive workload of reviewing continuous ECGs. Hence, how to design an appropriate algorithm for objectively evaluating the multi-lead ECG recordings is particularly important. Despite the deep learning methods performing well in many fields, as a data-driven method, it may not be entirely suitable for ECG analysis due to the difficulty in obtaining sufficient data and the low signal-to-noise ratio of ECG recordings. In this study, with the aim of providing an accurate and automatic ECG quality assessment scheme, we propose an innovative ECG quality assessment algorithm based on hand-crafted statistical features and deep-learned spectral features. Methods In this paper, a novel approach, combining the deep-learned Stockwell transform (S-Transform) spectrogram features and hand-crafted statistical features, is proposed for ECG quality assessment. Firstly, a double-input convolutional neural network (CNN) is established. Then, the S-Transform with a novel online augmentation scheme is performed on the multi-lead raw ECG signal received from one input layer to obtain proper time-frequency representation. After that, the CNN with three convolutional layers is employed to extract robust deep-learned features automatically. Simultaneously, the hand-crafted statistical features, including lead-fall, baseline drift, and R peak features, are calculated and fed into another input layer for feature fusion training. Finally, the deep-learned and hand-crafted features are concatenated and further fused by a fully connected layer for quality classification. Furthermore, a log-odds analysis scheme combining with a gradient-based method can localize the abnormal zone in time, frequency, and spatial domains. Results and Conclusion Our proposed method is evaluated on a publicly available database with 10-fold cross-validation. The experimental results demonstrate that the proposed assessment algorithm reached a mean accuracy of 93.09%, a mean F1-score of 0.8472, and a sensitivity of 0.9767. Moreover, comprehensive experiments indicate that the fusion of CNN features and statistical features has complementary advantages and ideal interpretability, achieving end-to-end multi-lead ECG assessment with satisfying performance","Stockwell transform, Feature fusion, Convolutional neural network, ECG quality assessment",106269,,Computer Methods and Programs in Biomedicine
208,@article: DIRVANAUSKAS2019161,Embryo development stage prediction algorithm for automated time lapse incubators,Darius Dirvanauskas and Rytis Maskeliunas and Vidas Raudonis and Robertas Damasevicius,2019,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260718311921,https://doi.org/10.1016/j.cmpb.2019.05.027,Background and Objecti,"Embryo classification, Image analysis, Neural network, CNN",161-174,,Computer Methods and Programs in Biomedicine
209,@article: LI2022106564,Automatic location scheme of anatomical landmarks in 3D head MRI based on the scale attention hourglass network,Sai Li and Qiong Gong and Haojiang Li and Shuchao Chen and Yifei Liu and Guangying Ruan and Lin Zhu and Lizhi Liu and Hongbo Chen,2022,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721006386,https://doi.org/10.1016/j.cmpb.2021.106564,Background and Objecti,"Anatomical landmark, Medical image, Scale attention hourglass network, Full convolutional neural network",106564,,Computer Methods and Programs in Biomedicine
210,@article: OKSUZ2021105909,Brain MRI artefact detection and correction using convolutional neural networks,Ilkay Oksuz,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260720317429,https://doi.org/10.1016/j.cmpb.2020.105909,"Background and Objective: Brain MRI is one of the most commonly used diagnostic imaging tools to detect neurodegenerative disease. Diagnostic image quality is a key factor to enable robust image analysis algorithms developed for downstream tasks such as segmentation. In clinical practice, one of the main challenges is the presence of image artefacts, which can lead to low diagnostic image quality. Methods: In this paper, we propose using dense convolutional neural networks to detect and a residual U-net architecture to correct motion related brain MRI artefacts. We first generate synthetic artefacts using an MR physics based corruption strategy. Then, we use a detection strategy based on dense convolutional neural network to detect artefacts. The detected artefacts are corrected using a residual U-net network trained on corrupted data. Results: Our pipeline for detection and correction of artefacts is capable of reaching not only better quality image quality, but also better segmentation accuracy of stroke segmentation. The algorithm is validated using 28 cases brain MRI stroke segmentation dataset and showed an accuracy of 97.8% for detecting artefacts in our experiments. We also illustrated the improved image quality and segmentation accuracy with the proposed correction algorithm. Conclusions: Ensuring high image quality and high segmentation quality jointly can improve the automatic image analysis pipelines and reduce the influence of low image quality on final prognosis. With this work, we illustrate a performance analysis on brain MRI stroke segmentation","Brain MRI, Artefact detection, Convolutional neural networks, Stroke segmentation",105909,,Computer Methods and Programs in Biomedicine
211,@article: HERNANDEZ2021106443,Algorithms and methods for computerized analysis of mammography images in breast cancer risk assessment,Angie Hernández and David A. Miranda and Said Pertuz,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721005174,https://doi.org/10.1016/j.cmpb.2021.106443,"Background and objectives: The computerized analysis of mammograms for the development of quantitative biomarkers is a growing field with applications in breast cancer risk assessment. Computerized image analysis offers the possibility of using different methods and algorithms to extract additional information from screening and diagnosis images to aid in the assessment of breast cancer risk. In this work, we review the algorithms and methods for the automated, computerized analysis of mammography images for the task mentioned, and discuss the main challenges that the development and improvement of these methods face today. Methods: We review the recent progress in two main branches of mammography-based risk assessment: parenchymal analysis and breast density estimation, including performance indicators of most of the studies considered. Parenchymal analysis methods are divided into feature-based methods and deep learning-based methods; breast density methods are grouped into area-based, volume-based, and breast categorization methods. Additionally, we identify the challenges that these study fields currently face. Results: Parenchymal analysis using deep learning algorithms are on the rise, with some studies showing high-performance indicators, such as an area under the receiver operating characteristic curve of up to 90. Methods for risk assessment using breast density report a wider variety of performance indicators; however, we can also identify that the approaches using deep learning methods yield high performance in each of the subdivisions considered. Conclusions: Both breast density estimation and parenchymal analysis are promising tools for the task of breast cancer risk assessment; deep learning methods have shown performance comparable or superior to the other considered methods. All methods considered face challenges such as the lack of objective comparison between them and the lack of access to datasets from different populations","Mammography, Risk assessment, Breast density, Parenchymal analysis",106443,,Computer Methods and Programs in Biomedicine
212,@article: MORALES2021105788,Retinal layer segmentation in rodent OCT images: Local intensity profiles & fully convolutional neural networks,Sandra Morales and Adrián Colomer and José M. Mossi and Rocío {del Amor} and David Woldbye and Kristian Klemp and Michael Larsen and Valery Naranjo,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260720316217,https://doi.org/10.1016/j.cmpb.2020.105788,"Background and Objective: Optical coherence tomography (OCT) is a useful technique to monitor retinal layer state both in humans and animal models. Automated OCT analysis in rats is of great relevance to study possible toxic effect of drugs and other treatments before human trials. In this paper, two different approaches to detect the most significant retinal layers in a rat OCT image are presented. Methods: One approach is based on a combination of local horizontal intensity profiles along with a new proposed variant of watershed transformation and the other is built upon an encoder-decoder convolutional network architecture. Results: After a wide validation, an averaged absolute distance error of 3.77 ± 2.59 and 1.90 ± 0.91 µm is achieved by both approaches, respectively, on a batch of the rat OCT database. After a second test of the deep-learning-based method using an unseen batch of the database, an averaged absolute distance error of 2.67 ± 1.25 µm is obtained. The rat OCT database used in this paper is made publicly available to facilitate further comparisons. Conclusions: Based on the obtained results, it was demonstrated the competitiveness of the first approach since outperforms the commercial Insight image segmentation software (Phoenix Research Labs) as well as its utility to generate labelled images for validation purposes speeding significantly up the ground truth generation process. Regarding the second approach, the deep-learning-based method improves the results achieved by the more conventional method and also by other state-of-the-art techniques. In addition, it was verified that the results of the proposed network can be generalized to new rat OCT images","Optical coherence tomography, Rodent OCT, Rat OCT, Layer segmentation, Convolutional neural networks, Intensity profile",105788,,Computer Methods and Programs in Biomedicine
213,@article: DU2022106483,Classification of Imbalanced Electrocardiosignal Data using Convolutional Neural Network,Chaofan Du and Peter Xiaoping Liu and Minhua Zheng,2022,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721005575,https://doi.org/10.1016/j.cmpb.2021.106483,"Background and objective: In the application of wearable heart-monitors, it is of great significance to analyze electrocardiogram (ECG) signals for anomaly detection. ECG arrhythmia classification remains an open problem in that it cannot easily recognize data from minority classes due to the imbalanced dataset and particular characteristic of the time series signal. In this study, a novel method is presented as a possible solution to imbalanced classification problems. Methods: An improved data augmentation method based on variational auto-encoder (VAE) and auxiliary classifier generative adversarial network (ACGAN) is implemented to address the difficulties resulting from the imbalanced dataset. Based on the augmented dataset, convolutional neural network (CNN) classifiers are employed to automatically recognize arrhythmias using two-dimensional ECG images. Results: In experimental studies conducted with the MIT-BIH arrhythmia database, the proposed method achieves 98.45% accuracy and 97.03% sensitivity. The sensitivities of two minority classes achieve 95.83% and 97.37%, respectively. Conclusion: In imbalanced classification, the sensitivity of minority class is a key evaluation indicator. One of the significant contributions of this study is that the proposed method can obtain higher sensitivity of minority class. The experimental results demonstrate that the proposed method for ECG arrhythmia calssification under imbalanced data has better performance compared with traditional cropping augmentation methods and traditional classifiers","Electrocardiogram arrhythmia, Imbalanced datasets, Convolutional nerual network, Data augmentation",106483,,Computer Methods and Programs in Biomedicine
214,@article: SILVARODRIGUEZ2020105637,Going deeper through the Gleason scoring scale: An automatic end-to-end system for histology prostate grading and cribriform pattern detection,Julio Silva-Rodríguez and Adrián Colomer and María A. Sales and Rafael Molina and Valery Naranjo,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S016926072031470X,https://doi.org/10.1016/j.cmpb.2020.105637,Background and Objecti,"Prostate cancer, Gleason, Cribriform, Whole side images, Convolutional neural networks, Deep learning",105637,,Computer Methods and Programs in Biomedicine
215,@article: LI2020105518,Mass detection in mammograms by bilateral analysis using convolution neural network,Yanfeng Li and Linlin Zhang and Houjin Chen and Lin Cheng,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260719314919,https://doi.org/10.1016/j.cmpb.2020.105518,Background and objecti,"Image registration, Self-supervised learning, Bilateral mammograms, Mass detection, Deep learning",105518,,Computer Methods and Programs in Biomedicine
216,@article: ARCHILA2022106607,"A multimodal Parkinson quantification by fusing eye and gait motion patterns, using covariance descriptors, from non-invasive computer vision",John Archila and Antoine Manzanera and Fabio Martínez,2022,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721006817,https://doi.org/10.1016/j.cmpb.2021.106607,"Background and objective: Parkinson’s disease (PD) is a motor neurodegenerative disease principally manifested by motor disabilities, such as postural instability, bradykinesia, tremor, and stiffness. In clinical practice, there exist several diagnostic rating scales that coarsely allow the measurement, characterization and classification of disease progression. These scales, however, are only based on strong changes in kinematic patterns, and the classification remains subjective, depending on the expertise of physicians. In addition, even for experts, disease analysis based on independent classical motor patterns lacks sufficient sensitivity to establish disease progression. Consequently, the disease diagnosis, stage, and progression could be affected by misinterpretations that lead to incorrect or inefficient treatment plans. This work introduces a multimodal non-invasive strategy based on video descriptors that integrate patterns from gait and eye fixation modalities to assist PD quantification and to support the diagnosis and follow-up of the patient. The multimodal representation is achieved from a compact covariance descriptor that characterizes postural and time changes of both information sources to improve disease classification. Methods: A multimodal approach is introduced as a computational method to capture movement abnormalities associated with PD. Two modalities (gait and eye fixation) are recorded in markerless video sequences. Then, each modality sequence is represented, at each frame, by primitive features composed of (1) kinematic measures extracted from a dense optical flow, and (2) deep features extracted from a convolutional network. The spatial distributions of these characteristics are compactly coded in covariance matrices, making it possible to map each particular dynamic in a Riemannian manifold. The temporal mean covariance is then computed and submitted to a supervised Random Forest algorithm to obtain a disease prediction for a particular patient. The fusion of the covariance descriptors and eye movements integrating deep and kinematic features is evaluated to assess their contribution to disease quantification and prediction. In particular, in this study, the gait quantification is associated with typical patterns observed by the specialist, while ocular fixation, associated with early disease characterization, complements the analysis. Results: In a study conducted with 13 control subjects and 13 PD patients, the fusion of gait and ocular fixation, integrating deep and kinematic features, achieved an average accuracy of 100% for early and late fusion. The classification probabilities show high confidence in the prediction diagnosis, the control subjects probabilities being lower than 0.27 with early fusion and 0.3 with late fusion, and those of the PD patients, being higher than 0.62 with early fusion and 0.51 with late fusion. Furthermore, it is observed that higher probability outputs are correlated with more advanced stages of the disease, according to the H&Y scale. Conclusions: A novel approach for fusing motion modalities captured in markerless video sequences was introduced. This multimodal integration had a remarkable discrimination performance in a study conducted with PD and control patients. The representation of compact covariance descriptors from kinematic and deep features suggests that the proposed strategy is a potential tool to support diagnosis and subsequent monitoring of the disease. During fusion it was observed that devoting major attention to eye fixational patterns may contribute to a better quantification of the disease, especially at stage 2","Parkinson, Multimodal approach, Temporal mean covariance, Deep features, Kinematic features",106607,,Computer Methods and Programs in Biomedicine
217,@article: ESTEBAN2019303,A new optical density granulometry-based descriptor for the classification of prostate histological images using shallow and deep Gaussian processes,Ángel E. Esteban and Miguel López-Pérez and Adrián Colomer and María A. Sales and Rafael Molina and Valery Naranjo,2019,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260719303906,https://doi.org/10.1016/j.cmpb.2019.07.003,Background and objecti,"Prostate cancer, Histopathological images, Gaussian processes, Variational inference, Granulometries, Deep Gaussian processes",303-317,,Computer Methods and Programs in Biomedicine
218,@article: TORRES2022106629,A review of image processing methods for fetal head and brain analysis in ultrasound images,Helena R. Torres and Pedro Morais and Bruno Oliveira and Cahit Birdir and Mario Rüdiger and Jaime C. Fonseca and João L. Vilaça,2022,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260722000141,https://doi.org/10.1016/j.cmpb.2022.106629,Background and objecti,"Brain structures analysis, Anatomical planes, Fetal ultrasound, Head analysis, Neurodevelopment",106629,,Computer Methods and Programs in Biomedicine
219,@article: HUANG2020105115,Two stage residual CNN for texture denoising and structure enhancement on low dose CT image,Liangliang Huang and Huiyan Jiang and Shaojie Li and Zhiqi Bai and Jitong Zhang,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260719301038,https://doi.org/10.1016/j.cmpb.2019.105115,Background and objecti,"Image denoising, Low dose CT, Two stage residual CNN, Normal dose CT model",105115,,Computer Methods and Programs in Biomedicine
220,@article: SHEN2019105012,Learning from adversarial medical images for X-ray breast mass segmentation,Tianyu Shen and Chao Gou and Fei-Yue Wang and Zilong He and Weiguo Chen,2019,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260719304468,https://doi.org/10.1016/j.cmpb.2019.105012,Background and Objecti,"Medical image synthesis, Generative adversarial network, X-ray breast mass, Lesion segmentation",105012,,Computer Methods and Programs in Biomedicine
221,@article: CUI2021106142,Multiscale attention guided U-Net architecture for cardiac segmentation in short-axis MRI images,Hengfei Cui and Chang Yuwen and Lei Jiang and Yong Xia and Yanning Zhang,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721002170,https://doi.org/10.1016/j.cmpb.2021.106142,"Background and Objective: Automatic cardiac segmentation plays an utmost role in the diagnosis and quantification of cardiovascular diseases. Methods: This paper proposes a new cardiac segmentation method in short-axis Magnetic Resonance Imaging (MRI) images, called attention U-Net architecture with input image pyramid and deep supervised output layers (AID), which can fully-automatically learn to pay attention to target structures of various sizes and shapes. During each training process, the model continues to learn how to emphasize the desired features and suppress irrelevant areas in the original images, effectively improving the accuracy of cardiac segmentation. At the same time, we introduce the Focal Tversky Loss (FTL), which can effectively solve the problem of high imbalance in the amount of data between the target class and the background class during cardiac image segmentation. In order to obtain a better representation of intermediate features, we add a multi-scale input pyramid to the attention network. Results: The proposed cardiac segmentation technique is tested on the public Left Ventricle Segmentation Challenge (LVSC) dataset, which is shown to achieve 0.75, 0.87 and 0.92 for Jaccard Index, Sensitivity and Specificity, respectively. Experimental results demonstrate that the proposed method is able to improve the segmentation accuracy compared with the standard U-Net, and achieves comparable performance to the most advanced fully-automated methods. Conclusions: Given its effectiveness and advantages, the proposed method can facilitate cardiac segmentation in short-axis MRI images in clinical practice","Short-axis MRI, Cardiac segmentation, Attention U-Net, Focal Tversky loss, Multi-scale",106142,,Computer Methods and Programs in Biomedicine
222,@article: LIU2020105639,Using the VQ-VAE to improve the recognition of abnormalities in short-duration 12-lead electrocardiogram records,Han Liu and Zhengbo Zhao and Xiao Chen and Rong Yu and Qiang She,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260720314723,https://doi.org/10.1016/j.cmpb.2020.105639,Background and Objecti,"Electrocardiogram, Artificial intelligence, Deep learning, Data augmentation",105639,,Computer Methods and Programs in Biomedicine
223,@article: LACALLE2021105837,SpheroidJ: An Open-Source Set of Tools for Spheroid Segmentation,David Lacalle and Héctor Alfonso Castro-Abril and Teodora Randelovic and César Domínguez and Jónathan Heras and Eloy Mata and Gadea Mata and Yolanda Méndez and Vico Pascual and Ignacio Ochoa,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260720316709,https://doi.org/10.1016/j.cmpb.2020.105837,Background and objectiv,"Spheroids, Segmentation, Deep Learning, ImageJ, Java, Python",105837,,Computer Methods and Programs in Biomedicine
224,@article: WANG201993,A RR interval based automated apnea detection approach using residual network,Lei Wang and Youfang Lin and Jing Wang,2019,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260719300185,https://doi.org/10.1016/j.cmpb.2019.05.002,Background and Objecti,"Sleep apnea, Electrocardiogram (ECG), RR Interval, Residual network, Deep learning",93-104,,Computer Methods and Programs in Biomedicine
225,@article: CIDMEJIAS2021105958,A deep learning approach using synthetic images for segmenting and estimating 3D orientation of nanoparticles in EM images,Antón Cid-Mejías and Raúl Alonso-Calvo and Helena Gavilán and José Crespo and Víctor Maojo,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S016926072100033X,https://doi.org/10.1016/j.cmpb.2021.105958,"Background and objective: Nanoparticles present properties that can be applied to a wide range of fields such as biomedicine, electronics or optics. The type of properties depends on several characteristics, being some of them related with the particle structure. A proper characterization of nanoparticles is crucial since it could affect their applications. To characterize a particle shape and size, the nanotechnologists employ Electron Microscopy (EM) to obtain images of nanoparticles and perform measures over them. This task could be tedious, repetitive and slow, we present a Deep Learning method based on Convolutional Neural Networks (CNNs) to detect, segment, infer orientations and reconstruct microscope images of nanoparticles. Since machine learning algorithms depend on annotated data and there is a lack of annotated datasets of nanoparticles, our work makes use of artificial datasets of images resembling real nanoparticles photographs. Methods: Our work is divided into three tasks. Firstly, a method to create annotated datasets of artificial images resembling Scanning Electron Microscope (SEM). Secondly, two models of convolutional neural networks are trained using the artificial datasets previously generated, the first one is in charge of the detection and segmentation of the nanoparticles while the second one will infer the nanoparticle orientation. Finally, the 3D reconstruction module will recreate in a 3D scene the set of detected particles. Results: We have tested our method with five different shapes of basic nanoparticles: spheres, cubes, ellipsoids, hexagonal discs and octahedrons. An analysis of the reconstructions was conducted by manually comparing each of them with the real images. The results obtained have been promising, the particles are segmented and reconstructed accordingly to their shapes and orientations. Conclusions: We have developed a method for nanoparticle detection and segmentation in microscope images. Moreover, we can also infer an approximation of the 3D orientation of the particles and, in conjunction with the detections, create a 3D reconstruction of the photographs. The novelty of our approximation lies in the dataset used. Instead of using annotated images, we have created the datasets simulating the microscope images by using basic geometrical objects that imitate real nanoparticles","Nanoparticles, Detection, Segmentation, Orientation inference, Electron microscopy, 3D reconstruction",105958,,Computer Methods and Programs in Biomedicine
226,@article: DAVARIDOLATABADI2017117,Automated diagnosis of coronary artery disease (CAD) patients using optimized SVM,Azam {Davari Dolatabadi} and Siamak Esmael Zadeh Khadem and Babak Mohammadzadeh Asl,2017,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260716306605,https://doi.org/10.1016/j.cmpb.2016.10.011,Background and objecti,"Electrocardiogram, Coronary artery disease, Hearth rate variability, Principal component analysis, Support vector machines",117-126,,Computer Methods and Programs in Biomedicine
227,@article: DEB2022106658,An adaptive registration algorithm for zebrafish larval brain images,Shoureen Deb and Natascia Tiso and Enrico Grisan and Ananda S. Chowdhury,2022,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260722000438,https://doi.org/10.1016/j.cmpb.2022.106658,Background and Objecti,"Zebrafish imaging, Adaptive registration, FFD-Demons synergism",106658,,Computer Methods and Programs in Biomedicine
228,@article: LI2018205,An effective computer aided diagnosis model for pancreas cancer on PET/CT images,Siqi Li and Huiyan Jiang and Zhiguo Wang and Guoxu Zhang and Yu-dong Yao,2018,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260718305030,https://doi.org/10.1016/j.cmpb.2018.09.001,"Background and objective: Pancreas cancer is a digestive tract tumor with high malignancy, which is difficult for diagnosis and treatment at early time. To this end, this paper proposes a computer aided diagnosis (CAD) model for pancreas cancer on Positron Emission Tomography/Computed Tomography (PET/CT) images. Methods: There are three essential steps in the proposed CAD model, including (1) pancreas segmentation, (2) feature extraction and selection, (3) classifier design, respectively. First, pancreas segmentation is performed using simple linear iterative clustering (SLIC) on CT pseudo-color images generated by the gray interval mapping (GIP) method. Second, dual threshold principal component analysis (DT-PCA) is developed to select the most beneficial feature combination, which not only considers principal features but also integrates some non-principal features into a new polar angle representation. Finally, a hybrid feedback-support vector machine-random forest (HFB-SVM-RF) model is designed to identify normal pancreas or pancreas cancer and the key is to use 8 types of SVMs to establish the decision trees of RF. Results: The proposed CAD model is tested on 80 cases of PET/CT data (from General Hospital of Shenyang Military Area Command) and achieves the average pancreas cancer identification accuracy of 96.47%, sensibility of 95.23% and specificity of 97.51%, respectively. In addition, the proposed pancreas segmentation method is also evaluated using a public dataset with 82 3D CT scans from the National Institutes of Health (NIH) Clinical Center and its performance is found to surpass other methods, with a mean Dice coefficient of 78.9% and Jaccard index of 65.4%. Conclusions: Collectively, contrast experiments in 10-fold cross validation demonstrate the efficiency and accuracy of the proposed CAD model as well as its performance advantages as compared with related methods","PET/CT Image, Pancreas segmentation, Feature selection, Pancreas cancer identification, Machine learning",205-214,,Computer Methods and Programs in Biomedicine
229,@article: FOLL2021106461,FLIRT: A feature generation toolkit for wearable data,Simon Föll and Martin Maritsch and Federica Spinola and Varun Mishra and Filipe Barata and Tobias Kowatsch and Elgar Fleisch and Felix Wortmann,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721005356,https://doi.org/10.1016/j.cmpb.2021.106461,"Background and Objective: Researchers use wearable sensing data and machine learning (ML) models to predict various health and behavioral outcomes. However, sensor data from commercial wearables are prone to noise, missing, or artifacts. Even with the recent interest in deploying commercial wearables for long-term studies, there does not exist a standardized way to process the raw sensor data and researchers often use highly specific functions to preprocess, clean, normalize, and compute features. This leads to a lack of uniformity and reproducibility across different studies, making it difficult to compare results. To overcome these issues, we present FLIRT: A Feature Generation Toolkit for Wearable Data; it is an open-source Python package that focuses on processing physiological data specifically from commercial wearables with all its challenges from data cleaning to feature extraction. Methods: FLIRT leverages a variety of state-of-the-art algorithms (e.g., particle filters, ML-based artifact detection) to ensure a robust preprocessing of physiological data from wearables. In a subsequent step, FLIRT utilizes a sliding-window approach and calculates a feature vector of more than 100 dimensions – a basis for a wide variety of ML algorithms. Results: We evaluated FLIRT on the publicly available WESAD dataset, which focuses on stress detection with an Empatica E4 wearable. Preprocessing the data with FLIRT ensures that unintended noise and artifacts are appropriately filtered. In the classification task, FLIRT outperforms the preprocessing baseline of the original WESAD paper. Conclusion: FLIRT provides functionalities beyond existing packages that can address unmet needs in physiological data processing and feature generation: (a) integrated handling of common wearable file formats (e.g., Empatica E4 archives), (b) robust preprocessing, and (c) standardized feature generation that ensures reproducibility of results. Nevertheless, while FLIRT comes with a default configuration to accommodate most situations, it offers a highly configurable interface for all of its implemented algorithms to account for specific needs","Physiological signal processing, Wearable sensors, Artifact detection, Signal filtering, Machine learning, Feature engineering",106461,,Computer Methods and Programs in Biomedicine
230,@article: LIU2021106254,Magnetic resonance image diagnosis of femoral head necrosis based on ResNet18 network,Yan Liu and Guo-rong She and Shu-xaing Chen,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S016926072100328X,https://doi.org/10.1016/j.cmpb.2021.106254,Purpo,"ResNet18, Convolutional neural network, Magnetic Resonance Imaging, Computed Tomography, Early treatment",106254,,Computer Methods and Programs in Biomedicine
231,@article: DING2022106574,Multi-resolution 3D-HOG feature learning method for Alzheimer’s Disease diagnosis,Zhiyuan Ding and Yan Liu and Xu Tian and Wenjing Lu and Zheng Wang and Xiangzhu Zeng and Ling Wang,2022,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721006489,https://doi.org/10.1016/j.cmpb.2021.106574,"Background and Objective: Alzheimer’s Disease (AD) is a progressive irreversible neurodegeneration disease and thus timely identification is critical to delay its progression. Methods: In this work, we focus on the traditional branch to design discriminative feature extraction and selection strategies to achieve explainable AD identification. Specifically, a spatial pyramid based three-dimensional histogram of oriented gradient (3D-HOG) feature learning method is proposed. Both global and local texture changes are included in spatial pyramid 3D-HOG (SPHOG) features for comprehensive analysis. Then a modified wrapper-based feature selection algorithm is introduced to select the discriminative features for AD identification while reduce feature dimensions. Results: Discriminative SPHOG histograms with various resolutions are selected, which can represent the atrophy characteristics of cerebral cortex with promising performance. As subareas corresponding to selected histograms are consistent with clinical experience, explanatory is emphasized and illustrated with Hippocampus. Conclusion: Experimental results illustrate the effectiveness of the proposed method on feature learning based on samples obtained from common dataset and a clinical dataset. The proposed method will be useful for further medical analysis as its explanatory on other region-of-interests (ROIs) of the brain for early diagnosis of AD","Feature learning, Multi-resolution, HOG, Alzheimer’s Disease",106574,,Computer Methods and Programs in Biomedicine
232,@article: MITRA201825,The region of interest localization for glaucoma analysis from retinal fundus image using deep learning,Anirban Mitra and Priya Shankar Banerjee and Sudipta Roy and Somasis Roy and Sanjit Kumar Setua,2018,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260718308381,https://doi.org/10.1016/j.cmpb.2018.08.003,Background and objectiv,"Optic Disc Localization, Anchor Boxes, K-means clustering, Intersection over Union, Convolution Neural Networks, Batch Normalization, Leaky ReLU, Max Pooling, Non-maximum suppression",25-35,,Computer Methods and Programs in Biomedicine
233,@article: KHALIGHI2016180,ISRUC-Sleep: A comprehensive public dataset for sleep researchers,Sirvan Khalighi and Teresa Sousa and José Moutinho Santos and Urbano Nunes,2016,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260715002734,https://doi.org/10.1016/j.cmpb.2015.10.013,"To facilitate the performance comparison of new methods for sleep patterns analysis, datasets with quality content, publicly-available, are very important and useful. We introduce an open-access comprehensive sleep dataset, called ISRUC-Sleep. The data were obtained from human adults, including healthy subjects, subjects with sleep disorders, and subjects under the effect of sleep medication. Each recording was randomly selected between PSG recordings that were acquired by the Sleep Medicine Centre of the Hospital of Coimbra University (CHUC). The dataset comprises three groups of data: (1) data concerning 100 subjects, with one recording session per subject; (2) data gathered from 8 subjects; two recording sessions were performed per subject, and (3) data collected from one recording session related to 10 healthy subjects. The polysomnography (PSG) recordings, associated with each subject, were visually scored by two human experts. Comparing the existing sleep-related public datasets, ISRUC-Sleep provides data of a reasonable number of subjects with different characteristics such as: data useful for studies involving changes in the PSG signals over time; and data of healthy subjects useful for studies involving comparison of healthy subjects with the patients, suffering from sleep disorders. This dataset was created aiming to complement existing datasets by providing easy-to-apply data collection with some characteristics not covered yet. ISRUC-Sleep can be useful for analysis of new contributions: (i) in biomedical signal processing; (ii) in development of ASSC methods; and (iii) on sleep physiology studies. To evaluate and compare new contributions, which use this dataset as a benchmark, results of applying a subject-independent automatic sleep stage classification (ASSC) method on ISRUC-Sleep dataset are presented","Sleep dataset, Automatic sleep stage classification, Polysomnographic signals, Effects of sleep disorder, Medication effects, Feature selection",180-192,,Computer Methods and Programs in Biomedicine
234,@article: ALMASNI2018221,Skin lesion segmentation in dermoscopy images via deep full resolution convolutional networks,Mohammed A. Al-masni and Mugahed A. Al-antari and Mun-Taek Choi and Seung-Moo Han and Tae-Seong Kim,2018,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260718304267,https://doi.org/10.1016/j.cmpb.2018.05.027,Background and objecti,"Deep learning, Dermoscopy, Full resolution convolutional network (FrCN), Melanoma, Skin lesion segmentation",221-231,,Computer Methods and Programs in Biomedicine
235,@article: XIANG2019275,AMC-Net: Asymmetric and multi-scale convolutional neural network for multi-label HPA classification,Shao Xiang and Qiaokang Liang and Yucheng Hu and Pen Tang and Gianmarc Coppola and Dan Zhang and Wei Sun,2019,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260719307527,https://doi.org/10.1016/j.cmpb.2019.07.009,Background and objectiv,"Human protein atlas, Multi-label classification, Deep learning, Convolutional neural network",275-287,,Computer Methods and Programs in Biomedicine
236,@article: TEKCHANDANI2020105478,Performance improvement of mediastinal lymph node severity detection using GAN and Inception network,Hitesh Tekchandani and Shrish Verma and Narendra Londhe,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260719319790,https://doi.org/10.1016/j.cmpb.2020.105478,Background and objecti,"Lymph Node, Severity, Malignant, Benign, GAN, Inception Network",105478,,Computer Methods and Programs in Biomedicine
237,@article: MOUELHI201837,Fast unsupervised nuclear segmentation and classification scheme for automatic allred cancer scoring in immunohistochemical breast tissue images,Aymen Mouelhi and Hana Rmili and Jaouher Ben Ali and Mounir Sayadi and Raoudha Doghri and Karima Mrad,2018,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260718301950,https://doi.org/10.1016/j.cmpb.2018.08.005,Background and objecti,"Breast cancer, Immunohistochemistry, Nuclei segmentation, Morphological operators, Color separation methods, Automatic scoring",37-51,,Computer Methods and Programs in Biomedicine
238,@article: RAK201947,Combining convolutional neural networks and star convex cuts for fast whole spine vertebra segmentation in MRI,Marko Rak and Johannes Steffen and Anneke Meyer and Christian Hansen and Klaus–Dietz Tönnies,2019,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260718307417,https://doi.org/10.1016/j.cmpb.2019.05.003,"Background and Objective: We propose an automatic approach for fast vertebral body segmentation in three-dimensional magnetic resonance images of the whole spine. Previous works are limited to the lower thoracolumbar section and often take minutes to compute, which is problematic in clinical routine, for study data sets with numerous subjects or when the cervical or upper thoracic spine is to be analyzed. Methods: We address these limitations by a novel graph cut formulation based on vertebra patches extracted along the spine. For each patch, our formulation incorporates appearance and shape information derived from a task-specific convolutional neural network as well as star-convexity constraints that ensure a topologically correct segmentation of each vertebra. When segmenting vertebrae individually, ambiguities will occur due to overlapping segmentations of adjacent vertebrae. We tackle this problem by novel non-overlap constraints between neighboring patches based on so-called encoding swaps. The latter allow us to obtain a globally optimal multi-label segmentation of all vertebrae in polynomial time. Results: We validated our approach on two data sets. The first contains T1- and T2-weighted whole spine images of 64 subjects with varying health conditions. The second comprises 23 T2-weighted thoracolumbar images of young healthy adults and is publicly available. Our method yielded Dice coefficients of 93.8  ±  2.6% and 96.0  ±  1.0% for both data sets with a run time of 1.35  ±  0.08 s and 0.90  ±  0.03 s per vertebra on consumer hardware. A complete whole spine segmentation took 32.4 ± 1.92 s on average. Conclusions: Our results are superior to those of previous works at a fraction of their run time, which illustrates the efficiency and effectiveness of our whole spine segmentation approach","Magnetic resonance, Spine analysis, Vertebra segmentation, Graph cuts, Neural networks",47-56,,Computer Methods and Programs in Biomedicine
239,@article: ALONSO2012346,A Java simulator of Rescorla and Wagner's prediction error model and configural cue extensions,Eduardo Alonso and Esther Mondragón and Alberto Fernández,2012,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260712000429,https://doi.org/10.1016/j.cmpb.2012.02.004,"In this paper we present the “R&W Simulator” (version 3.0), a Java simulator of Rescorla and Wagner's prediction error model of learning. It is able to run whole experimental designs, and compute and display the associative values of elemental and compound stimuli simultaneously, as well as use extra configural cues in generating compound values; it also permits change of the US parameters across phases. The simulator produces both numerical and graphical outputs, and includes a functionality to export the results to a data processor spreadsheet. It is user-friendly, and built with a graphical interface designed to allow neuroscience researchers to input the data in their own “language”. It is a cross-platform simulator, so it does not require any special equipment, operative system or support program, and does not need installation. The “R&W Simulator” (version 3.0) is available free","Java simulator, Open-source, Platform independent, Prediction error learning, Classical conditioning, Compound stimuli, Configural cue",346-355,,Computer Methods and Programs in Biomedicine
240,@article: LIAO2021106189,Deep learning for registration of region of interest in consecutive wireless capsule endoscopy frames,Chao Liao and Chengliang Wang and Jianying Bai and Libin Lan and Xing Wu,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721002637,https://doi.org/10.1016/j.cmpb.2021.106189,"Background and objective: Functional gastrointestinal disorders (FGIDs) are reported as worldwide gastrointestinal (GI) diseases. GI motility assessment can assist the diagnosis of patients with intestine motility dysfunction. Wireless capsule endoscopy (WCE) can acquire images in the gastrointestinal (GI) tract including the small intestine where other conventional endoscopes cannot penetrate, and WCE images can reveal GI motility. To generally analyze WCE frames, the high-precision registration of consecutive WCE frames is an absolute necessity. It is difficult and meaningless to register entire WCE frames on a pixel level due to the unpredictable and massive non-rigid deformation between consecutive frames, the low quality of imaging and the complex intestinal environment. Thus, the registration of region of interest (ROI) functioning in a feature level has more significance than entire frame registration. Methods: In this paper we present Timecylce-WCE, an end-to-end automatic registration approach of ROIs on WCE images. The clinicians can determine a ROI by drawing a bounding box in any WCE frame to be registered. This proposed approach is based on a deep-learning model of time-consistency in recurrent-registering, skip-registering and self-registering cycle, and it is fully unsupervised without any label. We incorporate the global correlation map with the local correlation map in matching the features, and a novel overall loss function is designed to enable the convergence of the model. As the output, a thin-plate spline (TPS) transformed region in the template frame is highly aligned with the query ROI in a finer-grained level. To the best of our knowledge this is the first time that a deep-learning-based registration method is proposed for WCE imaging motion. Results: To highlight the effectiveness of the proposed approach, our proposed method is compared with the existing non-deep-learning methods and tested in a validation dataset with labeled matching points. The presented method resulted in the best PCK@10 (Percentage of Correct Key-points, i.e., the predicted and the true joint is within the threshold - 10 pixels) of 66.49%. We also demonstrate that variants of design improved registration accuracy. Conclusions: From the experimental analysis, it is clear that our proposed method outperforms the other existing methods. This lays the groundwork for subsequent studies, such as GI motility assessment, and WCE image synthesis","Wireless capsule endoscopy (WCE) images, Image registration, Unsupervised, Deep learning",106189,,Computer Methods and Programs in Biomedicine
241,@article: BUENO2020105273,Glomerulosclerosis identification in whole slide images using semantic segmentation,Gloria Bueno and M. Milagro Fernandez-Carrobles and Lucia Gonzalez-Lopez and Oscar Deniz,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260719311381,https://doi.org/10.1016/j.cmpb.2019.105273,"Background and Objective: Glomeruli identification, i.e., detection and characterization, is a key procedure in many nephropathology studies. In this paper, semantic segmentation based on convolutional neural networks (CNN) is proposed to detect glomeruli using Whole Slide Imaging (WSI) follows by a classification CNN to divide the glomeruli into normal and sclerosed. Methods: Comparison between U-Net and SegNet CNNs is performed for pixel-level segmentation considering both a two and three class problem, that is, a) non-glomerular and glomerular structures and b) non-glomerular normal glomerular and sclerotic structures. The two class semantic segmentation result is then used for a CNN classification where glomerular regions are divided into normal and global sclerosed glomeruli. Results: These methods were tested on a dataset composed of 47 WSIs belonging to human kidney sections stained with Periodic Acid Schiff (PAS). The best approach was the SegNet for two class segmentation follows by a fine-tuned AlexNet network to characterize the glomeruli. 98.16% of accuracy was obtained with this process of consecutive CNNs (SegNet-AlexNet) for segmentation and classification. Conclusion: The results obtained demonstrate that the sequential CNN segmentation-classification strategy achieves higher accuracy reducing misclassified cases and therefore being the methodology proposed for glomerulosclerosis detection","Semantic segmentation, Deep learning, Consecutive segmentation-classification CNN, Digital pathology, Glomeruli detection, Sclerotic glomeruli, Segnet, U-Net",105273,,Computer Methods and Programs in Biomedicine
242,@article: VALENTE2017295,Automatic diagnosis of strabismus in digital videos through cover test,Thales Levi Azevedo Valente and João Dallyson Sousa {de Almeida} and Aristófanes Corrêa Silva and Jorge Antonio Meireles Teixeira and Marcelo Gattass,2017,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260716307763,https://doi.org/10.1016/j.cmpb.2017.01.002,"Background and Objective: Medical image processing can contribute to the detection and diagnosis of human body anomalies, and it represents an important tool to assist in minimizing the degree of uncertainty of any diagnosis, while providing specialists with an additional source of diagnostic information. Strabismus is an anomaly that affects approximately 4% of the population. Strabismus modifies vision such that the eyes do not properly align, influencing binocular vision and depth perception. Additionally, it results in aesthetic problems, which can be reversed at any age. However, the use of low cost computational resources to assist in the diagnosis and treatment of strabismus is not yet widely available. This work presents a computational methodology to automatically diagnose strabismus through digital videos featuring a cover test using only a workstation computer to process these videos. Methods: The method proposed was validated in patients with exotropia and consists of eight steps: (1) acquisition, (2) detection of the region surrounding the eyes, (3) identification of the location of the pupil, (4) identification of the location of the limbus, (5) eye movement tracking, (6) detection of the occluder, (7) identification of evidence of the presence of strabismus, and (8) diagnosis. Results: To detect the presence of strabismus, the proposed method achieved a specificity value of 100%, and (2) a sensitivity value of 80%, with 93.33% accuracy in diagnosis of patients with extropia. This procedure was recognized to diagnose strabismus with an accuracy value of 87%, while acknowledging measures lower than 1Δ, and an average error in the deviation measure of 2.57Δ. Conclusions: We demonstrated the feasibility of using computational resources based on image processing techniques to achieve success in diagnosing strabismus by using the cover test. Despite the promising results the proposed method must be validated in a greater volume of video including other types of strabismus","Diagnosis of strabismus, Cover test, Image processing, Digital videos",295-305,,Computer Methods and Programs in Biomedicine
243,@article: ZAHIA2020105726,Dyslexia detection using 3D convolutional neural networks and functional magnetic resonance imaging,Sofia Zahia and Begonya Garcia-Zapirain and Ibone Saralegui and Begoña Fernandez-Ruanova,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260720315595,https://doi.org/10.1016/j.cmpb.2020.105726,"Background and Objectives: Dyslexia is a disorder of neurological origin which affects the learning of those who suffer from it, mainly children, and causes difficulty in reading and writing. When undiagnosed, dyslexia leads to intimidation and frustration of the affected children and also of their family circles. In case no early intervention is given, children may reach high school with serious achievement gaps. Hence, early detection and intervention services for dyslexic students are highly important and recommended in order to support children in developing a positive self-esteem and reaching their maximum academic capacities. This paper presents a new approach for automatic recognition of children with dyslexia using functional magnetic resonance Imaging. Methods: Our proposed system is composed of a sequence of preprocessing steps to retrieve the brain activation areas during three different reading tasks. Conversion to Nifti volumes, adjustment of head motion, normalization and smoothing transformations were performed on the fMRI scans in order to bring all the subject brains into one single model which will enable voxels comparison between each subject. Subsequently, using Statistical Parametric Maps (SPMs), a total of 165 3D volumes containing brain activation of 55 children were created. The classification of these volumes was handled using three parallel 3D Convolutional Neural Network (3D CNN), each corresponding to a brain activation during one reading task, and concatenated in the last two dense layers, forming a single architecture devoted to performing optimized detection of dyslexic brain activation. Additionally, we used 4-fold cross validation method in order to assess the generalizability of our model and control overfitting. Results: Our approach has achieved an overall average classification accuracy of 72.73%, sensitivity of 75%, specificity of 71.43%, precision of 60% and an F1-score of 67% in dyslexia detection. Conclusions: The proposed system has demonstrated that the recognition of dyslexic children is feasible using deep learning and functional magnetic resonance Imaging when performing phonological and orthographic reading tasks","Deep learning, Dyslexia, Functional magnetic resonance Imaging, 3D Convolutional Neural Networks, Computer-aided diagnosis (CAD)",105726,,Computer Methods and Programs in Biomedicine
244,@article: RIBALTALORENZO2019135,Segmenting brain tumors from FLAIR MRI using fully convolutional neural networks,Pablo {Ribalta Lorenzo} and Jakub Nalepa and Barbara Bobek-Billewicz and Pawel Wawrzyniak and Grzegorz Mrukwa and Michal Kawulok and Pawel Ulrych and Michael P. Hayball,2019,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260718315955,https://doi.org/10.1016/j.cmpb.2019.05.006,Background and Objecti,"Image segmentation, Deep neural network, MRI, Brain tumor",135-148,,Computer Methods and Programs in Biomedicine
245,@article: ALY2021105823,YOLO Based Breast Masses Detection and Classification in Full-Field Digital Mammograms,Ghada Hamed Aly and Mohammed Marey and Safaa Amin El-Sayed and Mohamed Fahmy Tolba,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260720316564,https://doi.org/10.1016/j.cmpb.2020.105823,Background and Objecti,"YOLO based breast mass detection, Anchor boxes, K-means clustering, Full-field digital mammograms, Breast masses classification",105823,,Computer Methods and Programs in Biomedicine
246,@article: BANDEIRADINIZ2018191,Detection of mass regions in mammograms by bilateral analysis adapted to breast density using similarity indexes and convolutional neural networks,João Otávio {Bandeira Diniz} and Pedro Henrique {Bandeira Diniz} and Thales Levi {Azevedo Valente} and Aristófanes {Corrêa Silva} and Anselmo Cardoso {de Paiva} and Marcelo Gattass,2018,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260717304248,https://doi.org/10.1016/j.cmpb.2018.01.007,Background and Objecti,"Bilateral asymmetry, Breast cancer, Computer-aided detection, Convolutional neural network, Deep learning, Similary indexes",191-207,,Computer Methods and Programs in Biomedicine
247,@article: DOMENICONI201620,Cross-organism learning method to discover new gene functionalities,Giacomo Domeniconi and Marco Masseroli and Gianluca Moro and Pietro Pinoli,2016,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260715003259,https://doi.org/10.1016/j.cmpb.2015.12.002,Backgrou,"Biomolecular annotation prediction, Knowledge discovery, Data representation, Discrete matrix completion, Transfer learning, Gene ontology",20-34,,Computer Methods and Programs in Biomedicine
248,@article: MATUSZEWSKI201931,Reducing the U-Net size for practical scenarios: Virus recognition in electron microscopy images,Damian J. Matuszewski and Ida-Maria Sintorn,2019,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260719300859,https://doi.org/10.1016/j.cmpb.2019.05.026,Background and objecti,"Deep learning, Hyper parameter optimization, Hardware integration, Transmission Electron Microscopy",31-39,,Computer Methods and Programs in Biomedicine
249,@article: GUO2021105998,Cerebrovascular segmentation from TOF-MRA based on multiple-U-net with focal loss function,Xiaoyu Guo and Ruoxiu Xiao and Yuanyuan Lu and Cheng Chen and Fei Yan and Kangneng Zhou and Wanzhang He and Zhiliang Wang,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721000730,https://doi.org/10.1016/j.cmpb.2021.105998,Background and Objecti,"Cerebrovascular segmentation, U-net, Focal loss function, Feature fusion",105998,,Computer Methods and Programs in Biomedicine
250,@article: CHOI2021105839,Reproducible and Interpretable Spiculation Quantification for Lung Cancer Screening,Wookjin Choi and Saad Nadeem and Sadegh R. Alam and Joseph O. Deasy and Allen Tannenbaum and Wei Lu,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260720316722,https://doi.org/10.1016/j.cmpb.2020.105839,"Spiculations are important predictors of lung cancer malignancy, which are spikes on the surface of the pulmonary nodules. In this study, we proposed an interpretable and parameter-free technique to quantify the spiculation using area distortion metric obtained by the conformal (angle-preserving) spherical parameterization. We exploit the insight that for an angle-preserved spherical mapping of a given nodule, the corresponding negative area distortion precisely characterizes the spiculations on that nodule. We introduced novel spiculation scores based on the area distortion metric and spiculation measures. We also semi-automatically segment lung nodule (for reproducibility) as well as vessel and wall attachment to differentiate the real spiculations from lobulation and attachment. A simple pathological malignancy prediction model is also introduced. We used the publicly-available LIDC-IDRI dataset pathologists (strong-label) and radiologists (weak-label) ratings to train and test radiomics models containing this feature, and then externally validate the models. We achieved AUC = 0.80 and 0.76, respectively, with the models trained on the 811 weakly-labeled LIDC datasets and tested on the 72 strongly-labeled LIDC and 73 LUNGx datasets; the previous best model for LUNGx had AUC = 0.68. The number-of-spiculations feature was found to be highly correlated (Spearman’s rank correlation coefficient ρ=0.44) with the radiologists’ spiculation score. We developed a reproducible and interpretable, parameter-free technique for quantifying spiculations on nodules. The spiculation quantification measures was then applied to the radiomics framework for pathological malignancy prediction with reproducible semi-automatic segmentation of nodule. Using our interpretable features (size, attachment, spiculation, lobulation), we were able to achieve higher performance than previous models. In the future, we will exhaustively test our model for lung cancer screening in the clinic","Conformal Mapping, Spiculation, Lung Cancer Screening",105839,,Computer Methods and Programs in Biomedicine
251,@article: WIMALARATHNA2021105942,Comparison of machine learning models to classify Auditory Brainstem Responses recorded from children with Auditory Processing Disorder,Hasitha Wimalarathna and Sangamanatha Ankmnal-Veeranna and Chris Allan and Sumit K. Agrawal and Prudence Allen and Jagath Samarabandu and Hanif M. Ladak,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S016926072100016X,https://doi.org/10.1016/j.cmpb.2021.105942,Introducti,"Signal feature extraction, Machine Learning, Auditory Brainstem Responses, Auditory Processing Disorder",105942,,Computer Methods and Programs in Biomedicine
252,@article: XIAO2021105766,Virus identification in electron microscopy images by residual mixed attention network,Chi Xiao and Xi Chen and Qiwei Xie and Guoqing Li and Hao Xiao and Jingdong Song and Hua Han,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260720315996,https://doi.org/10.1016/j.cmpb.2020.105766,"Background and Objective: Virus identification in electron microscopy (EM) images is considered as one of the front-line method in pathogen diagnosis and re-emerging infectious agents. However, the existing methods either focused on the detection of a single virus or required large amounts of manual labeling work to segment virus. In this work, we focus on the task of virus classification and propose an effective and simple method to identify different viruses. Methods: We put forward a residual mixed attention network (RMAN) for virus classification. The proposed network uses channel attention, bottom-up and top-down attention, and incorporates a residual architecture in an end-to-end training manner, which is suitable for dealing with EM virus images and reducing the burden of manual annotation. Results: We validate the proposed network through extensive experiments on a transmission electron microscopy virus image dataset. The top-1 error rate of our RMAN on 12 virus classes is 4.285%, which surpasses that of state-of-the-art networks and even human experts. In addition, the ablation study and the visualization of class activation mapping (CAM) further demonstrate the effectiveness of our method. Conclusions: The proposed automated method contributes to the development of medical virology, which provides virologists with a high-accuracy approach to recognize viruses as well as assist in the diagnosis of viruses","Virus identification, viral morphology, transmission electron microscopy, deep learning, attention mechanism",105766,,Computer Methods and Programs in Biomedicine
253,@article: POLONI2022106581,"Automated detection, selection and classification of hippocampal landmark points for the diagnosis of Alzheimer’s disease",Katia M. Poloni and Ricardo J. Ferrari,2022,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721006556,https://doi.org/10.1016/j.cmpb.2021.106581,"Background and Objective: Alzheimer’s disease (AD) is a neurodegenerative, progressive, and irreversible disease that accounts for up to 80% of all dementia cases. AD predominantly affects older adults, and its clinical diagnosis is a challenging evaluation process, with imprecision rates between 12 and 23%. Structural magnetic resonance (MR) imaging has been widely used in studies related to AD because this technique provides images with excellent anatomical details and information about structural changes induced by the disease in the brain. Current studies are focused on detecting AD in its initial stage, i.e., mild cognitive impairment (MCI), since treatments for preventing or delaying the onset of symptoms is more effective when administered at the early stages of the disease. This study proposes a new technique to perform MR image classification in AD diagnosis using discriminative hippocampal point landmarks among the cognitively normal (CN), MCI, and AD populations. Methods: Our approach, based on a two-level classification, first detects and selects discriminative landmark points from two diagnosis populations based on their matching distance compared to a probabilistic atlas of 3-D labeled landmark points. The points are classified using attributes computed in a spherical support region around each point using information from brain probability image tissues of gray matter, white matter, and cerebrospinal fluid as sources of information. Next, at the second level, the images are classified based on a quantitative evaluation obtained from the first-level classifier outputs. Results: For the CN×MCI experiment, we achieved an AUC of 0.83, an accuracy of 75.58%, with 72.9% of sensitivity and 77.81% of specificity. For the MCI×AD experiment, we achieved an AUC value of 0.73, an accuracy of 69.8%, a sensitivity of 74.09% and specificity of 64.57%. Finally, for the CN×AD, we achieved an AUC of 0.95, an accuracy of 89.24%, with 85.58% of sensitivity and 92.71% of specificity. Conclusions: The obtained classification results are similar to (or even higher than) other studies that classify AD compared to CN individuals and comparable to those classified patients with MCI","Structural hippocampi atrophy, Classification of Alzheimer’s disease, 3-D phase congruency, 3-D atlas of salient points, Magnetic resonance imaging",106581,,Computer Methods and Programs in Biomedicine
254,@article: HEMELINGS2021105920,Pathological myopia classification with simultaneous lesion segmentation using deep learning,Ruben Hemelings and Bart Elen and Matthew B. Blaschko and Julie Jacob and Ingeborg Stalmans and Patrick {De Boever},2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260720317533,https://doi.org/10.1016/j.cmpb.2020.105920,Background and Objectiv,"Pathological myopia, fovea localization, peripapillary atrophy, retinal detachment, convolutional neural network, fundus image, glaucoma",105920,,Computer Methods and Programs in Biomedicine
255,@article: ZHANG2021106448,MBNM: Multi-branch network based on memory features for long-tailed medical image recognition,Ruru Zhang and Haihong E and Lifei Yuan and Jiawen He and Hongxing Zhang and Shengjuan Zhang and Yanhui Wang and Meina Song and Lifei Wang,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721005228,https://doi.org/10.1016/j.cmpb.2021.106448,Background and objectiv,"Imbalanced medical image, Deep learning, Memory features, Fusion model",106448,,Computer Methods and Programs in Biomedicine
256,@article: WU2021106444,A novel combined dynamic ensemble selection model for imbalanced data to detect COVID-19 from complete blood count,Jiachao Wu and Jiang Shen and Man Xu and Minglai Shao,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721005186,https://doi.org/10.1016/j.cmpb.2021.106444,Backgrou,"COVID-19 screening, Imbalanced data, Dynamic ensemble selection, Hybrid multiple clustering and bagging, Candidate classifier generation",106444,,Computer Methods and Programs in Biomedicine
257,@article: CLERIGUES2020105521,Acute and sub-acute stroke lesion segmentation from multimodal MRI,Albert Clèrigues and Sergi Valverde and Jose Bernal and Jordi Freixenet and Arnau Oliver and Xavier Lladó,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260719305899,https://doi.org/10.1016/j.cmpb.2020.105521,"Background and objective. Acute stroke lesion segmentation tasks are of great clinical interest as they can help doctors make better informed time-critical treatment decisions. Magnetic resonance imaging (MRI) is time demanding but can provide images that are considered the gold standard for diagnosis. Automated stroke lesion segmentation can provide with an estimate of the location and volume of the lesioned tissue, which can help in the clinical practice to better assess and evaluate the risks of each treatment. Methods. We propose a deep learning methodology for acute and sub-acute stroke lesion segmentation using multimodal MR imaging. We pre-process the data to facilitate learning features based on the symmetry of brain hemispheres. The issue of class imbalance is tackled using small patches with a balanced training patch sampling strategy and a dynamically weighted loss function. Moreover, a combination of whole patch predictions, using a U-Net based CNN architecture, and high degree of overlapping patches reduces the need for additional post-processing. Results. The proposed method is evaluated using two public datasets from the 2015 Ischemic Stroke Lesion Segmentation challenge (ISLES 2015). These involve the tasks of sub-acute stroke lesion segmentation (SISS) and acute stroke penumbra estimation (SPES) from multiple diffusion, perfusion and anatomical MRI modalities. The performance is compared against state-of-the-art methods with a blind online testing set evaluation on each of the challenges. At the time of submitting this manuscript, our approach is the first method in the online rankings for the SISS (DSC=0.59 ± 0.31) and SPES sub-tasks (DSC=0.84 ± 0.10). When compared with the rest of submitted strategies, we achieve top rank performance with a lower Hausdorff distance. Conclusions. Better segmentation results are obtained by leveraging the anatomy and pathophysiology of acute stroke lesions and using a combined approach to minimize the effects of class imbalance. The same training procedure is used for both tasks, showing the proposed methodology can generalize well enough to deal with different unrelated tasks and imaging modalities without hyper-parameter tuning. In order to promote the reproducibility of our results, a public version of the proposed method has been released to the scientific community","Brain, MRI, Ischemic stroke, Automatic lesion segmentation, Convolutional neural networks, Deep learning",105521,,Computer Methods and Programs in Biomedicine
258,@article: CHUDZIK2018185,Microaneurysm detection using fully convolutional neural networks,Piotr Chudzik and Somshubra Majumdar and Francesco Calivá and Bashir Al-Diri and Andrew Hunter,2018,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260717308544,https://doi.org/10.1016/j.cmpb.2018.02.016,Backround and Objectiv,"Medical image analysis, Microaneurysm detection, Convolutional neural networks, Retinal fundus images",185-192,,Computer Methods and Programs in Biomedicine
259,@article: LI2020105090,Automatic detection of parapapillary atrophy and its association with children myopia,Hanxiang Li and Huiqi Li and Jieliang Kang and Yunlong Feng and Jie Xu,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260719307357,https://doi.org/10.1016/j.cmpb.2019.105090,Background and objecti,"Parapapillary atrophy, PPA segmentation, Children myopia, Image processing",105090,,Computer Methods and Programs in Biomedicine
260,@article: HAN2020105275,Semi-supervised segmentation of lesion from breast ultrasound images with attentional generative adversarial network,Luyi Han and Yunzhi Huang and Haoran Dou and Shuai Wang and Sahar Ahamad and Honghao Luo and Qi Liu and Jingfan Fan and Jiang Zhang,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260719306583,https://doi.org/10.1016/j.cmpb.2019.105275,Background and objecti,"Ultrasound image, Breast lesion, Image segmentation, Semi-supervised learning, Generative adversarial networks, Attention mechanism",105275,,Computer Methods and Programs in Biomedicine
261,@article: AREVALO2016248,Representation learning for mammography mass lesion classification with convolutional neural networks,John Arevalo and Fabio A. González and Raúl Ramos-Pollán and Jose L. Oliveira and Miguel Angel {Guevara Lopez},2016,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260715300110,https://doi.org/10.1016/j.cmpb.2015.12.014,Background and objecti,"Breast cancer, Feature learning, Convolutional neural networks, Computer-aided diagnosis, Mammography",248-257,,Computer Methods and Programs in Biomedicine
262,@article: TALAVERAMARTINEZ2019105049,Computational texture features of dermoscopic images and their link to the descriptive terminology: A survey,Lidia Talavera-Martínez and Pedro Bibiloni and Manuel González-Hidalgo,2019,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260719308442,https://doi.org/10.1016/j.cmpb.2019.105049,"Computer-extracted texture features are relevant to diagnose cutaneous lesions such as melanomas. Our goal is to set a relationship between a well-established descriptive terminology, which describes the attributes of dermoscopic structures based on their aspect rather than their underlying causes, and the computational methods to extract texture-based features. By tackling this problem, we can ascertain what indicators used by dermatologists are reflected in the extracted texture features. We first review the state-of-the-art models for texture extraction in dermoscopic images. By comparing the methods’ performance and goals, we conclude that (I) a single color space does not seem to give performances as good as using several ones, thus the latter is reasonable (II) the optimal number of extracted features seems to vary depending on the method’s goal, and extracting a large number of features can lead to a loss of models robustness (III) methods such as GLCM, Sobel or Law energy filters are mainly used to capture local properties to detect specific dermoscopic structures (IV) methods that extract local and global features, like Gabor wavelets or SPT, tend to be used to analyze the presence of certain patterns of dermoscopic structures, e.g. globular, reticular, etc","Texture analysis, Survey, Dermoscopy, Texture features, Image processing, Melanoma, Descriptive terminology",105049,,Computer Methods and Programs in Biomedicine
263,@article: SUN201677,Computerized breast cancer analysis system using three stage semi-supervised learning method,Wenqing Sun and Tzu-Liang (Bill) Tseng and Jianying Zhang and Wei Qian,2016,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260715302571,https://doi.org/10.1016/j.cmpb.2016.07.017,Background and Objecti,"Semi-supervised learning, Computer aided detection, Mass detection, Unlabeled data",77-88,,Computer Methods and Programs in Biomedicine
264,@article: GUDIGAR2020105205,Brain pathology identification using computer aided diagnostic tool: A systematic review,Anjan Gudigar and U. Raghavendra and Ajay Hegde and M. Kalyani and Edward J. Ciaccio and U. Rajendra Acharya,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260719316669,https://doi.org/10.1016/j.cmpb.2019.105205,"Computer aided diagnostic (CAD) has become a significant tool in expanding patient quality-of-life by reducing human errors in diagnosis. CAD can expedite decision-making on complex clinical data automatically. Since brain diseases can be fatal, rapid identification of brain pathology to prolong patient life is an important research topic. Many algorithms have been proposed for efficient brain pathology identification (BPI) over the past decade. Constant refinement of the various image processing algorithms must take place to expand performance of the automatic BPI task. In this paper, a systematic survey of contemporary BPI algorithms using brain magnetic resonance imaging (MRI) is presented. A summarization of recent literature provides investigators with a helpful synopsis of the domain. Furthermore, to enhance the performance of BPI, future research directions are indicated","Brain pathology, Computer aided diagnostic, Classification, Deep learning, Feature extraction, Magnetic resonance imaging",105205,,Computer Methods and Programs in Biomedicine
265,@article: ASUROGLU2021105816,A deep learning approach for sepsis monitoring via severity score estimation,Tunç Aşuroğlu and Hasan Oğul,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260720316497,https://doi.org/10.1016/j.cmpb.2020.105816,Background and objecti,"Sepsis, prognosis, vital signs, SOFA score, deep learning, early detection",105816,,Computer Methods and Programs in Biomedicine
266,@article: HAGIWARA20181,Computer-aided diagnosis of glaucoma using fundus images: A review,Yuki Hagiwara and Joel En Wei Koh and Jen Hong Tan and Sulatha V. Bhandary and Augustinus Laude and Edward J. Ciaccio and Louis Tong and U. Rajendra Acharya,2018,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260718305492,https://doi.org/10.1016/j.cmpb.2018.07.012,Background and objectiv,"Computer-aided detection system, Deep learning, Glaucoma, Machine learning, Optic disc, Segmentation",1-12,,Computer Methods and Programs in Biomedicine
267,@article: YU2021106382,Lightweight deep neural networks for cholelithiasis and cholecystitis detection by point-of-care ultrasound,Chih-Jui Yu and Hsing-Jung Yeh and Chun-Chao Chang and Jui-Hsiang Tang and Wei-Yu Kao and Wen-Chao Chen and Yi-Jin Huang and Chien-Hung Li and Wei-Hao Chang and Yun-Ting Lin and Herdiantri Sufriyana and Emily Chia-Yu Su,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721004569,https://doi.org/10.1016/j.cmpb.2021.106382,Background and objecti,"Ultrasound, Abdomen, Computer-aided diagnosis, Machine learning, Neural network, Pattern recognition",106382,,Computer Methods and Programs in Biomedicine
268,@article: HANG2020105466,Deep stacked support matrix machine based representation learning for motor imagery EEG classification,Wenlong Hang and Wei Feng and Shuang Liang and Qiong Wang and Xuejun Liu and Kup-Sze Choi,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260719316104,https://doi.org/10.1016/j.cmpb.2020.105466,Background and objecti,"Electroencephalograph, brain-computer interface, support matrix machine, stacked generalization, deep architecture",105466,,Computer Methods and Programs in Biomedicine
269,@article: CHEN2020105630,Interactive thyroid whole slide image diagnostic system using deep representation,Pingjun Chen and Xiaoshuang Shi and Yun Liang and Yuan Li and Lin Yang and Paul D. Gader,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260720314632,https://doi.org/10.1016/j.cmpb.2020.105630,"Background and objectives: The vast size of the histopathology whole slide image poses formidable challenges to its automatic diagnosis. With the goal of computer-aided diagnosis and the insights that suspicious regions are generally easy to identify in thyroid whole slide images (WSIs), we develop an interactive whole slide diagnostic system for thyroid frozen sections based on the suspicious regions preselected by pathologists. Methods:We propose to generate feature representations for the suspicious regions via extracting and fusing patch features using deep neural networks. We then evaluate region classification and retrieval on four classifiers and three supervised hashing methods based on the feature representations. The code is released at https://github.com/PingjunChen/ThyroidInteractive. Results: We evaluate the proposed system on 345 thyroid frozen sections and achieve 96.1% cross-validated classification accuracy, and retrieval mean average precision (MAP) of 0.972. Conclusions: With the participation of pathologists, the system possesses the following four notable advantages compared to directly handling whole slide images: 1) Reduced interference of irrelevant regions; 2) Alleviated computation and memory cost. 3) Fine-grained and precise suspicious region retrieval. 4) Cooperative relationship between pathologists and the diagnostic system. Additionally, experimental results demonstrate the potential of the proposed system on the practical thyroid frozen section diagnosis","Thyroid frozen section, Whole slide image, Suspicious region, Deep representation, Region retrieval",105630,,Computer Methods and Programs in Biomedicine
270,@article: LONG2021105972,BloodCaps: A capsule network based model for the multiclassification of human peripheral blood cells,Fei Long and Jing-Jie Peng and Weitao Song and Xiaobo Xia and Jun Sang,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S016926072100047X,https://doi.org/10.1016/j.cmpb.2021.105972,"Background and Objective: The classification of human peripheral blood cells yields significance in the detection of inflammation, infections and blood cell disorders such as leukemia. Limitations in traditional algorithms for blood cell classification and increased computational processing power have allowed machine learning methods to be utilized for this clinically prevalent task. Methods: In the current work, we present BloodCaps, a capsule based model designed for the accurate multiclassification of a diverse and broad spectrum of blood cells. Results: Implemented on a large-scale dataset of 8 categories of human peripheral blood cells, the proposed architecture achieved an overall accuracy of 99.3%, outperforming convolutional neural networks such as AlexNet(81.5%), VGG16(97.8%), ResNet-18(95.9%) and InceptionV3(98.4%). Furthermore, we devised three new datasets(low-resolution dataset, small dataset, and low-resolution small dataset) from the original dataset, and tested BloodCaps in comparison with AlexNet, VGG16, ResNet-18, and InceptionV3. To further validate the applicability of our proposed model, we tested BloodCaps on additional public datasets such as the All IDB2, BCCD, and Cell Vision datasets. Compared with the reported results, BloodCaps showed the best performance in all three scenarios. Conclusions: The proposed method proved superior in octal classification among all three datasets. We believe the proposed method represents a promising tool to improve the diagnostic performance of clinical blood examinations","Capsule Networks, CNN, Blood Cells, Image Classification, Deep Learning",105972,,Computer Methods and Programs in Biomedicine
271,@article: MILADINOVIC2021105808,Effect of power feature covariance shift on BCI spatial-filtering techniques: A comparative study,Aleksandar Miladinović and Miloš Ajčević and Joanna Jarmolowska and Uros Marusic and Marco Colussi and Giulia Silveri and Piero Paolo Battaglini and Agostino Accardo,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260720316412,https://doi.org/10.1016/j.cmpb.2020.105808,Background and Objecti,"BCI, EEG, Spatial filtering, Covariance shift, Motor-imagery",105808,,Computer Methods and Programs in Biomedicine
272,@article: QIU2021106297,Fusion of CNN1 and CNN2-based magnetic resonance image diagnosis of knee meniscus injury and a comparative analysis with computed tomography,Xubin Qiu and Zhiwei Liu and Ming Zhuang and Dong Cheng and Chenlei Zhu and Xiaoying Zhang,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721003710,https://doi.org/10.1016/j.cmpb.2021.106297,Purpo,"Knee joint, Meniscus injury, Magnetic Resonance Imaging, Convolutional neural network, Diagnostic value",106297,,Computer Methods and Programs in Biomedicine
273,@article: MOON2020105360,Computer-aided tumor detection in automated breast ultrasound using a 3-D convolutional neural network,Woo Kyung Moon and Yao-Sian Huang and Chin-Hua Hsu and Ting-Yin {Chang Chien} and Jung Min Chang and Su Hyun Lee and Chiun-Sheng Huang and Ruey-Feng Chang,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260719307503,https://doi.org/10.1016/j.cmpb.2020.105360,Background and Objectiv,"Automated breast ultrasound, Breast cancer, Computer-aided detection, 3-D convolutional neural network, Focal loss, Ensemble learning",105360,,Computer Methods and Programs in Biomedicine
274,@article: FABREGAT2018121,Deep neural models for extracting entities and relationships in the new RDD corpus relating disabilities and rare diseases,Hermenegildo Fabregat and Lourdes Araujo and Juan Martinez-Romo,2018,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260718301330,https://doi.org/10.1016/j.cmpb.2018.07.007,"Background and objective: There is a huge amount of rare diseases, many of which have associated important disabilities. It is paramount to know in advance the evolution of the disease in order to limit and prevent the appearance of disabilities and to prepare the patient to manage the future difficulties. Rare disease associations are making an effort to manually collect this information, but it is a long process. A lot of information about the consequences of rare diseases is published in scientific papers, and our goal is to automatically extract disabilities associated with diseases from the","Biomedical corpora, Rare diseases, Disabilities, Deep neural networks, Entity recognition, Relationship classification",121-129,,Computer Methods and Programs in Biomedicine
275,@article: ALGHAMDI2021106152,DV-DCNN: Dual-view deep convolutional neural network for matching detected masses in mammograms,Manal AlGhamdi and Mohamed Abdel-Mottaleb,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721002261,https://doi.org/10.1016/j.cmpb.2021.106152,"Background and Objective: Mammography is an X-ray imaging technique used for breast cancer screening. Each breast is usually screened at two different angles generating two views known as mediolateral oblique (MLO) and craniocaudal (CC), which are clinically used by radiologists to detect suspicious masses and diagnose breast cancer. Previous studies applied deep learning models to process each view separately and concatenate the features from the two views to detect and classifying masses. However, direct concatenation is not enough to uncover the relationship between the masses that appear in the two views because they can substantially vary in terms of shape, size, and texture. The relationship between the two views should be established by matching correspondence between their extracted masses. This paper presents a dual-view deep convolutional neural network (DV-DCNN) model for matching masses detected from the two views by establishing correspondence between their extracted patches, which leads to more robust mass detection. Methods: Given a pair of patches as input, the presented model determines whether these patches represent the same mass or not. The network contains two parts: a feature extraction part using tied dense blocks, and a neighborhood patch matching part with three consecutive layers, i.e., a cross-input neighborhood differences layer to find the relationship between the two patches, a patch summary features layer to define a summary of the neighborhood differences and an across-patch features layer to learn a higher-level representation across neighborhood differences. Results: To evaluate the model’s performance in diverse cases, several experimental scenarios were followed for training and testing using two public datasets, i.e., CBIS-DDSM and INbreast. We also evaluate the contribution of our mass-matching model within a mass detection framework. Experiments show that DV-DCNN outperforms other related deep learning models and demonstrate that the detection results improve when using our model. Conclusions: Matching potential masses between two different views of the same breast leads to more robust mass detection. Experimental results demonstrate the efficacy of a dual-view deep learning model in matching masses, which helps in increasing the accuracy of mass detection and decreasing the false positive rates","Mammography, dual-view, breast cancer, deep learning, matching",106152,,Computer Methods and Programs in Biomedicine
276,@article: BISWAS2018165,Symtosis: A liver ultrasound tissue characterization and risk stratification in optimized deep learning paradigm,Mainak Biswas and Venkatanareshbabu Kuppili and Damodar Reddy Edla and Harman S. Suri and Luca Saba and Rui Tato Marinhoe and J. Miguel Sanches and Jasjit S. Suri,2018,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260717308416,https://doi.org/10.1016/j.cmpb.2017.12.016,Background and Objecti,,165-177,,Computer Methods and Programs in Biomedicine
277,@article: XI2021106077,Recovering dense 3D point clouds from single endoscopic image,Long Xi and Yan Zhao and Long Chen and Qing Hong Gao and Wen Tang and Tao Ruan Wan and Tao Xue,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721001528,https://doi.org/10.1016/j.cmpb.2021.106077,"Background and objective: Recovering high-quality 3D point clouds from monocular endoscopic images is a challenging task. This paper proposes a novel deep learning-based computational framework for 3D point cloud reconstruction from single monocular endoscopic images. Methods: An unsupervised mono-depth learning network is used to generate depth information from monocular images. Given a single mono endoscopic image, the network is capable of depicting a depth map. The depth map is then used to recover a dense 3D point cloud. A generative Endo-AE network based on an auto-encoder is trained to repair defects of the dense point cloud by generating the best representation from the incomplete data. The performance of the proposed framework is evaluated against state-of-the-art learning-based methods. The results are also compared with non-learning based stereo 3D reconstruction algorithms. Results: Our proposed methods outperform both the state-of-the-art learning-based and non-learning based methods for 3D point cloud reconstruction. The Endo-AE model for point cloud completion can generate high-quality, dense 3D endoscopic point clouds from incomplete point clouds with holes. Our framework is able to recover complete 3D point clouds with the missing rate of information up to 60%. Five large medical in-vivo databases of 3D point clouds of real endoscopic scenes have been generated and two synthetic 3D medical datasets are created. We have made these datasets publicly available for researchers free of charge. Conclusions: The proposed computational framework can produce high-quality and dense 3D point clouds from single mono-endoscopy images for augmented reality, virtual reality and other computer-mediated medical applications","3D point clouds, Monocular endoscopic scenes, Artificial intelligence/ deep learning, Augmented reality, Virtual reality, Minimally invasive surgery",106077,,Computer Methods and Programs in Biomedicine
278,@article: DONG2021106421,Hole-filling based on content loss indexed 3D partial convolution network for freehand ultrasound reconstruction,Jiahui Dong and Tianyu Fu and Yucong Lin and Qiaoling Deng and Jingfan Fan and Hong Song and Zhigang Cheng and Ping Liang and Yongtian Wang and Jian Yang,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721004958,https://doi.org/10.1016/j.cmpb.2021.106421,Background and objecti,"Ultrasound, 3D reconstruction, Partial convolution, Generative adversarial network",106421,,Computer Methods and Programs in Biomedicine
279,@article: CHU2021105906,Ultrasonic thyroid nodule detection method based on U-Net network,Chen Chu and Jihui Zheng and Yong Zhou,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260720317399,https://doi.org/10.1016/j.cmpb.2020.105906,Objecti,"Thyroid nodules, Ultrasound, Image segmentation, U-Net, Deep learning",105906,,Computer Methods and Programs in Biomedicine
280,@article: LI2020105724,White learning methodology: A case study of cancer-related disease factors analysis in real-time PACS environment,Tengyue Li and Simon Fong and Shirley W.I. Siu and Xin-she Yang and Lian-Sheng Liu and Sabah Mohammed,2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260720315571,https://doi.org/10.1016/j.cmpb.2020.105724,Background and Objecti,"Data mining methodology, Deep learning, Bayesian network, Radiological data analysis",105724,,Computer Methods and Programs in Biomedicine
281,@article: ABREU2020105675,Morphological autoencoders for apnea detection in respiratory gating radiotherapy,Mariana Abreu and Ana Fred and João Valente and Chen Wang and Hugo {Plácido da Silva},2020,,0169-2607,https://www.sciencedirect.com/science/article/pii/S016926072031508X,https://doi.org/10.1016/j.cmpb.2020.105675,"Background and Objective: Respiratory gating training is a common technique to increase patient proprioception, with the goal of (e.g.) minimizing the effects of organ motion during radiotherapy. In this work, we devise a system based on autoencoders for classification of regular, apnea and unconstrained breathing patterns (i.e. multiclass). Methods: Our approach is based on morphological analysis of the respiratory signals, using an autoencoder trained on regular breathing. The correlation between the input and output of the autoencoder is used to train and test several classifiers in order to select the best. Our approach is evaluated in a novel real-world respiratory gating biofeedback training dataset and on the Apnea-ECG reference dataset. Results: Accuracies of 95 ± 3.5% and 87 ± 6.6% were obtained for two different datasets, in the classification of breathing and apnea. These results suggest the viability of a generalised model to characterise the breathing patterns under study. Conclusions: Using autoencoders to learn respiratory gating training patterns allows a data-driven approach to feature extraction, by focusing only on the signal’s morphology. The proposed system is prone to be used in real-time and could potentially be transferred to other domains","Artificial neural networks, Respiratory gating, Apnea detection, Machine learning, Signal processing",105675,,Computer Methods and Programs in Biomedicine
282,@article: ALAKEELY2021105992,Using deep learning to identify diabetic retinopathy in Saudi Arabia,Adel AlAkeely and Hamad Alsubaie and Abdulaziz Alharbi and Fahad Alsaawi and Lama Alshabib and Abdullah Albahlal and Abdullah Alzee,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721000675,https://doi.org/10.1016/j.cmpb.2021.105992,,,105992,,Computer Methods and Programs in Biomedicine
283,@article: TOR2021105941,Automated detection of conduct disorder and attention deficit hyperactivity disorder using decomposition and nonlinear techniques with EEG signals,Hui Tian Tor and Chui Ping Ooi and Nikki SJ Lim-Ashworth and Joel Koh En Wei and V Jahmunah and Shu Lih Oh and U Rajendra Acharya and Daniel Shuen Sheng Fung,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721000158,https://doi.org/10.1016/j.cmpb.2021.105941,Background and objectiv,"Attention deficit hyperactive disorder, Conduct disorder, Nonlinear features, Sequential forward selection, K-fold validation, Classifiers, Machine learning",105941,,Computer Methods and Programs in Biomedicine
284,@article: WANG2015164,Polyp-Alert: Near real-time feedback during colonoscopy,Yi Wang and Wallapak Tavanapong and Johnny Wong and Jung Hwan Oh and Piet C. {de Groen},2015,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260715000887,https://doi.org/10.1016/j.cmpb.2015.04.002,"We present a software system called “Polyp-Alert” to assist the endoscopist find polyps by providing visual feedback during colonoscopy. Polyp-Alert employs our previous edge-cross-section visual features and a rule-based classifier to detect a polyp edge—an edge along the contour of a polyp. The technique employs tracking of detected polyp edge(s) to group a sequence of images covering the same polyp(s) as one polyp shot. In our experiments, the software correctly detected 97.7% (42 of 43) of polyp shots on 53 randomly selected video files of entire colonoscopy procedures. However, Polyp-Alert incorrectly marked only 4.3% of a full-length colonoscopy procedure as showing a polyp when they do not. The test data set consists of about 18h worth of video data from Olympus and Fujinon endoscopes. The technique is extensible to other brands of colonoscopes. Furthermore, Polyp-Alert can provide as high as ten feedbacks per second for a smooth display of feedback. The performance of our system is by far the most promising to potentially assist the endoscopist find more polyps in clinical practice during a routine screening colonoscopy","Near Real-time, Polyp detection, Colonoscopy, Medical imaging/video",164-179,,Computer Methods and Programs in Biomedicine
285,@article: BARILE2021106113,Data augmentation using generative adversarial neural networks on brain structural connectivity in multiple sclerosis,Berardino Barile and Aldo Marzullo and Claudio Stamile and Françoise Durand-Dubief and Dominique Sappey-Marinier,2021,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260721001887,https://doi.org/10.1016/j.cmpb.2021.106113,"Background and objective:Machine learning frameworks have demonstrated their potentials in dealing with complex data structures, achieving remarkable results in many areas, including brain imaging. However, a large collection of data is needed to train these models. This is particularly challenging in the biomedical domain since, due to acquisition accessibility, costs and pathology related variability, available datasets are limited and usually imbalanced. To overcome this challenge, generative models can be used to generate new data. Methods: In this study, a framework based on generative adversarial network is proposed to create synthetic structural brain networks in Multiple Sclerosis (MS). The dataset consists of 29 relapsing-remitting and 19 secondary-progressive MS patients. T1 and diffusion tensor imaging (DTI) acquisitions were used to obtain the structural brain network for each subject. Evaluation of the quality of newly generated brain networks is performed by (i) analysing their structural properties and (ii) studying their impact on classification performance. Results: We demonstrate that advanced generative models could be directly applied to the structural brain networks. We quantitatively and qualitatively show that newly generated data do not present significant differences compared to the real ones. In addition, augmenting the existing dataset with generated samples leads to an improvement of the classification performance (F1score 81%) with respect to the baseline approach (F1score 66%). Conclusions: Our approach defines a new tool for biomedical application when connectome-based data augmentation is needed, providing a valid alternative to usual image-based data augmentation techniques","Brain connectivity, Multiple sclerosis, Data augmentation, Generative adversarial networks",106113,,Computer Methods and Programs in Biomedicine
286,@article: NIWAS201665,Automated anterior segment OCT image analysis for Angle Closure Glaucoma mechanisms classification,Swamidoss Issac Niwas and Weisi Lin and Xiaolong Bai and Chee Keong Kwoh and C.-C. {Jay Kuo} and Chelvin C. Sng and Maria Cecilia Aquino and Paul T.K. Chew,2016,,0169-2607,https://www.sciencedirect.com/science/article/pii/S016926071530362X,https://doi.org/10.1016/j.cmpb.2016.03.018,Background and objectiv,"Angle closure glaucoma, Compound image transforms, Feature selection, Segmentation-free method, Machine learning classifier",65-75,,Computer Methods and Programs in Biomedicine
287,@article: YAN201911,A propagation-DNN: Deep combination learning of multi-level features for MR prostate segmentation,Ke Yan and Xiuying Wang and Jinman Kim and Mohamed Khadra and Michael Fulham and Dagan Feng,2019,,0169-2607,https://www.sciencedirect.com/science/article/pii/S016926071831099X,https://doi.org/10.1016/j.cmpb.2018.12.031,Background and objecti,"Prostate segmentation, Deep neural network, Multi-level features",11-21,,Computer Methods and Programs in Biomedicine
